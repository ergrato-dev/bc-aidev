# üìö Recursos - Semana 29: NLP Fundamentos

## üìñ Ebooks Gratuitos

### Procesamiento de Lenguaje Natural
- [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/) - Jurafsky & Martin (Stanford)
- [Natural Language Processing with Python](https://www.nltk.org/book/) - NLTK Book (O'Reilly)
- [A Primer on Neural Network Models for NLP](https://arxiv.org/abs/1510.00726) - Yoav Goldberg

### Word Embeddings
- [Word2Vec Tutorial](https://arxiv.org/abs/1301.3781) - Paper original de Mikolov et al.
- [GloVe: Global Vectors](https://nlp.stanford.edu/pubs/glove.pdf) - Paper de Stanford

---

## üé• Videograf√≠a

### Cursos Completos
- [Stanford CS224N: NLP with Deep Learning](https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ) - Christopher Manning
- [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course) - Curso interactivo gratuito

### Videos Espec√≠ficos
- [Word2Vec Explained](https://www.youtube.com/watch?v=ISUHBJwPpwg) - StatQuest
- [Word Embeddings](https://www.youtube.com/watch?v=viZrOnJclY0) - 3Blue1Brown style
- [Tokenization Explained](https://www.youtube.com/watch?v=zduSFxRajkE) - Hugging Face

---

## üåê Webgraf√≠a

### Documentaci√≥n Oficial
- [NLTK Documentation](https://www.nltk.org/) - Natural Language Toolkit
- [spaCy Documentation](https://spacy.io/) - Industrial-strength NLP
- [Gensim Documentation](https://radimrehurek.com/gensim/) - Topic Modeling & Word Vectors
- [Hugging Face Docs](https://huggingface.co/docs) - Transformers & Tokenizers

### Tutoriales y Gu√≠as
- [Real Python - NLP](https://realpython.com/nltk-nlp-python/) - NLTK Tutorial
- [Towards Data Science - Word2Vec](https://towardsdatascience.com/word2vec-explained-49c52b4ccb71)
- [Jay Alammar - Word2Vec](https://jalammar.github.io/illustrated-word2vec/) - Visualizaci√≥n ilustrada

### Datasets
- [Kaggle NLP Datasets](https://www.kaggle.com/datasets?tags=13204-NLP)
- [Hugging Face Datasets](https://huggingface.co/datasets)
- [NLTK Corpora](https://www.nltk.org/nltk_data/)

### Pre-trained Models
- [Gensim Data](https://github.com/RaRe-Technologies/gensim-data) - Word vectors pre-entrenados
- [FastText Vectors](https://fasttext.cc/docs/en/crawl-vectors.html) - Facebook Research
- [GloVe Vectors](https://nlp.stanford.edu/projects/glove/) - Stanford NLP

---

## üõ†Ô∏è Herramientas

### Bibliotecas Python
| Librer√≠a | Uso Principal | Instalaci√≥n |
|----------|---------------|-------------|
| NLTK | Preprocesamiento, tokenizaci√≥n | `pip install nltk` |
| spaCy | NLP industrial, NER, POS | `pip install spacy` |
| Gensim | Word2Vec, Doc2Vec, LDA | `pip install gensim` |
| TextBlob | NLP simplificado | `pip install textblob` |

### Visualizaci√≥n
- [Embedding Projector](https://projector.tensorflow.org/) - Visualizar embeddings en 3D
- [What's in a Word?](https://pair-code.github.io/understanding-umap/) - UMAP para embeddings

---

## üìä Papers Fundamentales

1. **Word2Vec** (2013)
   - [Efficient Estimation of Word Representations](https://arxiv.org/abs/1301.3781)
   - Mikolov et al., Google

2. **GloVe** (2014)
   - [Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)
   - Pennington et al., Stanford

3. **FastText** (2016)
   - [Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606)
   - Bojanowski et al., Facebook

4. **BPE Tokenization** (2015)
   - [Neural Machine Translation of Rare Words](https://arxiv.org/abs/1508.07909)
   - Sennrich et al.

---

## üîó Enlaces R√°pidos

- [Anterior: Semana 28](../../03-deep-learning/week-28/README.md)
- [Siguiente: Semana 30](../week-30/README.md)
- [√çndice del M√≥dulo](../README.md)

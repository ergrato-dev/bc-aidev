# ğŸ” Proyecto: Buscador SemÃ¡ntico

## ğŸ¯ Objetivo

Construir un buscador semÃ¡ntico que encuentre documentos relevantes usando similaridad de embeddings.

---

## ğŸ“‹ DescripciÃ³n

En este proyecto crearÃ¡s un motor de bÃºsqueda semÃ¡ntica completo que:

1. Preprocesa y tokeniza documentos
2. Genera embeddings para cada documento
3. Permite buscar documentos por similaridad semÃ¡ntica
4. Muestra resultados ordenados por relevancia

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Documentos    â”‚â”€â”€â”€â”€â–¶â”‚  Preprocesamiento â”‚â”€â”€â”€â”€â–¶â”‚   Embeddings    â”‚
â”‚   (corpus)      â”‚     â”‚  + TokenizaciÃ³n   â”‚     â”‚   (vectores)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                         â”‚
                                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Resultados    â”‚â—€â”€â”€â”€â”€â”‚    Ranking por   â”‚â—€â”€â”€â”€â”€â”‚     Query       â”‚
â”‚   ordenados     â”‚     â”‚    similaridad   â”‚     â”‚   embedding     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Estructura

```
buscador-semantico/
â”œâ”€â”€ README.md
â”œâ”€â”€ starter/
â”‚   â””â”€â”€ main.py      # Plantilla para implementar
â””â”€â”€ solution/
    â””â”€â”€ main.py      # SoluciÃ³n completa
```

---

## ğŸ”§ Requisitos Funcionales

### Clase `SemanticSearchEngine`

Implementar los siguientes mÃ©todos:

1. **`__init__(model_name)`**: Inicializar con modelo de embeddings
2. **`preprocess(text)`**: Limpiar y normalizar texto
3. **`get_embedding(text)`**: Obtener embedding de texto
4. **`index_documents(documents)`**: Indexar corpus de documentos
5. **`search(query, top_k)`**: Buscar documentos similares
6. **`add_document(document)`**: AÃ±adir documento al Ã­ndice

---

## ğŸ“Š Dataset de Ejemplo

```python
documents = [
    "Machine learning is a subset of artificial intelligence",
    "Deep learning uses neural networks with many layers",
    "Natural language processing analyzes human language",
    "Computer vision enables machines to interpret images",
    "Reinforcement learning trains agents through rewards",
    "Python is widely used for data science projects",
    "TensorFlow and PyTorch are popular deep learning frameworks",
    "Word embeddings represent words as dense vectors",
]
```

---

## â–¶ï¸ EjecuciÃ³n

```bash
cd bootcamp/04-especializacion/week-29/3-proyecto/buscador-semantico

# Ejecutar tu implementaciÃ³n
python starter/main.py

# Ver la soluciÃ³n
python solution/main.py
```

---

## ğŸ“ Ejemplo de Uso

```python
# Crear buscador
engine = SemanticSearchEngine('glove-wiki-gigaword-50')

# Indexar documentos
engine.index_documents(documents)

# Buscar
results = engine.search("neural networks and AI", top_k=3)

# Mostrar resultados
for doc, score in results:
    print(f"[{score:.4f}] {doc}")
```

**Salida esperada:**
```
[0.8234] Deep learning uses neural networks with many layers
[0.7891] Machine learning is a subset of artificial intelligence
[0.6543] TensorFlow and PyTorch are popular deep learning frameworks
```

---

## âœ… Criterios de EvaluaciÃ³n

### Funcionalidad (40%)
- [ ] Preprocesamiento funciona correctamente
- [ ] Embeddings se calculan para documentos
- [ ] BÃºsqueda retorna resultados ordenados
- [ ] Manejo de palabras fuera de vocabulario

### CÃ³digo (30%)
- [ ] CÃ³digo bien organizado y modular
- [ ] Type hints en funciones
- [ ] Docstrings descriptivos
- [ ] Nombres descriptivos de variables

### Extras (30%)
- [ ] BÃºsqueda interactiva en terminal
- [ ] Soporte para mÃºltiples modelos
- [ ] MÃ©tricas de evaluaciÃ³n (tiempo de bÃºsqueda)
- [ ] Persistencia del Ã­ndice

---

## ğŸ’¡ Hints

1. **Modelo pequeÃ±o para pruebas**: Usa `glove-wiki-gigaword-50` (50 dims)
2. **CachÃ© de embeddings**: Guarda embeddings calculados para no recalcular
3. **NormalizaciÃ³n**: Considera normalizar vectores para bÃºsqueda mÃ¡s rÃ¡pida
4. **Manejo de OOV**: Ignora palabras que no estÃ¡n en el vocabulario

---

## ğŸ”— Recursos

- [Gensim Documentation](https://radimrehurek.com/gensim/)
- [Pre-trained Word Vectors](https://github.com/RaRe-Technologies/gensim-data)
- [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)

---

## ğŸš€ Extensiones Opcionales

1. **TF-IDF Weighting**: Ponderar palabras por importancia
2. **BM25 Hybrid**: Combinar con bÃºsqueda tradicional
3. **GUI Simple**: Interfaz web con Streamlit
4. **EvaluaciÃ³n**: Implementar mÃ©tricas como MRR o NDCG

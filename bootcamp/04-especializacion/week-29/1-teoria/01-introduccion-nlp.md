# ğŸŒ IntroducciÃ³n al Procesamiento de Lenguaje Natural

![Pipeline NLP](../0-assets/01-nlp-pipeline.svg)

## ğŸ¯ Objetivos

- Comprender quÃ© es NLP y sus aplicaciones
- Conocer los desafÃ­os del procesamiento de texto
- Entender el pipeline tÃ­pico de NLP

---

## ğŸ“‹ Â¿QuÃ© es NLP?

**Natural Language Processing (NLP)** es el campo de la IA que permite a las computadoras entender, interpretar y generar lenguaje humano.

### Aplicaciones Comunes

| AplicaciÃ³n | DescripciÃ³n | Ejemplos |
|------------|-------------|----------|
| ClasificaciÃ³n de texto | Asignar categorÃ­as a documentos | Spam detection, sentiment analysis |
| NER | Identificar entidades nombradas | Extraer nombres, fechas, lugares |
| TraducciÃ³n | Convertir entre idiomas | Google Translate |
| QA | Responder preguntas | ChatGPT, asistentes virtuales |
| Resumen | Condensar documentos | ResÃºmenes automÃ¡ticos |
| GeneraciÃ³n | Crear texto nuevo | GPT, escritura automÃ¡tica |

---

## ğŸ”„ Pipeline de NLP

El procesamiento de texto sigue un pipeline tÃ­pico:

```
Texto Crudo â†’ Preprocesamiento â†’ TokenizaciÃ³n â†’ RepresentaciÃ³n â†’ Modelo â†’ Salida
```

### 1. Preprocesamiento
- Limpieza de texto
- NormalizaciÃ³n
- EliminaciÃ³n de ruido

### 2. TokenizaciÃ³n
- Dividir texto en unidades (tokens)
- Palabras, subpalabras o caracteres

### 3. RepresentaciÃ³n Vectorial
- Convertir tokens en vectores numÃ©ricos
- One-hot, TF-IDF, embeddings

### 4. Modelado
- Aplicar algoritmos de ML/DL
- Clasificadores, secuencia a secuencia

### 5. Post-procesamiento
- Decodificar salida
- Formatear resultados

---

## ğŸ­ DesafÃ­os del NLP

### AmbigÃ¼edad LÃ©xica

```python
# La misma palabra, diferentes significados
"banco"  # InstituciÃ³n financiera o asiento
"vela"   # Objeto de cera o del verbo "velar"
```

### AmbigÃ¼edad SintÃ¡ctica

```
"Vi al hombre con el telescopio"
# Â¿QuiÃ©n tiene el telescopio?
```

### Contexto y Conocimiento del Mundo

```python
# Requiere conocimiento implÃ­cito
"El trofeo no cabe en la maleta porque es muy grande"
# Â¿QuÃ© es grande? El trofeo o la maleta?
```

### Variabilidad del Lenguaje

```python
# MÃºltiples formas de expresar lo mismo
"Me gusta esta pelÃ­cula"
"Esta peli me mola"
"QuÃ© buena pelÃ­cula!"
"â­â­â­â­â­"
```

---

## ğŸ“Š Representaciones de Texto

### Representaciones Sparse (Tradicionales)

**Bag of Words (BoW)**
```python
# Documento: "el gato come pescado"
# Vocabulario: [el, gato, come, pescado, perro]
# Vector: [1, 1, 1, 1, 0]
```

**TF-IDF**
- Term Frequency Ã— Inverse Document Frequency
- Pondera palabras por importancia

### Representaciones Dense (Modernas)

**Word Embeddings**
- Vectores densos de dimensiÃ³n fija (100-300)
- Capturan significado semÃ¡ntico
- Palabras similares â†’ vectores cercanos

```python
# Ejemplo conceptual
"rey"    â†’ [0.2, -0.5, 0.8, ...]  # 300 dimensiones
"reina"  â†’ [0.3, -0.4, 0.7, ...]  # Similar a "rey"
"banana" â†’ [-0.8, 0.1, -0.3, ...] # Muy diferente
```

---

## ğŸ”¢ De Texto a NÃºmeros

```python
# Flujo tÃ­pico
texto = "Me encanta Python"

# 1. Tokenizar
tokens = ["me", "encanta", "python"]

# 2. Vocabulario
vocab = {"me": 0, "encanta": 1, "python": 2, ...}

# 3. IDs
ids = [0, 1, 2]

# 4. Embeddings
embeddings = [
    [0.1, 0.2, ...],  # me
    [0.3, 0.4, ...],  # encanta
    [0.5, 0.6, ...]   # python
]
```

---

## ğŸ› ï¸ Herramientas de NLP

| LibrerÃ­a | Uso Principal |
|----------|---------------|
| NLTK | Educativo, lingÃ¼Ã­stica |
| spaCy | ProducciÃ³n, velocidad |
| Gensim | Word embeddings, topic modeling |
| Hugging Face | Transformers, modelos pre-entrenados |
| TextBlob | AnÃ¡lisis simple |

---

## âœ… Checklist de VerificaciÃ³n

- [ ] Entiendo quÃ© es NLP y sus aplicaciones
- [ ] Conozco las fases del pipeline de NLP
- [ ] Comprendo los desafÃ­os del procesamiento de texto
- [ ] Distingo entre representaciones sparse y dense

---

## ğŸ“š Recursos

- [Speech and Language Processing - Jurafsky](https://web.stanford.edu/~jurafsky/slp3/)
- [NLTK Book](https://www.nltk.org/book/)
- [spaCy 101](https://spacy.io/usage/spacy-101)

---

_Siguiente: [Preprocesamiento de Texto](02-preprocesamiento.md)_

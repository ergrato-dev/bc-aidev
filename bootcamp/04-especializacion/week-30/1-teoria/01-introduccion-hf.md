# ğŸ¤— IntroducciÃ³n a Hugging Face

![Ecosistema Hugging Face](../0-assets/01-hf-ecosystem.svg)

## ğŸ¯ Objetivos

- Conocer el ecosistema Hugging Face
- Entender quÃ© son los Transformers
- Instalar y configurar la librerÃ­a

---

## ğŸ“‹ Â¿QuÃ© es Hugging Face?

**Hugging Face** es la plataforma lÃ­der para Machine Learning, especialmente NLP. Ofrece:

1. **ğŸ¤— Transformers**: LibrerÃ­a de modelos pre-entrenados
2. **ğŸ“š Datasets**: ColecciÃ³n de datasets para ML
3. **ğŸ¯ Hub**: Repositorio de modelos compartidos
4. **ğŸ”¤ Tokenizers**: Tokenizadores rÃ¡pidos en Rust
5. **âš¡ Accelerate**: Entrenamiento distribuido

---

## ğŸ—ï¸ Arquitectura Transformer

Los **Transformers** revolucionaron NLP en 2017 con el paper "Attention is All You Need".

### Componentes Clave

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TRANSFORMER                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     ENCODER      â”‚      DECODER         â”‚
â”‚  (comprensiÃ³n)   â”‚   (generaciÃ³n)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - BERT          â”‚  - GPT               â”‚
â”‚  - RoBERTa       â”‚  - GPT-2, GPT-3      â”‚
â”‚  - DistilBERT    â”‚  - LLaMA             â”‚
â”‚  - ALBERT        â”‚  - Mistral           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           ENCODER-DECODER               â”‚
â”‚  - T5, BART, mT5, FLAN-T5              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tipos de Modelos

| Tipo | Arquitectura | Tareas | Ejemplos |
|------|--------------|--------|----------|
| **Encoder** | Solo encoder | ClasificaciÃ³n, NER, QA extractivo | BERT, RoBERTa |
| **Decoder** | Solo decoder | GeneraciÃ³n de texto | GPT, LLaMA |
| **Encoder-Decoder** | Completo | TraducciÃ³n, Resumen | T5, BART |

---

## âš™ï¸ InstalaciÃ³n

```bash
# InstalaciÃ³n bÃ¡sica
pip install transformers

# Con PyTorch (recomendado)
pip install transformers torch

# Con TensorFlow
pip install transformers tensorflow

# InstalaciÃ³n completa
pip install transformers[torch] datasets accelerate
```

### Verificar InstalaciÃ³n

```python
import transformers
print(f"Transformers version: {transformers.__version__}")

# Verificar backend
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
```

---

## ğŸš€ Primer Ejemplo

```python
from transformers import pipeline

# Crear pipeline de anÃ¡lisis de sentimientos
classifier = pipeline("sentiment-analysis")

# Clasificar texto
result = classifier("I love using Hugging Face!")
print(result)
# [{'label': 'POSITIVE', 'score': 0.9998}]

# Clasificar mÃºltiples textos
texts = [
    "This is amazing!",
    "I hate waiting in line.",
    "The weather is okay today."
]
results = classifier(texts)
for text, res in zip(texts, results):
    print(f"{text} â†’ {res['label']} ({res['score']:.2%})")
```

---

## ğŸŒ Hugging Face Hub

El **Hub** es un repositorio con miles de modelos y datasets.

### Explorar Modelos

```python
from huggingface_hub import list_models

# Buscar modelos de sentiment analysis
models = list_models(filter="sentiment-analysis", limit=5)
for model in models:
    print(f"- {model.modelId}")
```

### Modelos Populares

| Modelo | ParÃ¡metros | Uso |
|--------|------------|-----|
| `bert-base-uncased` | 110M | ClasificaciÃ³n, NER |
| `distilbert-base-uncased` | 66M | VersiÃ³n ligera de BERT |
| `roberta-base` | 125M | Mejor que BERT en muchas tareas |
| `gpt2` | 124M | GeneraciÃ³n de texto |
| `t5-small` | 60M | Tareas seq2seq |

### Modelos en EspaÃ±ol

| Modelo | DescripciÃ³n |
|--------|-------------|
| `dccuchile/bert-base-spanish-wwm-cased` | BERT entrenado en espaÃ±ol |
| `PlanTL-GOB-ES/roberta-base-bne` | RoBERTa del Plan TL EspaÃ±a |
| `bertin-project/bertin-roberta-base-spanish` | BERTIN |
| `mrm8488/bert-spanish-cased-finetuned-ner` | NER en espaÃ±ol |

---

## ğŸ“ CachÃ© de Modelos

Los modelos se descargan a `~/.cache/huggingface/`:

```python
import os
from pathlib import Path

# Ver directorio de cachÃ©
cache_dir = Path.home() / ".cache" / "huggingface"
print(f"CachÃ©: {cache_dir}")

# Cambiar directorio de cachÃ©
os.environ["HF_HOME"] = "/path/to/custom/cache"

# O al cargar modelo
from transformers import AutoModel
model = AutoModel.from_pretrained("bert-base-uncased", cache_dir="./my_cache")
```

---

## ğŸ”‘ AutenticaciÃ³n (Opcional)

Para modelos privados o subir modelos:

```bash
# Login desde terminal
huggingface-cli login

# O con token
huggingface-cli login --token YOUR_TOKEN
```

```python
# Login desde Python
from huggingface_hub import login
login(token="YOUR_TOKEN")

# O usar variable de entorno
# export HF_TOKEN=your_token
```

---

## âœ… Checklist de VerificaciÃ³n

- [ ] Entiendo el ecosistema Hugging Face
- [ ] Conozco los tipos de modelos (encoder, decoder, encoder-decoder)
- [ ] Tengo transformers instalado correctamente
- [ ] Puedo ejecutar un pipeline bÃ¡sico

---

_Siguiente: [Pipelines](02-pipelines.md)_

"""
Ejercicio 01: Pipelines de Hugging Face
=======================================

Aprende a usar los pipelines para tareas NLP comunes.

Instrucciones:
1. Lee cada secci√≥n y descomenta el c√≥digo
2. Ejecuta el script despu√©s de cada paso
3. Experimenta con diferentes textos

Nota: La primera ejecuci√≥n descargar√° modelos (~250MB+)
"""

# ============================================
# PASO 1: Setup e Imports
# ============================================
print("--- Paso 1: Setup ---")

# Descomenta las siguientes l√≠neas:
# from transformers import pipeline
# import warnings
# warnings.filterwarnings('ignore')
#
# print('‚úì Transformers importado correctamente')

print()


# ============================================
# PASO 2: An√°lisis de Sentimientos
# ============================================
print("--- Paso 2: An√°lisis de Sentimientos ---")

# El pipeline m√°s b√°sico: clasificar texto como positivo/negativo
# Modelo por defecto: distilbert-base-uncased-finetuned-sst-2-english

# Descomenta las siguientes l√≠neas:
# print('Cargando pipeline de sentiment-analysis...')
# sentiment = pipeline('sentiment-analysis')
#
# # Probar con un texto
# result = sentiment('I absolutely love this product!')
# print(f'Resultado: {result}')
#
# # Probar con m√∫ltiples textos
# texts = [
#     "This movie was fantastic!",
#     "I hate waiting in long lines.",
#     "The weather is okay today.",
#     "What a terrible experience.",
# ]
#
# results = sentiment(texts)
# print('\nAn√°lisis de m√∫ltiples textos:')
# for text, res in zip(texts, results):
#     emoji = 'üòä' if res['label'] == 'POSITIVE' else 'üòû'
#     print(f"  {emoji} {res['label']:8} ({res['score']:.2%}) | {text}")

print()


# ============================================
# PASO 3: Reconocimiento de Entidades (NER)
# ============================================
print("--- Paso 3: Named Entity Recognition ---")

# NER identifica entidades como personas, lugares, organizaciones
# aggregation_strategy="simple" agrupa tokens de la misma entidad

# Descomenta las siguientes l√≠neas:
# print('Cargando pipeline de NER...')
# ner = pipeline('ner', aggregation_strategy='simple')
#
# text = "Apple Inc. was founded by Steve Jobs in California in 1976."
# entities = ner(text)
#
# print(f'Texto: "{text}"')
# print('\nEntidades encontradas:')
# for entity in entities:
#     print(f"  {entity['word']:20} ‚Üí {entity['entity_group']:5} ({entity['score']:.2%})")
#
# # Probar con otro texto
# text2 = "Elon Musk is the CEO of Tesla and SpaceX, based in Texas."
# entities2 = ner(text2)
#
# print(f'\nTexto: "{text2}"')
# print('Entidades:')
# for entity in entities2:
#     print(f"  {entity['word']:20} ‚Üí {entity['entity_group']:5} ({entity['score']:.2%})")

print()


# ============================================
# PASO 4: Preguntas y Respuestas
# ============================================
print("--- Paso 4: Question Answering ---")

# QA extrae respuestas de un contexto dado
# El modelo busca el span de texto que responde la pregunta

# Descomenta las siguientes l√≠neas:
# print('Cargando pipeline de QA...')
# qa = pipeline('question-answering')
#
# context = """
# Python is a high-level, general-purpose programming language.
# Its design philosophy emphasizes code readability. Python was
# created by Guido van Rossum and first released in 1991.
# It supports multiple programming paradigms, including structured,
# object-oriented and functional programming.
# """
#
# questions = [
#     "Who created Python?",
#     "When was Python first released?",
#     "What does Python emphasize?",
# ]
#
# print('Contexto sobre Python...\n')
# for question in questions:
#     result = qa(question=question, context=context)
#     print(f'Q: {question}')
#     print(f'A: {result["answer"]} (confidence: {result["score"]:.2%})\n')

print()


# ============================================
# PASO 5: Generaci√≥n de Texto
# ============================================
print("--- Paso 5: Generaci√≥n de Texto ---")

# Genera texto continuando un prompt
# GPT-2 es autoregresivo: predice el siguiente token

# Descomenta las siguientes l√≠neas:
# print('Cargando pipeline de text-generation (GPT-2)...')
# generator = pipeline('text-generation', model='gpt2')
#
# prompts = [
#     "Artificial intelligence will",
#     "The future of technology is",
#     "Machine learning helps us",
# ]
#
# for prompt in prompts:
#     print(f'\nPrompt: "{prompt}"')
#     result = generator(
#         prompt,
#         max_length=40,
#         num_return_sequences=1,
#         do_sample=True,
#         temperature=0.7,
#         pad_token_id=50256  # GPT-2 EOS token
#     )
#     generated = result[0]['generated_text']
#     print(f'Generated: {generated}')

print()


# ============================================
# PASO 6: Zero-Shot Classification
# ============================================
print("--- Paso 6: Zero-Shot Classification ---")

# Clasifica texto en categor√≠as sin entrenamiento previo
# Usa NLI (Natural Language Inference) internamente

# Descomenta las siguientes l√≠neas:
# print('Cargando pipeline de zero-shot-classification...')
# zero_shot = pipeline('zero-shot-classification')
#
# texts_to_classify = [
#     "I need to buy groceries for dinner tonight",
#     "The stock market crashed by 5% today",
#     "Barcelona won the Champions League final",
#     "Python 3.12 introduces new features for developers",
# ]
#
# labels = ["shopping", "finance", "sports", "technology", "entertainment"]
#
# print(f'Categor√≠as disponibles: {labels}\n')
#
# for text in texts_to_classify:
#     result = zero_shot(text, candidate_labels=labels)
#     top_label = result['labels'][0]
#     top_score = result['scores'][0]
#     print(f'"{text[:50]}..."')
#     print(f'  ‚Üí {top_label} ({top_score:.2%})\n')

print()


# ============================================
# PASO 7: Comparaci√≥n de Modelos
# ============================================
print("--- Paso 7: Usar Modelos Espec√≠ficos ---")

# Puedes especificar qu√© modelo usar en cada pipeline

# Descomenta las siguientes l√≠neas:
# # Modelo multiling√ºe para sentimientos
# print('Cargando modelo multiling√ºe...')
# sentiment_multi = pipeline(
#     'sentiment-analysis',
#     model='nlptown/bert-base-multilingual-uncased-sentiment'
# )
#
# # Probar en diferentes idiomas
# texts_multi = [
#     "I love this product!",           # Ingl√©s
#     "¬°Me encanta este producto!",     # Espa√±ol
#     "J'adore ce produit!",            # Franc√©s
#     "Ich liebe dieses Produkt!",      # Alem√°n
# ]
#
# print('\nSentiment multiling√ºe:')
# for text in texts_multi:
#     result = sentiment_multi(text)
#     print(f'  {result[0]["label"]:8} | {text}')

print()
print("=" * 50)
print("¬°Ejercicio completado!")
print("Ahora sabes usar los pipelines de Hugging Face.")

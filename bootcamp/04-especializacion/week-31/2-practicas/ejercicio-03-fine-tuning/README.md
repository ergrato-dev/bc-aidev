# ğŸ”§ Ejercicio 03: Fine-tuning con LoRA

## ğŸ¯ Objetivo

Aprender a hacer fine-tuning eficiente usando LoRA y PEFT.

---

## ğŸ“‹ DescripciÃ³n

En este ejercicio configurarÃ¡s LoRA, prepararÃ¡s un dataset, y ejecutarÃ¡s un ciclo de entrenamiento bÃ¡sico.

---

## ğŸ”§ Requisitos

```bash
pip install transformers peft datasets accelerate bitsandbytes
```

**Nota**: Este ejercicio requiere GPU para entrenamiento real. En CPU solo veremos la configuraciÃ³n.

---

## ğŸ”§ Pasos del Ejercicio

### Paso 1: Cargar Modelo Base

Cargar un modelo pequeÃ±o para fine-tuning:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained("gpt2")
tokenizer = AutoTokenizer.from_pretrained("gpt2")
```

**Abre `starter/main.py`** y descomenta la secciÃ³n correspondiente.

### Paso 2: Configurar LoRA

Definir quÃ© capas adaptar:

```python
from peft import LoraConfig, get_peft_model

config = LoraConfig(
    r=8,
    lora_alpha=16,
    target_modules=["c_attn"],
    lora_dropout=0.05
)
model = get_peft_model(model, config)
```

### Paso 3: Preparar Dataset

Formatear datos para entrenamiento:

```python
def format_example(example):
    return f"### Instruction:\n{example['instruction']}\n\n### Response:\n{example['output']}"
```

### Paso 4: Configurar Training

Definir argumentos de entrenamiento:

```python
from transformers import TrainingArguments

args = TrainingArguments(
    output_dir="./lora-output",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    learning_rate=2e-4
)
```

### Paso 5: Entrenar

Ejecutar el entrenamiento:

```python
from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=dataset
)
trainer.train()
```

### Paso 6: Guardar y Cargar Adaptadores

Guardar solo los pesos LoRA:

```python
model.save_pretrained("./my-lora-adapter")
```

---

## ğŸ“ Estructura

```
ejercicio-03-fine-tuning/
â”œâ”€â”€ README.md
â””â”€â”€ starter/
    â””â”€â”€ main.py
```

---

## â–¶ï¸ EjecuciÃ³n

```bash
cd bootcamp/04-especializacion/week-31/2-practicas/ejercicio-03-fine-tuning
python starter/main.py
```

---

## âœ… Criterios de Ã‰xito

- [ ] Entiendo la configuraciÃ³n de LoRA
- [ ] SÃ© preparar un dataset para fine-tuning
- [ ] Comprendo los TrainingArguments principales
- [ ] Puedo guardar y cargar adaptadores
- [ ] Entiendo parÃ¡metros entrenables vs congelados

---

## ğŸ”— Recursos

- [PEFT Documentation](https://huggingface.co/docs/peft)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [TRL Library](https://huggingface.co/docs/trl)

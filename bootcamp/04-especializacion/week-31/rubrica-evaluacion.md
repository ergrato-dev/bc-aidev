# üìã R√∫brica de Evaluaci√≥n - Semana 31

## ü§ñ Large Language Models (LLMs)

---

## üìä Distribuci√≥n de Puntuaci√≥n

| Componente          | Porcentaje | Puntos |
| ------------------- | ---------- | ------ |
| üß† Conocimiento     | 30%        | 30 pts |
| üí™ Desempe√±o        | 40%        | 40 pts |
| üì¶ Producto         | 30%        | 30 pts |
| **Total**           | **100%**   | **100 pts** |

**Nota m√≠nima aprobatoria: 70 puntos**

---

## üß† Conocimiento (30 puntos)

### Conceptos Te√≥ricos

| Criterio | Excelente (10) | Bueno (7) | Suficiente (5) | Insuficiente (0-3) |
|----------|----------------|-----------|----------------|-------------------|
| **Arquitecturas LLM** | Explica diferencias entre GPT, BERT, T5, incluyendo pre-training objectives | Describe arquitecturas principales y sus usos | Conoce diferencias b√°sicas | No distingue arquitecturas |
| **Prompt Engineering** | Domina t√©cnicas avanzadas: few-shot, CoT, self-consistency | Aplica few-shot y zero-shot correctamente | Entiende prompts b√°sicos | No comprende prompting |
| **Fine-tuning** | Entiende PEFT, LoRA, QLoRA y cu√°ndo usar cada uno | Conoce fine-tuning tradicional y LoRA | Sabe qu√© es fine-tuning | No entiende fine-tuning |

---

## üí™ Desempe√±o (40 puntos)

### Ejercicios Pr√°cticos

#### Ejercicio 01: Prompt Engineering (12 pts)

| Criterio | Puntos | Descripci√≥n |
|----------|--------|-------------|
| Zero-shot prompts | 4 | Dise√±a prompts efectivos sin ejemplos |
| Few-shot prompts | 4 | Incluye ejemplos que mejoran resultados |
| Chain-of-Thought | 4 | Implementa razonamiento paso a paso |

#### Ejercicio 02: Generaci√≥n de Texto (14 pts)

| Criterio | Puntos | Descripci√≥n |
|----------|--------|-------------|
| Par√°metros de generaci√≥n | 5 | Configura temperature, top_p, top_k correctamente |
| Control de output | 5 | Maneja max_length, repetition_penalty |
| Comparaci√≥n de modelos | 4 | Eval√∫a diferentes modelos para la misma tarea |

#### Ejercicio 03: Fine-tuning con LoRA (14 pts)

| Criterio | Puntos | Descripci√≥n |
|----------|--------|-------------|
| Configuraci√≥n PEFT | 5 | Configura LoRA correctamente |
| Dataset preparation | 5 | Prepara datos en formato adecuado |
| Training loop | 4 | Ejecuta entrenamiento sin errores |

---

## üì¶ Producto (30 puntos)

### Proyecto: Asistente Especializado

| Criterio | Excelente (30) | Bueno (22) | Suficiente (15) | Insuficiente (0-10) |
|----------|----------------|------------|-----------------|---------------------|
| **Funcionalidad** | Asistente responde coherentemente en su dominio, mantiene personalidad, maneja edge cases | Respuestas coherentes, personalidad consistente | Funciona b√°sicamente pero inconsistente | No funciona o respuestas incoherentes |
| **Sistema de Prompts** | System prompt bien dise√±ado, few-shot examples, instrucciones claras | System prompt claro con instrucciones | Prompt b√°sico funcional | Sin sistema de prompts definido |
| **C√≥digo** | Limpio, documentado, modular, maneja errores | Organizado y funcional | Funciona pero desorganizado | C√≥digo dif√≠cil de entender |
| **Documentaci√≥n** | README completo, ejemplos de uso, limitaciones documentadas | Documentaci√≥n clara | Documentaci√≥n m√≠nima | Sin documentaci√≥n |

---

## ‚úÖ Checklist de Verificaci√≥n

### Conocimientos M√≠nimos
- [ ] Diferencio GPT (decoder) de BERT (encoder)
- [ ] Entiendo qu√© es el pre-training y por qu√© es importante
- [ ] S√© cu√°ndo usar zero-shot vs few-shot
- [ ] Comprendo el concepto de temperature en generaci√≥n
- [ ] Conozco la diferencia entre fine-tuning completo y LoRA

### Habilidades Pr√°cticas
- [ ] Puedo dise√±ar prompts para diferentes tareas
- [ ] Controlo par√°metros de generaci√≥n de texto
- [ ] Puedo configurar y entrenar con PEFT/LoRA
- [ ] S√© evaluar outputs de modelos generativos
- [ ] Manejo alucinaciones y respuestas problem√°ticas

### Proyecto
- [ ] Asistente responde en espa√±ol/ingl√©s seg√∫n contexto
- [ ] Sistema de prompts documentado
- [ ] Maneja preguntas fuera de dominio apropiadamente
- [ ] C√≥digo organizado y comentado

---

## üìù Ejemplos de Evaluaci√≥n

### Prompt Engineering - Excelente
```python
# System prompt bien estructurado
system_prompt = """Eres un asistente experto en Python.
Tu rol es ayudar a programadores a resolver problemas.

Reglas:
1. Responde SOLO sobre Python
2. Incluye ejemplos de c√≥digo cuando sea √∫til
3. Explica el razonamiento paso a paso
4. Si no sabes algo, dilo honestamente

Ejemplo de buena respuesta:
Usuario: ¬øC√≥mo itero un diccionario?
Asistente: Para iterar un diccionario en Python tienes varias opciones...
[c√≥digo de ejemplo]
"""
```

### Fine-tuning - Excelente
```python
# Configuraci√≥n LoRA apropiada
from peft import LoraConfig, get_peft_model

config = LoraConfig(
    r=16,                    # Rank de adaptaci√≥n
    lora_alpha=32,           # Scaling factor
    target_modules=["q_proj", "v_proj"],  # M√≥dulos a adaptar
    lora_dropout=0.05,       # Regularizaci√≥n
    bias="none",
    task_type="CAUSAL_LM"
)
```

---

## üéØ Niveles de Logro

| Nivel | Puntuaci√≥n | Descripci√≥n |
|-------|------------|-------------|
| üåü Sobresaliente | 90-100 | Domina LLMs, prompts avanzados, fine-tuning eficiente |
| ‚úÖ Aprobado | 70-89 | Comprende y aplica conceptos correctamente |
| ‚ö†Ô∏è En desarrollo | 50-69 | Necesita reforzar algunos conceptos |
| ‚ùå No aprobado | 0-49 | Requiere repetir el contenido |

---

## üìö Recursos de Apoyo

Si tienes dificultades:

1. **Prompt Engineering**: Revisa ejemplos en [Prompt Engineering Guide](https://www.promptingguide.ai/)
2. **Fine-tuning**: Sigue el tutorial de [Hugging Face PEFT](https://huggingface.co/docs/peft)
3. **Generaci√≥n**: Experimenta en [Hugging Face Spaces](https://huggingface.co/spaces)

---

## üîÑ Proceso de Entrega

1. Completa todos los ejercicios en `2-practicas/`
2. Desarrolla el proyecto en `3-proyecto/`
3. Verifica el checklist de esta r√∫brica
4. Sube tu c√≥digo al repositorio
5. Completa la autoevaluaci√≥n

---

_R√∫brica Semana 31 | M√≥dulo: Especializaci√≥n | Bootcamp IA: Zero to Hero_

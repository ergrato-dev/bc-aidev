# üìñ Glosario - Semana 32: RAG y Vector Databases

## A

### ANN (Approximate Nearest Neighbor)
Algoritmo que encuentra vecinos aproximados en lugar de exactos, sacrificando precisi√≥n por velocidad. Usado en b√∫squeda vectorial a gran escala.

## B

### BM25
Algoritmo de ranking basado en frecuencia de t√©rminos. Usado en b√∫squeda tradicional (keyword search) y complementa b√∫squeda sem√°ntica en sistemas h√≠bridos.

## C

### Chunk
Fragmento de un documento m√°s grande. En RAG, los documentos se dividen en chunks para indexar y recuperar porciones relevantes.

```python
def chunk_text(text: str, size: int = 300) -> list[str]:
    return [text[i:i+size] for i in range(0, len(text), size)]
```

### ChromaDB
Base de datos vectorial open source, embebida, dise√±ada para ser simple de usar con aplicaciones de IA.

### Contexto
Informaci√≥n recuperada que se proporciona al LLM junto con la pregunta del usuario para generar respuestas m√°s precisas.

### Cosine Similarity
M√©trica que mide la similitud entre dos vectores bas√°ndose en el √°ngulo entre ellos.

$$\text{cos}(\theta) = \frac{A \cdot B}{||A|| \times ||B||}$$

## D

### Dense Retrieval
B√∫squeda basada en embeddings densos (vectores de alta dimensionalidad). Contrasta con sparse retrieval (basado en t√©rminos).

### Distance Metrics
Funciones para medir distancia entre vectores:
- **L2 (Euclidean)**: Distancia directa
- **Cosine**: Basada en √°ngulo
- **Dot Product**: Producto punto

## E

### Embedding
Representaci√≥n vectorial densa de texto, im√°genes u otros datos. Captura significado sem√°ntico en un espacio vectorial.

```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')
embedding = model.encode("Hello world")  # shape: (384,)
```

### Embedding Model
Modelo que convierte texto a vectores. Ejemplos: all-MiniLM-L6-v2, OpenAI ada-002, Cohere embed.

## F

### Few-shot Learning
T√©cnica donde se proporcionan ejemplos en el prompt para guiar la respuesta del modelo.

## G

### Ground Truth
Respuestas correctas conocidas usadas para evaluar la calidad del sistema RAG.

### Grounding
Proceso de anclar las respuestas del LLM en informaci√≥n factual recuperada.

## H

### Hallucination
Cuando un LLM genera informaci√≥n incorrecta o inventada. RAG reduce este problema proporcionando contexto factual.

### HNSW (Hierarchical Navigable Small World)
Algoritmo de indexaci√≥n vectorial que organiza datos en una estructura de grafo jer√°rquico. Muy eficiente para b√∫squeda ANN.

### Hybrid Search
Combinaci√≥n de b√∫squeda sem√°ntica (vectores) con b√∫squeda por palabras clave (BM25) para mejores resultados.

## I

### Indexing
Proceso de almacenar embeddings en una estructura optimizada para b√∫squeda r√°pida.

### IVF (Inverted File Index)
T√©cnica de indexaci√≥n que agrupa vectores en clusters para acelerar la b√∫squeda.

## K

### K-Nearest Neighbors (KNN)
Algoritmo que encuentra los k vectores m√°s cercanos a una query.

## L

### Latent Space
Espacio vectorial donde los embeddings representan conceptos sem√°nticos. Puntos cercanos tienen significados similares.

### LLM (Large Language Model)
Modelo de lenguaje grande que genera texto. En RAG, el LLM usa el contexto recuperado para responder.

## M

### Metadata
Informaci√≥n adicional asociada a documentos (autor, fecha, categor√≠a). Permite filtrar resultados.

```python
collection.add(
    documents=["texto"],
    metadatas=[{"author": "Juan", "date": "2024"}]
)
```

### MTEB (Massive Text Embedding Benchmark)
Benchmark para evaluar modelos de embeddings en m√∫ltiples tareas.

## O

### Overlap
Solapamiento entre chunks consecutivos. Ayuda a mantener contexto en los bordes.

```python
chunk_size = 300
overlap = 50
# Chunks: [0:300], [250:550], [500:800]...
```

## P

### Pinecone
Base de datos vectorial cloud gestionada. Escalable y con caracter√≠sticas enterprise.

### Prompt Engineering
T√©cnica de dise√±ar prompts efectivos para obtener mejores respuestas del LLM.

### Prompt Augmentation
Proceso de enriquecer el prompt con contexto recuperado antes de enviarlo al LLM.

## Q

### Query
Texto de b√∫squeda del usuario que se convierte en embedding para buscar documentos similares.

### Qdrant
Base de datos vectorial escrita en Rust, conocida por su velocidad y eficiencia.

## R

### RAG (Retrieval Augmented Generation)
T√©cnica que combina recuperaci√≥n de informaci√≥n con generaci√≥n de texto para producir respuestas m√°s precisas y fundamentadas.

**Pipeline:**
1. Query ‚Üí Embedding
2. Vector Search ‚Üí Top-K Documents
3. Prompt + Context ‚Üí LLM
4. LLM ‚Üí Response

### Recall@K
M√©trica que mide qu√© proporci√≥n de documentos relevantes est√°n en los top-k resultados.

$$\text{Recall@K} = \frac{\text{Relevant in top-K}}{\text{Total Relevant}}$$

### Reranking
Proceso de reordenar resultados de b√∫squeda usando un modelo m√°s sofisticado despu√©s de la recuperaci√≥n inicial.

### Retriever
Componente que busca y recupera documentos relevantes de la base de conocimiento.

## S

### Semantic Search
B√∫squeda basada en significado en lugar de coincidencia exacta de palabras.

### Sentence Transformers
Biblioteca Python para generar embeddings de oraciones usando modelos transformer.

### Similarity Score
Puntuaci√≥n que indica qu√© tan similar es un documento a la query (0 a 1 t√≠picamente).

### Sparse Retrieval
B√∫squeda basada en vectores dispersos (ej. TF-IDF, BM25). Complementa dense retrieval.

## T

### Top-K
Los k documentos m√°s relevantes recuperados para una query.

### Transformer
Arquitectura de red neuronal base para modelos de embeddings y LLMs modernos.

## U

### Upsert
Operaci√≥n que inserta un documento si no existe, o lo actualiza si ya existe.

## V

### Vector Database
Base de datos especializada en almacenar y buscar embeddings de alta dimensionalidad.

**Caracter√≠sticas clave:**
- Indexaci√≥n eficiente (HNSW, IVF)
- B√∫squeda de similitud r√°pida
- Filtrado por metadata
- Escalabilidad

### Vector Index
Estructura de datos optimizada para b√∫squeda de similitud vectorial.

### Vector Space
Espacio matem√°tico donde cada documento est√° representado como un punto (vector).

## W

### Weaviate
Base de datos vectorial con soporte para b√∫squeda h√≠brida y m√≥dulos de ML integrados.

### Window Size
Tama√±o del contexto que el modelo puede procesar. Importante al dise√±ar chunks.

---

## üîó Referencias R√°pidas

| Concepto | F√≥rmula/C√≥digo |
|----------|----------------|
| Cosine Similarity | `np.dot(a,b) / (norm(a) * norm(b))` |
| Chunk Overlap | `overlap = chunk_size * 0.15` |
| Score from Distance | `score = 1 / (1 + distance)` |

---

## üîó Navegaci√≥n

| ‚¨ÖÔ∏è Teor√≠a | üè† Semana | Pr√°cticas ‚û°Ô∏è |
|-----------|-----------|--------------|
| [1-teoria](../1-teoria/) | [README](../README.md) | [2-practicas](../2-practicas/) |

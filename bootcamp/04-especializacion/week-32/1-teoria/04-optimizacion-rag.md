# ‚ö° Optimizaci√≥n de RAG

![Estrategias de Chunking](../0-assets/03-chunking-strategies.svg)

## üéØ Objetivos de Aprendizaje

- Dominar estrategias de chunking efectivas
- Implementar reranking para mejorar precisi√≥n
- Conocer t√©cnicas de hybrid search
- Evaluar y mejorar sistemas RAG

---

## üìã Contenido

### 1. Estrategias de Chunking

El **chunking** es crucial: chunks muy grandes pierden especificidad, muy peque√±os pierden contexto.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ESTRATEGIAS DE CHUNKING                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   FIXED SIZE                    SEMANTIC                        ‚îÇ
‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                        ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ   ‚îÇ 500 char ‚îÇ                  ‚îÇ P√°rrafo 1‚îÇ                    ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                    ‚îÇ
‚îÇ   ‚îÇ 500 char ‚îÇ                  ‚îÇ P√°rrafo 2‚îÇ ‚Üê Tama√±o variable  ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                  ‚îÇ          ‚îÇ                    ‚îÇ
‚îÇ   ‚îÇ 500 char ‚îÇ                  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                    ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ P√°rrafo 3‚îÇ                    ‚îÇ
‚îÇ                                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îÇ   ‚úÖ Simple                     ‚úÖ Preserva contexto            ‚îÇ
‚îÇ   ‚ùå Corta oraciones            ‚ùå Tama√±os irregulares          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Recursive Character Splitting

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", ". ", " ", ""],
    length_function=len
)

# Intenta dividir por p√°rrafos, luego l√≠neas, luego oraciones...
chunks = splitter.split_text(document)
```

#### Semantic Chunking

```python
from langchain_experimental.text_splitter import SemanticChunker
from langchain.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# Divide cuando el significado cambia significativamente
splitter = SemanticChunker(
    embeddings=embeddings,
    breakpoint_threshold_type="percentile",
    breakpoint_threshold_amount=95
)

chunks = splitter.split_text(document)
```

#### Chunking por Estructura

```python
# Para Markdown
from langchain.text_splitter import MarkdownTextSplitter

md_splitter = MarkdownTextSplitter(
    chunk_size=500,
    chunk_overlap=50
)

# Para c√≥digo
from langchain.text_splitter import Language, RecursiveCharacterTextSplitter

code_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.PYTHON,
    chunk_size=500,
    chunk_overlap=50
)
```

### 2. Overlap y Contexto

El **overlap** previene p√©rdida de informaci√≥n en los bordes:

```
Sin Overlap:
[Chunk 1: "El gato salt√≥ sobre"] [Chunk 2: "la cerca del jard√≠n"]
         ‚Üë Contexto perdido ‚Üë

Con Overlap (50 chars):
[Chunk 1: "El gato salt√≥ sobre la cerca"]
              [Chunk 2: "sobre la cerca del jard√≠n"]
                    ‚Üë Contexto preservado ‚Üë
```

### 3. Reranking

El **reranking** es un segundo paso que reordena resultados para mayor precisi√≥n:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PIPELINE CON RERANKING                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   Query ‚îÄ‚îÄ‚ñ∂ Vector Search ‚îÄ‚îÄ‚ñ∂ Top 20 ‚îÄ‚îÄ‚ñ∂ Reranker ‚îÄ‚îÄ‚ñ∂ Top 5    ‚îÇ
‚îÇ             (r√°pido, ~95%     docs       (lento,      docs     ‚îÇ
‚îÇ              precisi√≥n)                   ~99%                  ‚îÇ
‚îÇ                                           precisi√≥n)            ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```python
from sentence_transformers import CrossEncoder

# Modelo de reranking
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

def rerank_results(query: str, documents: list[str], top_k: int = 5):
    """Reordena documentos por relevancia."""
    # Crear pares (query, doc)
    pairs = [[query, doc] for doc in documents]
    
    # Calcular scores
    scores = reranker.predict(pairs)
    
    # Ordenar por score
    ranked = sorted(zip(documents, scores), key=lambda x: x[1], reverse=True)
    
    return ranked[:top_k]


# Uso
initial_results = vector_db.query(query, n_results=20)
reranked = rerank_results(query, initial_results['documents'][0], top_k=5)
```

### 4. Hybrid Search

Combina b√∫squeda **sem√°ntica** (vectores) con **keyword** (BM25):

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    HYBRID SEARCH                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ   Query: "error 404 en producci√≥n"                              ‚îÇ
‚îÇ                     ‚îÇ                                           ‚îÇ
‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ
‚îÇ          ‚ñº                   ‚ñº                                  ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                           ‚îÇ
‚îÇ   ‚îÇ   SEMANTIC  ‚îÇ     ‚îÇ   KEYWORD   ‚îÇ                           ‚îÇ
‚îÇ   ‚îÇ  (vectores) ‚îÇ     ‚îÇ   (BM25)    ‚îÇ                           ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                           ‚îÇ
‚îÇ          ‚îÇ                   ‚îÇ                                  ‚îÇ
‚îÇ   "problemas de     "error 404" literal                         ‚îÇ
‚îÇ    servidor"                                                    ‚îÇ
‚îÇ          ‚îÇ                   ‚îÇ                                  ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ
‚îÇ                    ‚ñº                                            ‚îÇ
‚îÇ            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                      ‚îÇ
‚îÇ            ‚îÇ   FUSI√ìN    ‚îÇ (RRF, weighted)                      ‚îÇ
‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                      ‚îÇ
‚îÇ                   ‚ñº                                             ‚îÇ
‚îÇ           Resultados combinados                                 ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

```python
from rank_bm25 import BM25Okapi

class HybridSearch:
    def __init__(self, documents: list[str], embeddings):
        self.documents = documents
        self.embeddings = embeddings
        
        # √çndice BM25
        tokenized = [doc.lower().split() for doc in documents]
        self.bm25 = BM25Okapi(tokenized)
        
        # Embeddings
        self.doc_embeddings = embeddings.encode(documents)
    
    def search(self, query: str, top_k: int = 5, alpha: float = 0.5):
        """
        B√∫squeda h√≠brida.
        alpha: peso para sem√°ntico (1-alpha para keyword)
        """
        # B√∫squeda sem√°ntica
        query_emb = self.embeddings.encode(query)
        semantic_scores = cosine_similarity([query_emb], self.doc_embeddings)[0]
        
        # B√∫squeda keyword
        keyword_scores = self.bm25.get_scores(query.lower().split())
        
        # Normalizar scores
        semantic_norm = (semantic_scores - semantic_scores.min()) / (semantic_scores.max() - semantic_scores.min() + 1e-6)
        keyword_norm = (keyword_scores - keyword_scores.min()) / (keyword_scores.max() - keyword_scores.min() + 1e-6)
        
        # Combinar
        combined = alpha * semantic_norm + (1 - alpha) * keyword_norm
        
        # Top-K
        top_indices = combined.argsort()[-top_k:][::-1]
        
        return [(self.documents[i], combined[i]) for i in top_indices]
```

### 5. Query Transformation

Mejorar la query antes de buscar:

```python
def expand_query(query: str, llm) -> list[str]:
    """Genera variaciones de la query."""
    prompt = f"""Genera 3 formas diferentes de preguntar lo mismo:
    
    Pregunta original: {query}
    
    Variaciones:"""
    
    response = llm.generate(prompt)
    variations = [query] + parse_variations(response)
    return variations


def hypothetical_document(query: str, llm) -> str:
    """HyDE: genera documento hipot√©tico para buscar."""
    prompt = f"""Escribe un p√°rrafo que responder√≠a esta pregunta:
    
    Pregunta: {query}
    
    Respuesta (p√°rrafo informativo):"""
    
    return llm.generate(prompt)
```

### 6. Evaluaci√≥n de RAG

```python
class RAGEvaluator:
    """Eval√∫a calidad del sistema RAG."""
    
    def __init__(self, rag_system):
        self.rag = rag_system
    
    def evaluate_retrieval(self, test_cases: list[dict]) -> dict:
        """
        Eval√∫a calidad del retrieval.
        test_cases: [{"query": "...", "relevant_docs": ["id1", "id2"]}]
        """
        metrics = {"recall@3": [], "precision@3": [], "mrr": []}
        
        for case in test_cases:
            retrieved = self.rag.retrieve(case["query"], k=3)
            retrieved_ids = [doc.id for doc in retrieved]
            relevant_ids = set(case["relevant_docs"])
            
            # Recall@K
            hits = len(set(retrieved_ids) & relevant_ids)
            recall = hits / len(relevant_ids)
            metrics["recall@3"].append(recall)
            
            # Precision@K
            precision = hits / len(retrieved_ids)
            metrics["precision@3"].append(precision)
            
            # MRR
            for i, doc_id in enumerate(retrieved_ids):
                if doc_id in relevant_ids:
                    metrics["mrr"].append(1 / (i + 1))
                    break
            else:
                metrics["mrr"].append(0)
        
        return {k: sum(v)/len(v) for k, v in metrics.items()}
```

### 7. Optimizaciones Pr√°cticas

| T√©cnica | Cu√°ndo usar | Impacto |
|---------|-------------|---------|
| Chunk overlap | Siempre | Preserva contexto |
| Reranking | Alta precisi√≥n cr√≠tica | +10-15% precisi√≥n |
| Hybrid search | Keywords importantes | Mejor para t√©rminos t√©cnicos |
| Query expansion | Queries ambiguas | Mejor recall |
| Caching embeddings | Queries repetidas | Menor latencia |

---

## üîë Puntos Clave

1. **Chunking** afecta enormemente la calidad
2. **Reranking** mejora precisi√≥n significativamente
3. **Hybrid search** combina lo mejor de ambos mundos
4. **Eval√∫a** antes de optimizar ciegamente

---

## ‚úÖ Checklist de Verificaci√≥n

- [ ] Entiendo las estrategias de chunking
- [ ] S√© implementar reranking
- [ ] Comprendo hybrid search
- [ ] Puedo evaluar un sistema RAG

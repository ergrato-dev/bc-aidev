#  Glosario - Semana 34: MLOps

T茅rminos clave de MLOps, APIs y deployment ordenados alfab茅ticamente.

---

## A

### API (Application Programming Interface)
Interfaz que permite la comunicaci贸n entre diferentes aplicaciones. En ML, las APIs exponen modelos para que otros sistemas puedan consumir predicciones.

### Artifact
Cualquier archivo o dato generado durante el ciclo de ML: modelos entrenados, datasets procesados, m茅tricas, logs.

---

## B

### Blue-Green Deployment
Estrategia de deployment donde se mantienen dos entornos id茅nticos (blue y green) para minimizar downtime durante actualizaciones.

### Build
Proceso de crear una imagen Docker a partir de un Dockerfile y el c贸digo fuente.

---

## C

### Canary Release
Estrategia de deployment gradual donde una nueva versi贸n se expone a un peque帽o porcentaje de usuarios antes del rollout completo.

### CI/CD (Continuous Integration/Continuous Deployment)
Pr谩cticas de automatizaci贸n para integrar c贸digo frecuentemente (CI) y desplegarlo autom谩ticamente (CD).

### Container
Unidad de software que empaqueta c贸digo y dependencias para ejecutarse de forma aislada y consistente.

### Counter (Prometheus)
Tipo de m茅trica que solo puede incrementar. til para contar requests, errores, predicciones.

---

## D

### Data Drift
Cambio en la distribuci贸n de los datos de entrada respecto a los datos de entrenamiento.

### Docker
Plataforma para desarrollar, enviar y ejecutar aplicaciones en contenedores.

### Docker Compose
Herramienta para definir y ejecutar aplicaciones multi-contenedor con un archivo YAML.

### Dockerfile
Archivo de texto con instrucciones para construir una imagen Docker.

---

## E

### Endpoint
URL espec铆fica de una API donde se pueden realizar operaciones. Ejemplo: `/api/v1/predict`.

### Environment Variables
Variables de configuraci贸n definidas fuera del c贸digo, usadas para configurar aplicaciones sin modificar c贸digo.

---

## F

### FastAPI
Framework moderno de Python para crear APIs, con validaci贸n autom谩tica y documentaci贸n OpenAPI.

### Feature Store
Sistema centralizado para almacenar, versionar y servir features de ML.

---

## G

### Gauge (Prometheus)
Tipo de m茅trica que puede subir o bajar. til para valores actuales como memoria usada o requests activos.

### Grafana
Plataforma de visualizaci贸n y monitoreo que se integra con m煤ltiples fuentes de datos como Prometheus.

---

## H

### Health Check
Endpoint que verifica si un servicio est谩 funcionando correctamente. Usado por orquestadores para detectar fallos.

### Histogram (Prometheus)
Tipo de m茅trica que muestrea observaciones y las cuenta en buckets configurables. til para latencias.

---

## I

### Image (Docker)
Template de solo lectura con instrucciones para crear un contenedor Docker.

### Inference
Proceso de usar un modelo entrenado para hacer predicciones sobre nuevos datos.

---

## K

### Kubernetes (K8s)
Plataforma de orquestaci贸n de contenedores para automatizar deployment, escalado y gesti贸n.

---

## L

### Latency
Tiempo que tarda una operaci贸n, como el tiempo de respuesta de una API o el tiempo de inferencia de un modelo.

### Liveness Probe
Verificaci贸n peri贸dica para determinar si un contenedor est谩 vivo. Si falla, el contenedor se reinicia.

### Load Balancer
Componente que distribuye tr谩fico entre m煤ltiples instancias de un servicio.

---

## M

### Metric
Medici贸n cuantitativa del comportamiento de un sistema. Ejemplo: requests por segundo, latencia, errores.

### MLOps
Conjunto de pr谩cticas para desplegar y mantener modelos de ML en producci贸n de manera confiable y eficiente.

### Model Registry
Sistema para versionar, almacenar y gestionar modelos de ML.

### Model Serving
Proceso de hacer disponible un modelo entrenado para realizar predicciones en producci贸n.

### Multi-stage Build
T茅cnica en Docker para crear im谩genes optimizadas usando m煤ltiples etapas de construcci贸n.

---

## O

### OpenAPI (Swagger)
Especificaci贸n para describir APIs REST. FastAPI genera documentaci贸n OpenAPI autom谩ticamente.

### Orchestration
Automatizaci贸n de la configuraci贸n, coordinaci贸n y gesti贸n de contenedores y servicios.

---

## P

### Pipeline
Secuencia automatizada de pasos para entrenar, validar y desplegar modelos de ML.

### Prometheus
Sistema de monitoreo y alertas de c贸digo abierto, dise帽ado para sistemas distribuidos.

### PromQL
Lenguaje de consultas de Prometheus para seleccionar y agregar datos de series temporales.

### Pydantic
Biblioteca de Python para validaci贸n de datos usando anotaciones de tipos.

---

## R

### Readiness Probe
Verificaci贸n para determinar si un contenedor est谩 listo para recibir tr谩fico.

### REST (Representational State Transfer)
Estilo arquitect贸nico para dise帽ar APIs web usando m茅todos HTTP est谩ndar.

### Rollback
Proceso de revertir a una versi贸n anterior de una aplicaci贸n o modelo cuando hay problemas.

---

## S

### Scaling
Ajustar la capacidad de un sistema. Horizontal: m谩s instancias. Vertical: m谩s recursos por instancia.

### Schema
Definici贸n de la estructura de datos esperada. En APIs, define el formato de requests y responses.

### Scraping (Prometheus)
Proceso donde Prometheus obtiene m茅tricas de los endpoints `/metrics` de los servicios.

### Service Discovery
Mecanismo para detectar autom谩ticamente servicios disponibles en una red.

---

## T

### Throughput
Cantidad de operaciones procesadas por unidad de tiempo. Ejemplo: predicciones por segundo.

---

## U

### Uvicorn
Servidor ASGI de alto rendimiento para aplicaciones Python como FastAPI.

---

## V

### Validation
Proceso de verificar que los datos cumplen con el esquema y reglas definidas antes de procesarlos.

### Volume (Docker)
Mecanismo para persistir datos generados por contenedores Docker.

---

## F贸rmulas y M茅tricas Comunes

### Disponibilidad (Availability)
$$\text{Availability} = \frac{\text{Uptime}}{\text{Uptime} + \text{Downtime}} \times 100\%$$

### Latencia Percentil
$$P_{99} = \text{Valor donde el 99\% de las requests son m谩s r谩pidas}$$

### Error Rate
$$\text{Error Rate} = \frac{\text{Requests Fallidos}}{\text{Total Requests}} \times 100\%$$

### Throughput
$$\text{Throughput} = \frac{\text{Requests Exitosos}}{\text{Tiempo}}$$

---

## PromQL Ejemplos

```promql
# Rate de requests por segundo (煤ltimos 5 min)
rate(ml_api_requests_total[5m])

# Latencia percentil 99
histogram_quantile(0.99, rate(ml_api_request_duration_seconds_bucket[5m]))

# Tasa de errores
sum(rate(ml_api_requests_total{status_code=~"5.."}[5m])) / sum(rate(ml_api_requests_total[5m]))

# Predicciones por clase
sum by (predicted_class) (rate(ml_model_predictions_total[1h]))
```

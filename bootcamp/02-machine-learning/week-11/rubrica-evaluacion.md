# üìä R√∫brica de Evaluaci√≥n - Semana 11

## √Årboles de Decisi√≥n y Random Forest

### Distribuci√≥n de Evidencias

| Tipo            | Porcentaje | Descripci√≥n                                |
| --------------- | ---------- | ------------------------------------------ |
| üß† Conocimiento | 30%        | Comprensi√≥n te√≥rica de √°rboles y ensambles |
| üí™ Desempe√±o    | 40%        | Ejercicios pr√°cticos completados           |
| üì¶ Producto     | 30%        | Proyecto clasificador de vinos             |

---

## üß† Conocimiento (30%)

### Conceptos Evaluados

| Concepto               | Peso | Criterio de Evaluaci√≥n              |
| ---------------------- | ---- | ----------------------------------- |
| Estructura de √°rboles  | 20%  | Explica nodos, hojas, profundidad   |
| Criterios de divisi√≥n  | 25%  | Diferencia Gini vs Entropy          |
| Overfitting en √°rboles | 20%  | Entiende poda y regularizaci√≥n      |
| Random Forest          | 25%  | Explica bagging y votaci√≥n          |
| Feature importance     | 10%  | Interpreta importancia de variables |

### Niveles de Desempe√±o

| Nivel        | Puntos | Descripci√≥n                            |
| ------------ | ------ | -------------------------------------- |
| Excelente    | 90-100 | Explica conceptos con ejemplos propios |
| Bueno        | 75-89  | Comprende y aplica correctamente       |
| Suficiente   | 60-74  | Conoce conceptos b√°sicos               |
| Insuficiente | <60    | No demuestra comprensi√≥n               |

---

## üí™ Desempe√±o (40%)

### Ejercicios Pr√°cticos

| Ejercicio              | Peso | Criterios                                  |
| ---------------------- | ---- | ------------------------------------------ |
| √Årbol de clasificaci√≥n | 25%  | Entrena, eval√∫a, visualiza √°rbol           |
| √Årbol de regresi√≥n     | 25%  | Aplica DecisionTreeRegressor correctamente |
| Random Forest          | 30%  | Implementa RF con par√°metros ajustados     |
| Feature importance     | 20%  | Extrae e interpreta importancias           |

### Criterios por Ejercicio

#### Ejercicio 01: √Årbol de Clasificaci√≥n

| Criterio                            | Puntos |
| ----------------------------------- | ------ |
| Carga y prepara datos correctamente | 20     |
| Entrena DecisionTreeClassifier      | 25     |
| Eval√∫a con m√©tricas apropiadas      | 25     |
| Visualiza el √°rbol                  | 20     |
| C√≥digo limpio y comentado           | 10     |

#### Ejercicio 02: √Årbol de Regresi√≥n

| Criterio                                     | Puntos |
| -------------------------------------------- | ------ |
| Usa DecisionTreeRegressor                    | 25     |
| Controla profundidad para evitar overfitting | 30     |
| Eval√∫a con R¬≤ y MAE                          | 25     |
| Compara diferentes profundidades             | 20     |

#### Ejercicio 03: Random Forest

| Criterio                          | Puntos |
| --------------------------------- | ------ |
| Implementa RandomForestClassifier | 25     |
| Ajusta n_estimators y max_depth   | 25     |
| Usa OOB score o cross-validation  | 25     |
| Compara con √°rbol individual      | 25     |

#### Ejercicio 04: Feature Importance

| Criterio                          | Puntos |
| --------------------------------- | ------ |
| Extrae feature*importances*       | 30     |
| Visualiza importancias en gr√°fico | 30     |
| Interpreta resultados             | 25     |
| Experimenta eliminando features   | 15     |

---

## üì¶ Producto (30%)

### Proyecto: Clasificador de Vinos

**Dataset**: Wine dataset (sklearn) - 3 clases, 13 features

| Criterio          | Peso | Descripci√≥n                      |
| ----------------- | ---- | -------------------------------- |
| **Funcionalidad** | 35%  | C√≥digo ejecuta sin errores       |
| **Rendimiento**   | 25%  | Accuracy ‚â• 0.92 en test          |
| **Metodolog√≠a**   | 20%  | Train/test split, CV para tuning |
| **An√°lisis**      | 15%  | Feature importance, conclusiones |
| **C√≥digo**        | 5%   | Limpio, documentado, modular     |

### Niveles de Rendimiento

| Accuracy Test | Calificaci√≥n     |
| ------------- | ---------------- |
| ‚â• 0.95        | Excelente (100%) |
| 0.92 - 0.94   | Bueno (85%)      |
| 0.88 - 0.91   | Suficiente (70%) |
| < 0.88        | Requiere mejora  |

### Checklist del Proyecto

```
‚ñ° EDA b√°sico del dataset
‚ñ° Train/test split (80/20)
‚ñ° Random Forest entrenado
‚ñ° GridSearchCV o RandomizedSearchCV para tuning
‚ñ° M√©tricas: accuracy, precision, recall, F1
‚ñ° Matriz de confusi√≥n
‚ñ° Feature importance visualizada
‚ñ° Comparaci√≥n con √°rbol individual
‚ñ° Conclusiones documentadas
```

---

## üìã Criterios Generales

### C√≥digo Python

| Aspecto          | Esperado                                 |
| ---------------- | ---------------------------------------- |
| Estilo           | PEP 8, nombres descriptivos              |
| Documentaci√≥n    | Docstrings en funciones                  |
| Imports          | Organizados (stdlib, third-party, local) |
| Reproducibilidad | random_state fijado                      |

### Visualizaciones

| Aspecto  | Esperado                          |
| -------- | --------------------------------- |
| Claridad | T√≠tulos, labels, leyendas         |
| Formato  | Figuras guardadas en PNG          |
| Estilo   | Tema consistente (dark preferido) |

---

## üéØ Calificaci√≥n Final

```
Nota Final = (Conocimiento √ó 0.30) + (Desempe√±o √ó 0.40) + (Producto √ó 0.30)
```

### Escala de Aprobaci√≥n

| Rango | Resultado     |
| ----- | ------------- |
| ‚â• 90  | Sobresaliente |
| 80-89 | Notable       |
| 70-79 | Aprobado      |
| 60-69 | Suficiente    |
| < 60  | No aprobado   |

**Nota m√≠nima para aprobar**: 70% en cada tipo de evidencia.

---

_R√∫brica Semana 11 | √Årboles de Decisi√≥n y Random Forest_

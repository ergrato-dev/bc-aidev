<svg viewBox="0 0 650 400" xmlns="http://www.w3.org/2000/svg">
  <!-- Background -->
  <rect width="650" height="400" fill="#1a1a2e"/>
  
  <!-- Title -->
  <text x="325" y="30" text-anchor="middle" fill="#E5E7EB" font-family="system-ui, sans-serif" font-size="20" font-weight="bold">Criterios de División: Gini vs Entropy</text>
  
  <!-- Left Panel: Gini -->
  <rect x="25" y="55" width="290" height="180" fill="#16213e" rx="10"/>
  <text x="170" y="80" text-anchor="middle" fill="#3B82F6" font-family="system-ui, sans-serif" font-size="16" font-weight="bold">Gini Impurity</text>
  
  <text x="170" y="110" text-anchor="middle" fill="#E5E7EB" font-family="system-ui, sans-serif" font-size="12">Gini = 1 - Σ pᵢ²</text>
  
  <text x="45" y="140" fill="#9CA3AF" font-family="system-ui, sans-serif" font-size="11">• Rango: [0, 0.5] para binario</text>
  <text x="45" y="160" fill="#9CA3AF" font-family="system-ui, sans-serif" font-size="11">• 0 = nodo puro (una sola clase)</text>
  <text x="45" y="180" fill="#9CA3AF" font-family="system-ui, sans-serif" font-size="11">• 0.5 = máxima impureza (50/50)</text>
  <text x="45" y="200" fill="#9CA3AF" font-family="system-ui, sans-serif" font-size="11">• Más rápido de calcular</text>
  <text x="45" y="220" fill="#10B981" font-family="system-ui, sans-serif" font-size="11">• Default en sklearn</text>
  
  <!-- Right Panel: Entropy -->
  <rect x="335" y="55" width="290" height="180" fill="#16213e" rx="10"/>
  <text x="480" y="80" text-anchor="middle" fill="#8B5CF6" font-family="system-ui, sans-serif" font-size="16" font-weight="bold">Entropy (Information Gain)</text>
  
  <text x="480" y="110" text-anchor="middle" fill="#E5E7EB" font-family="system-ui, sans-serif" font-size="12">Entropy = -Σ pᵢ log₂(pᵢ)</text>
  
  <text x="355" y="140" fill="#9CA3AF" font-family="system-ui, sans-serif" font-size="11">• Rango: [0, 1] para binario</text>
  <text x="355" y="160" fill="#9CA3AF" font-family="system-ui, sans-serif" font-size="11">• 0 = nodo puro</text>
  <text x="355" y="180" fill="#9CA3AF" font-family="system-ui, sans-serif" font-size="11">• 1 = máxima incertidumbre</text>
  <text x="355" y="200" fill="#9CA3AF" font-family="system-ui, sans-serif" font-size="11">• Basado en teoría de información</text>
  <text x="355" y="220" fill="#F59E0B" font-family="system-ui, sans-serif" font-size="11">• criterion='entropy' en sklearn</text>
  
  <!-- Example Section -->
  <rect x="25" y="250" width="600" height="135" fill="#16213e" rx="10"/>
  <text x="45" y="275" fill="#E5E7EB" font-family="system-ui, sans-serif" font-size="13" font-weight="bold">Ejemplo: Nodo con 60% clase A, 40% clase B</text>
  
  <!-- Gini Calculation -->
  <text x="45" y="305" fill="#3B82F6" font-family="system-ui, sans-serif" font-size="12" font-weight="bold">Gini:</text>
  <text x="95" y="305" fill="#E5E7EB" font-family="system-ui, sans-serif" font-size="11">1 - (0.6² + 0.4²) = 1 - (0.36 + 0.16) = 0.48</text>
  
  <!-- Entropy Calculation -->
  <text x="45" y="335" fill="#8B5CF6" font-family="system-ui, sans-serif" font-size="12" font-weight="bold">Entropy:</text>
  <text x="105" y="335" fill="#E5E7EB" font-family="system-ui, sans-serif" font-size="11">-(0.6·log₂(0.6) + 0.4·log₂(0.4)) ≈ 0.97</text>
  
  <!-- Information Gain -->
  <text x="45" y="365" fill="#10B981" font-family="system-ui, sans-serif" font-size="12" font-weight="bold">Information Gain:</text>
  <text x="175" y="365" fill="#E5E7EB" font-family="system-ui, sans-serif" font-size="11">IG = Entropy(padre) - Σ (nᵢ/N) · Entropy(hijoᵢ)</text>
</svg>
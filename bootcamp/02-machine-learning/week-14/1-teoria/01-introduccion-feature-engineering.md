# üîß Introducci√≥n a Feature Engineering

## üéØ Objetivos

- Comprender qu√© es Feature Engineering y su importancia
- Conocer el flujo de trabajo de preprocesamiento
- Entender el principio "Fit on Train, Transform on Both"

---

## üìã Contenido

### 1. ¬øQu√© es Feature Engineering?

**Feature Engineering** es el proceso de transformar datos crudos en caracter√≠sticas (features) que los algoritmos de Machine Learning pueden utilizar efectivamente.

> "Coming up with features is difficult, time-consuming, requires expert knowledge. Applied machine learning is basically feature engineering." ‚Äî Andrew Ng

```python
# Raw data (dif√≠cil para ML)
raw_data = {
    'fecha': '2024-03-15',
    'ciudad': 'Madrid',
    'temperatura': None,
    'ingresos': 50000
}

# Engineered features (listo para ML)
engineered = {
    'dia_semana': 4,           # Extra√≠do de fecha
    'es_fin_semana': 0,        # Derivado
    'ciudad_Madrid': 1,        # One-hot encoded
    'ciudad_Barcelona': 0,
    'temperatura': 18.5,       # Imputado
    'log_ingresos': 10.82      # Transformado
}
```

### 2. ¬øPor qu√© es Importante?

| Sin Feature Engineering          | Con Feature Engineering |
| -------------------------------- | ----------------------- |
| Valores faltantes causan errores | Datos completos         |
| Categor√≠as como texto            | Todo num√©rico           |
| Escalas muy diferentes           | Escalas normalizadas    |
| Features irrelevantes            | Features seleccionadas  |
| Distribuciones sesgadas          | Distribuciones normales |

### 3. Pipeline de Feature Engineering

![Feature Engineering Overview](../0-assets/01-feature-engineering-overview.svg)

```
Raw Data ‚Üí Handle Missing ‚Üí Encode Categories ‚Üí Scale/Transform ‚Üí Select Features ‚Üí ML Model
```

**Orden t√≠pico de operaciones:**

1. **Manejo de valores faltantes** - Imputation
2. **Codificaci√≥n de categ√≥ricas** - Encoding
3. **Escalado/Normalizaci√≥n** - Scaling
4. **Transformaciones** - Power transforms
5. **Selecci√≥n de caracter√≠sticas** - Feature selection

### 4. Principio Fundamental: Fit on Train

‚ö†Ô∏è **REGLA DE ORO**: Siempre ajustar (fit) los transformadores SOLO en datos de entrenamiento.

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split primero
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# ‚úÖ CORRECTO: fit solo en train
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)  # Solo transform

# ‚ùå INCORRECTO: fit en todo el dataset (DATA LEAKAGE!)
scaler_bad = StandardScaler()
X_all_scaled = scaler_bad.fit_transform(X)  # NUNCA hacer esto
```

**¬øPor qu√©?**

- Si hacemos fit en todo el dataset, el scaler "ve" informaci√≥n del test set
- Esto es **data leakage**: informaci√≥n del futuro contamina el entrenamiento
- El modelo parecer√° mejor de lo que realmente es

### 5. Tipos de Features

| Tipo                      | Descripci√≥n         | Ejemplo                       |
| ------------------------- | ------------------- | ----------------------------- |
| **Num√©ricas continuas**   | Valores en un rango | Edad, salario, temperatura    |
| **Num√©ricas discretas**   | Valores contables   | N√∫mero de hijos, habitaciones |
| **Categ√≥ricas nominales** | Sin orden           | Color, ciudad, g√©nero         |
| **Categ√≥ricas ordinales** | Con orden           | Educaci√≥n (bajo/medio/alto)   |
| **Datetime**              | Fechas y tiempos    | Fecha de compra               |
| **Texto**                 | Strings libres      | Comentarios, descripciones    |

### 6. Herramientas en sklearn

```python
# Preprocesamiento
from sklearn.preprocessing import (
    StandardScaler,      # Escalado est√°ndar
    MinMaxScaler,        # Escalado 0-1
    RobustScaler,        # Robusto a outliers
    OneHotEncoder,       # Codificaci√≥n one-hot
    OrdinalEncoder,      # Codificaci√≥n ordinal
    LabelEncoder,        # Para target (clasificaci√≥n)
    PowerTransformer,    # Box-Cox, Yeo-Johnson
)

# Imputaci√≥n
from sklearn.impute import (
    SimpleImputer,       # Media, mediana, moda
    KNNImputer,          # Basado en vecinos
)

# Selecci√≥n de features
from sklearn.feature_selection import (
    SelectKBest,         # Top K features
    RFE,                 # Recursive Feature Elimination
    SelectFromModel,     # Basado en importancias
)

# Pipelines
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
```

---

## üìö Recursos Adicionales

- [sklearn Preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)
- [Feature Engineering Book (Free)](https://www.feat.engineering/)

---

## ‚úÖ Checklist de Verificaci√≥n

- [ ] Entiendo qu√© es Feature Engineering
- [ ] Comprendo el principio "Fit on Train"
- [ ] Conozco los tipos de features
- [ ] S√© qu√© herramientas ofrece sklearn

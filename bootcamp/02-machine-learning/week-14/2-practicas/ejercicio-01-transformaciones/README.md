# ğŸ“Š Ejercicio 01: Transformaciones NumÃ©ricas

## ğŸ¯ Objetivo

Practicar el uso de StandardScaler, MinMaxScaler, RobustScaler y PowerTransformer para escalar y transformar variables numÃ©ricas.

## ğŸ“‹ Instrucciones

En este ejercicio aprenderÃ¡s a:

1. Comparar diferentes escaladores
2. Manejar outliers con RobustScaler
3. Normalizar distribuciones sesgadas
4. Visualizar el efecto de cada transformaciÃ³n

## ğŸ“ Archivos

```
ejercicio-01-transformaciones/
â”œâ”€â”€ README.md          # Este archivo
â””â”€â”€ starter/
    â””â”€â”€ main.py        # CÃ³digo para completar
```

## â±ï¸ Tiempo Estimado

30 minutos

## ğŸš€ Pasos

### Paso 1: Crear Datos de Ejemplo

Creamos un dataset con diferentes caracterÃ­sticas para ver cÃ³mo afectan los escaladores.

**Abre `starter/main.py`** y descomenta la secciÃ³n del Paso 1.

### Paso 2: Aplicar StandardScaler

El StandardScaler centra los datos con media 0 y desviaciÃ³n estÃ¡ndar 1.

### Paso 3: Aplicar MinMaxScaler

El MinMaxScaler escala los datos al rango [0, 1].

### Paso 4: Aplicar RobustScaler

El RobustScaler usa la mediana y el IQR, siendo robusto a outliers.

### Paso 5: Comparar Escaladores Visualmente

Visualizamos las distribuciones antes y despuÃ©s de escalar.

### Paso 6: PowerTransformer para Distribuciones Sesgadas

Aplicamos Box-Cox o Yeo-Johnson para normalizar distribuciones.

### Paso 7: Principio Fit on Train

Demostramos por quÃ© es crucial ajustar solo en datos de entrenamiento.

## âœ… Criterios de Ã‰xito

- [ ] Los datos escalados con StandardScaler tienen media â‰ˆ 0 y std â‰ˆ 1
- [ ] Los datos con MinMaxScaler estÃ¡n en rango [0, 1]
- [ ] RobustScaler maneja mejor los outliers
- [ ] PowerTransformer reduce el sesgo de la distribuciÃ³n
- [ ] Aplicas fit solo en train y transform en ambos

# Comparaci√≥n de Algoritmos: KNN vs SVM vs Naive Bayes

## üéØ Objetivos

- Comparar caracter√≠sticas de los tres algoritmos
- Saber cu√°ndo usar cada uno
- Implementar comparaci√≥n pr√°ctica
- Tomar decisiones informadas de selecci√≥n de modelo

## üìã Contenido

### 1. Tabla Comparativa

![Comparaci√≥n Algoritmos](../0-assets/05-comparacion-algoritmos.svg)

| Criterio           | KNN            | SVM            | Naive Bayes       |
| ------------------ | -------------- | -------------- | ----------------- |
| **Tipo**           | Instance-based | Margin-based   | Probabil√≠stico    |
| **Entrenamiento**  | Ninguno (lazy) | Lento O(n¬≤-n¬≥) | Muy r√°pido O(n)   |
| **Predicci√≥n**     | Lento O(n)     | R√°pido         | Muy r√°pido        |
| **Memoria**        | Guarda todo    | Solo SVs       | Solo par√°metros   |
| **No lineal**      | Natural        | Con kernels    | No (asume lineal) |
| **Interpretable**  | Moderado       | Bajo           | Alto              |
| **Probabilidades** | No nativo      | Con overhead   | Nativo            |

### 2. Cu√°ndo Usar Cada Algoritmo

#### KNN es mejor cuando:

- Dataset peque√±o (< 10k muestras)
- Necesitas un baseline r√°pido
- Los datos tienen estructura local
- No hay muchas features

```python
# Buen caso para KNN: datos peque√±os, pocas features
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=5)
```

#### SVM es mejor cuando:

- Alta dimensionalidad (muchas features)
- Hay margen claro entre clases
- Necesitas alto rendimiento
- Datos no son linealmente separables (usar RBF)

```python
# Buen caso para SVM: alta dimensionalidad
from sklearn.svm import SVC
svm = SVC(kernel='rbf', C=1.0, gamma='scale')
```

#### Naive Bayes es mejor cuando:

- Clasificaci√≥n de texto
- Necesitas probabilidades
- Dataset muy grande
- Entrenamiento/predicci√≥n debe ser r√°pido

```python
# Buen caso para NB: clasificaci√≥n de texto
from sklearn.naive_bayes import MultinomialNB
nb = MultinomialNB(alpha=0.1)
```

### 3. Comparaci√≥n Pr√°ctica

```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
import time
import numpy as np

# Cargar datos
cancer = load_breast_cancer()
X, y = cancer.data, cancer.target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Definir modelos
models = {
    'KNN': Pipeline([
        ('scaler', StandardScaler()),
        ('clf', KNeighborsClassifier(n_neighbors=5))
    ]),
    'SVM (RBF)': Pipeline([
        ('scaler', StandardScaler()),
        ('clf', SVC(kernel='rbf', gamma='scale'))
    ]),
    'SVM (Linear)': Pipeline([
        ('scaler', StandardScaler()),
        ('clf', SVC(kernel='linear'))
    ]),
    'Naive Bayes': GaussianNB()
}

# Comparar
results = []

for name, model in models.items():
    # Cross-validation
    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')

    # Tiempo de entrenamiento
    start = time.time()
    model.fit(X_train, y_train)
    train_time = time.time() - start

    # Tiempo de predicci√≥n
    start = time.time()
    y_pred = model.predict(X_test)
    pred_time = time.time() - start

    # Test accuracy
    test_acc = model.score(X_test, y_test)

    results.append({
        'Model': name,
        'CV Mean': cv_scores.mean(),
        'CV Std': cv_scores.std(),
        'Test Acc': test_acc,
        'Train Time': train_time,
        'Pred Time': pred_time
    })

# Mostrar resultados
import pandas as pd
df = pd.DataFrame(results)
print(df.to_string(index=False))
```

### 4. An√°lisis por Tipo de Problema

#### Clasificaci√≥n Binaria

| Problema           | Recomendaci√≥n               |
| ------------------ | --------------------------- |
| Spam detection     | Naive Bayes (MultinomialNB) |
| Medical diagnosis  | SVM (RBF) con GridSearch    |
| Credit scoring     | SVM o ensemble              |
| Sentiment analysis | Naive Bayes o SVM linear    |

#### Clasificaci√≥n Multiclase

| Problema                | Recomendaci√≥n                  |
| ----------------------- | ------------------------------ |
| Image classification    | SVM (RBF)                      |
| Document categorization | Naive Bayes                    |
| Species classification  | KNN (si dataset peque√±o) o SVM |

### 5. Consideraciones de Escalabilidad

```python
# Datos de ejemplo para testing de escalabilidad
from sklearn.datasets import make_classification

# Dataset peque√±o (1k samples)
X_small, y_small = make_classification(n_samples=1000, n_features=20, random_state=42)

# Dataset grande (100k samples)
X_large, y_large = make_classification(n_samples=100000, n_features=20, random_state=42)
```

| Dataset       | KNN                    | SVM            | Naive Bayes     |
| ------------- | ---------------------- | -------------- | --------------- |
| 1k samples    | ‚úÖ R√°pido              | ‚úÖ R√°pido      | ‚úÖ Instant√°neo  |
| 10k samples   | ‚ö†Ô∏è Lento en predicci√≥n | ‚ö†Ô∏è Lento train | ‚úÖ R√°pido       |
| 100k+ samples | ‚ùå Muy lento           | ‚ùå Muy lento   | ‚úÖ Sigue r√°pido |

### 6. Pipeline de Selecci√≥n de Modelo

```python
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
import warnings
warnings.filterwarnings('ignore')

def compare_models(X_train, X_test, y_train, y_test):
    """
    Compara KNN, SVM y Naive Bayes con tuning b√°sico.
    """

    # KNN con b√∫squeda de k
    knn_params = {'clf__n_neighbors': [3, 5, 7, 9]}
    knn_pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('clf', KNeighborsClassifier())
    ])
    knn_grid = GridSearchCV(knn_pipe, knn_params, cv=5, n_jobs=-1)

    # SVM con b√∫squeda de C y kernel
    svm_params = {
        'clf__C': [0.1, 1, 10],
        'clf__kernel': ['rbf', 'linear']
    }
    svm_pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('clf', SVC())
    ])
    svm_grid = GridSearchCV(svm_pipe, svm_params, cv=5, n_jobs=-1)

    # Naive Bayes (no necesita mucho tuning)
    nb = GaussianNB()

    # Entrenar y evaluar
    results = {}

    for name, model in [('KNN', knn_grid), ('SVM', svm_grid), ('NB', nb)]:
        model.fit(X_train, y_train)
        test_acc = model.score(X_test, y_test)

        if hasattr(model, 'best_params_'):
            print(f"{name} best params: {model.best_params_}")

        results[name] = test_acc
        print(f"{name} Test Accuracy: {test_acc:.4f}")

    # Mejor modelo
    best = max(results, key=results.get)
    print(f"\nüèÜ Mejor modelo: {best} ({results[best]:.4f})")

    return results

# Usar la funci√≥n
results = compare_models(X_train, X_test, y_train, y_test)
```

### 7. Gu√≠a de Decisi√≥n R√°pida

```
¬øEs clasificaci√≥n de texto?
‚îú‚îÄ‚îÄ S√ç ‚Üí Naive Bayes (MultinomialNB)
‚îî‚îÄ‚îÄ NO ‚Üí ¬øDataset > 10k muestras?
    ‚îú‚îÄ‚îÄ S√ç ‚Üí ¬øNecesitas probabilidades?
    ‚îÇ   ‚îú‚îÄ‚îÄ S√ç ‚Üí Naive Bayes (si features independientes) o SVM + probability=True
    ‚îÇ   ‚îî‚îÄ‚îÄ NO ‚Üí SVM con kernel RBF
    ‚îî‚îÄ‚îÄ NO ‚Üí ¬øFeatures > 100?
        ‚îú‚îÄ‚îÄ S√ç ‚Üí SVM (linear o RBF)
        ‚îî‚îÄ‚îÄ NO ‚Üí KNN o cualquiera de los 3
```

### 8. Resumen de Hiperpar√°metros

| Algoritmo | Hiperpar√°metros Clave        | Valores T√≠picos             |
| --------- | ---------------------------- | --------------------------- |
| **KNN**   | n_neighbors, weights, metric | k=5, 'uniform', 'euclidean' |
| **SVM**   | C, kernel, gamma             | C=1, 'rbf', 'scale'         |
| **NB**    | alpha (suavizado)            | 1.0 (Laplace)               |

---

## ‚úÖ Checklist de Verificaci√≥n

- [ ] Conozco las fortalezas y debilidades de cada algoritmo
- [ ] S√© cu√°ndo usar KNN, SVM o Naive Bayes
- [ ] Puedo implementar comparaci√≥n pr√°ctica
- [ ] Entiendo consideraciones de escalabilidad
- [ ] Puedo tomar decisiones informadas de selecci√≥n

---

## üìö Recursos

- [Choosing the right estimator - sklearn](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)
- [Model Selection - sklearn](https://scikit-learn.org/stable/model_selection.html)
- [Comparing Classifiers](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)

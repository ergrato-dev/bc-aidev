# üìä Ejercicio 04: Evaluaci√≥n de Clustering

## üéØ Objetivo

Aprender a evaluar y comparar algoritmos de clustering utilizando m√©tricas internas (sin ground truth) y externas (con ground truth).

---

## üìã Descripci√≥n

Evaluar clustering es m√°s complejo que evaluar clasificaci√≥n supervisada porque a menudo no tenemos etiquetas "correctas". En este ejercicio aprender√°s:

- ‚úÖ M√©tricas internas: Silhouette, Davies-Bouldin, Calinski-Harabasz
- ‚úÖ M√©tricas externas: ARI, NMI, Homogeneity, Completeness
- ‚úÖ C√≥mo elegir el n√∫mero √≥ptimo de clusters
- ‚úÖ Comparar algoritmos de forma objetiva

---

## üìö Conceptos Clave

### M√©tricas Internas (Sin Ground Truth)

| M√©trica               | Rango   | Mejor | Qu√© mide                       |
| --------------------- | ------- | ----- | ------------------------------ |
| **Silhouette**        | [-1, 1] | Mayor | Cohesi√≥n vs separaci√≥n         |
| **Davies-Bouldin**    | [0, ‚àû)  | Menor | Ratio de dispersi√≥n/separaci√≥n |
| **Calinski-Harabasz** | [0, ‚àû)  | Mayor | Varianza inter/intra cluster   |

### M√©tricas Externas (Con Ground Truth)

| M√©trica                    | Rango   | Mejor | Qu√© mide                             |
| -------------------------- | ------- | ----- | ------------------------------------ |
| **Adjusted Rand Index**    | [-1, 1] | Mayor | Concordancia de pares ajustada       |
| **Normalized Mutual Info** | [0, 1]  | Mayor | Informaci√≥n mutua normalizada        |
| **Homogeneity**            | [0, 1]  | Mayor | Cada cluster contiene solo una clase |
| **Completeness**           | [0, 1]  | Mayor | Todos de una clase est√°n juntos      |

---

## üîÑ Pasos del Ejercicio

### Paso 1: Calcular Silhouette Score

```python
from sklearn.metrics import silhouette_score, silhouette_samples

# Score global
score = silhouette_score(X, labels)

# Score por muestra (para visualizaci√≥n)
sample_scores = silhouette_samples(X, labels)
```

### Paso 2: Silhouette Plot

```python
def silhouette_plot(X, labels):
    """
    Visualize silhouette score per sample and cluster.
    """
    sample_scores = silhouette_samples(X, labels)
    n_clusters = len(np.unique(labels))

    y_lower = 10
    for i in range(n_clusters):
        cluster_scores = sample_scores[labels == i]
        cluster_scores.sort()

        y_upper = y_lower + len(cluster_scores)
        plt.fill_betweenx(np.arange(y_lower, y_upper),
                          0, cluster_scores)
        y_lower = y_upper + 10
```

### Paso 3: Encontrar K √ìptimo

```python
# Probar diferentes K
silhouette_scores = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k)
    labels = kmeans.fit_predict(X)
    score = silhouette_score(X, labels)
    silhouette_scores.append(score)

# El K con mayor silhouette es el √≥ptimo
```

### Paso 4: Davies-Bouldin Index

```python
from sklearn.metrics import davies_bouldin_score

dbi = davies_bouldin_score(X, labels)
# Menor es mejor
```

### Paso 5: M√©tricas Externas

```python
from sklearn.metrics import (
    adjusted_rand_score,
    normalized_mutual_info_score,
    homogeneity_score,
    completeness_score,
    v_measure_score
)

# Comparar con etiquetas reales
ari = adjusted_rand_score(y_true, y_pred)
nmi = normalized_mutual_info_score(y_true, y_pred)
homo = homogeneity_score(y_true, y_pred)
comp = completeness_score(y_true, y_pred)
```

### Paso 6: Comparar Algoritmos

```python
algorithms = [
    ('K-Means', KMeans(n_clusters=4)),
    ('DBSCAN', DBSCAN(eps=0.5, min_samples=5)),
    ('Hierarchical', AgglomerativeClustering(n_clusters=4))
]

for name, algo in algorithms:
    labels = algo.fit_predict(X)
    sil = silhouette_score(X, labels)
    dbi = davies_bouldin_score(X, labels)
    print(f"{name}: Silhouette={sil:.3f}, DBI={dbi:.3f}")
```

---

## üìÅ Estructura del Ejercicio

```
ejercicio-04-evaluacion/
‚îú‚îÄ‚îÄ README.md              # Este archivo
‚îî‚îÄ‚îÄ starter/
    ‚îî‚îÄ‚îÄ main.py            # C√≥digo a completar
```

---

## ‚úÖ Criterios de √âxito

- [ ] Calcular e interpretar silhouette score
- [ ] Crear silhouette plots por cluster
- [ ] Usar m√©todo del silhouette para encontrar K √≥ptimo
- [ ] Aplicar Davies-Bouldin y Calinski-Harabasz
- [ ] Evaluar con m√©tricas externas cuando hay ground truth
- [ ] Comparar algoritmos de forma objetiva

---

## üéØ Resultado Esperado

Al ejecutar el c√≥digo completo deber√≠as ver:

- Gr√°ficos de silhouette mostrando calidad de clusters
- Curvas de m√©tricas para diferentes valores de K
- Tabla comparativa de algoritmos
- Visualizaci√≥n de clusters buenos vs malos

---

## üìö Recursos

- [Sklearn Clustering Metrics](https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation)
- [Silhouette Analysis](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)
- [Comparing Clustering Algorithms](https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation)

---

## ‚è±Ô∏è Tiempo Estimado

- **Total**: 50 minutos
- Por paso:
  - Pasos 1-2: 15 min
  - Pasos 3-4: 15 min
  - Pasos 5-6: 20 min

---

## üîó Navegaci√≥n

| ‚¨ÖÔ∏è Anterior                                             | üè† Ejercicios    | Siguiente ‚û°Ô∏è                  |
| ------------------------------------------------------- | ---------------- | ----------------------------- |
| [Ejercicio 03: Jer√°rquico](../ejercicio-03-jerarquico/) | [Pr√°cticas](../) | [Proyecto](../../3-proyecto/) |

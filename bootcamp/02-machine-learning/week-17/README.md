# ğŸ“‰ Semana 17: ReducciÃ³n de Dimensionalidad

## ğŸ¯ Objetivos de Aprendizaje

Al finalizar esta semana, serÃ¡s capaz de:

- âœ… Comprender el problema de la maldiciÃ³n de la dimensionalidad
- âœ… Implementar PCA (AnÃ¡lisis de Componentes Principales)
- âœ… Aplicar t-SNE para visualizaciÃ³n de datos de alta dimensiÃ³n
- âœ… Usar UMAP como alternativa moderna a t-SNE
- âœ… Seleccionar el nÃºmero Ã³ptimo de componentes
- âœ… Combinar reducciÃ³n dimensional con otros algoritmos de ML

---

## ğŸ“š Requisitos Previos

- Ãlgebra lineal bÃ¡sica (vectores, matrices, autovalores)
- EstadÃ­stica descriptiva (varianza, covarianza)
- Scikit-learn bÃ¡sico
- Clustering (semana 16)

---

## ğŸ—‚ï¸ Estructura de la Semana

```
week-17/
â”œâ”€â”€ README.md
â”œâ”€â”€ rubrica-evaluacion.md
â”œâ”€â”€ 0-assets/
â”‚   â”œâ”€â”€ 01-curse-dimensionality.svg
â”‚   â”œâ”€â”€ 02-pca-concept.svg
â”‚   â”œâ”€â”€ 03-tsne-visualization.svg
â”‚   â””â”€â”€ 04-comparison-techniques.svg
â”œâ”€â”€ 1-teoria/
â”‚   â”œâ”€â”€ 01-intro-reduccion-dimensional.md
â”‚   â”œâ”€â”€ 02-pca.md
â”‚   â”œâ”€â”€ 03-tsne.md
â”‚   â””â”€â”€ 04-umap-comparacion.md
â”œâ”€â”€ 2-practicas/
â”‚   â”œâ”€â”€ ejercicio-01-pca/
â”‚   â”œâ”€â”€ ejercicio-02-tsne/
â”‚   â”œâ”€â”€ ejercicio-03-umap/
â”‚   â””â”€â”€ ejercicio-04-pipeline-completo/
â”œâ”€â”€ 3-proyecto/
â”‚   â””â”€â”€ visualizacion-mnist/
â”œâ”€â”€ 4-recursos/
â”‚   â””â”€â”€ README.md
â””â”€â”€ 5-glosario/
    â””â”€â”€ README.md
```

---

## ğŸ“ Contenidos

### ğŸ“– TeorÃ­a (1.5 horas)

| # | Tema | Archivo | DuraciÃ³n |
|---|------|---------|----------|
| 1 | IntroducciÃ³n y MaldiciÃ³n de Dimensionalidad | [01-intro-reduccion-dimensional.md](1-teoria/01-intro-reduccion-dimensional.md) | 20 min |
| 2 | PCA: AnÃ¡lisis de Componentes Principales | [02-pca.md](1-teoria/02-pca.md) | 30 min |
| 3 | t-SNE: VisualizaciÃ³n No Lineal | [03-tsne.md](1-teoria/03-tsne.md) | 20 min |
| 4 | UMAP y ComparaciÃ³n de TÃ©cnicas | [04-umap-comparacion.md](1-teoria/04-umap-comparacion.md) | 20 min |

### ğŸ’» PrÃ¡cticas (2.5 horas)

| # | Ejercicio | Carpeta | DuraciÃ³n |
|---|-----------|---------|----------|
| 1 | PCA desde Cero y Sklearn | [ejercicio-01-pca/](2-practicas/ejercicio-01-pca/) | 40 min |
| 2 | t-SNE para VisualizaciÃ³n | [ejercicio-02-tsne/](2-practicas/ejercicio-02-tsne/) | 35 min |
| 3 | UMAP y Comparaciones | [ejercicio-03-umap/](2-practicas/ejercicio-03-umap/) | 35 min |
| 4 | Pipeline Completo | [ejercicio-04-pipeline-completo/](2-practicas/ejercicio-04-pipeline-completo/) | 40 min |

### ğŸ¯ Proyecto (2 horas)

| Proyecto | DescripciÃ³n | Carpeta |
|----------|-------------|---------|
| VisualizaciÃ³n MNIST | Visualizar y clasificar dÃ­gitos con reducciÃ³n dimensional | [visualizacion-mnist/](3-proyecto/visualizacion-mnist/) |

---

## â±ï¸ DistribuciÃ³n del Tiempo

```
Total: 6 horas

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“– TeorÃ­a       â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  1.5h (25%)    â”‚
â”‚  ğŸ’» PrÃ¡cticas    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  2.5h (42%)    â”‚
â”‚  ğŸ¯ Proyecto     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  2.0h (33%)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Œ Entregables

1. **Ejercicios Completados**
   - [ ] PCA implementado desde cero y con sklearn
   - [ ] Visualizaciones t-SNE funcionando
   - [ ] ComparaciÃ³n UMAP vs t-SNE
   - [ ] Pipeline completo de reducciÃ³n + clasificaciÃ³n

2. **Proyecto Semanal**
   - [ ] VisualizaciÃ³n de MNIST con mÃºltiples tÃ©cnicas
   - [ ] AnÃ¡lisis de varianza explicada
   - [ ] ComparaciÃ³n de rendimiento en clasificaciÃ³n

---

## ğŸ§  Conceptos Clave

### TÃ©cnicas Lineales
- **PCA**: Maximiza varianza, proyecciÃ³n lineal, componentes ortogonales
- **LDA**: Maximiza separabilidad entre clases (supervisado)

### TÃ©cnicas No Lineales
- **t-SNE**: Preserva estructura local, bueno para visualizaciÃ³n
- **UMAP**: MÃ¡s rÃ¡pido que t-SNE, preserva estructura global

### MÃ©tricas
- Varianza explicada (PCA)
- PreservaciÃ³n de vecindarios (t-SNE/UMAP)
- Trustworthiness y continuity

---

## ğŸ”— NavegaciÃ³n

| â¬…ï¸ Anterior | ğŸ  MÃ³dulo | Siguiente â¡ï¸ |
|-------------|-----------|--------------|
| [Semana 16: Clustering](../week-16/README.md) | [MÃ³dulo 2: ML](../README.md) | [Semana 18: ML en ProducciÃ³n](../week-18/README.md) |

---

_Semana 17 de 36 | MÃ³dulo: Machine Learning | Bootcamp IA: Zero to Hero_

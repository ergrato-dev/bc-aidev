# âš™ï¸ OptimizaciÃ³n de HiperparÃ¡metros

## ðŸŽ¯ Objetivos de Aprendizaje

- Comprender la diferencia entre parÃ¡metros e hiperparÃ¡metros
- Implementar GridSearchCV y RandomizedSearchCV
- Entender Nested Cross-Validation
- Conocer el tradeoff Bias-Variance

---

## ðŸ“‹ Contenido

### 1. ParÃ¡metros vs HiperparÃ¡metros

| Tipo                | DescripciÃ³n                          | Ejemplo                                          | CÃ³mo se obtienen                |
| ------------------- | ------------------------------------ | ------------------------------------------------ | ------------------------------- |
| **ParÃ¡metros**      | Se aprenden durante el entrenamiento | Coeficientes en regresiÃ³n, pesos de red neuronal | OptimizaciÃ³n (gradient descent) |
| **HiperparÃ¡metros** | Se definen ANTES del entrenamiento   | n_estimators, max_depth, learning_rate           | BÃºsqueda manual o automÃ¡tica    |

```python
from sklearn.ensemble import RandomForestClassifier

# HiperparÃ¡metros (los defines tÃº)
model = RandomForestClassifier(
    n_estimators=100,      # HiperparÃ¡metro
    max_depth=10,          # HiperparÃ¡metro
    min_samples_split=2,   # HiperparÃ¡metro
    random_state=42
)

# ParÃ¡metros (se aprenden al entrenar)
model.fit(X_train, y_train)
# model.feature_importances_  â† ParÃ¡metros aprendidos
```

---

### 2. GridSearchCV

BÃºsqueda exhaustiva de todas las combinaciones:

```python
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# Datos
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir grid de hiperparÃ¡metros
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20, None],
    'min_samples_split': [2, 5, 10]
}

# Total de combinaciones: 3 Ã— 4 Ã— 3 = 36

# GridSearchCV
model = RandomForestClassifier(random_state=42)
grid_search = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    cv=5,                    # 5-fold CV
    scoring='accuracy',      # MÃ©trica a optimizar
    n_jobs=-1,               # ParalelizaciÃ³n
    verbose=1,               # Mostrar progreso
    return_train_score=True  # Guardar scores de train
)

# Ejecutar bÃºsqueda
grid_search.fit(X_train, y_train)

# Resultados
print(f"Mejores hiperparÃ¡metros: {grid_search.best_params_}")
print(f"Mejor score CV: {grid_search.best_score_:.4f}")
print(f"Score en test: {grid_search.score(X_test, y_test):.4f}")
```

**Output:**

```
Fitting 5 folds for each of 36 candidates, totalling 180 fits
Mejores hiperparÃ¡metros: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}
Mejor score CV: 0.8625
Score en test: 0.8700
```

---

### 3. Analizar Resultados de GridSearch

```python
import pandas as pd

# Convertir resultados a DataFrame
results = pd.DataFrame(grid_search.cv_results_)

# Columnas mÃ¡s importantes
cols = ['param_n_estimators', 'param_max_depth', 'param_min_samples_split',
        'mean_test_score', 'std_test_score', 'rank_test_score']
print(results[cols].sort_values('rank_test_score').head(10))

# Mejor modelo (ya estÃ¡ entrenado)
best_model = grid_search.best_estimator_
```

**Visualizar resultados:**

```python
import matplotlib.pyplot as plt
import numpy as np

# Heatmap para dos hiperparÃ¡metros
pivot = results.pivot_table(
    values='mean_test_score',
    index='param_max_depth',
    columns='param_n_estimators',
    aggfunc='mean'
)

fig, ax = plt.subplots(figsize=(10, 6))
im = ax.imshow(pivot, cmap='viridis', aspect='auto')
ax.set_xticks(range(len(pivot.columns)))
ax.set_xticklabels(pivot.columns)
ax.set_yticks(range(len(pivot.index)))
ax.set_yticklabels(pivot.index)
ax.set_xlabel('n_estimators')
ax.set_ylabel('max_depth')
plt.colorbar(im, label='Mean CV Score')
plt.title('GridSearchCV Results')
plt.tight_layout()
plt.show()
```

---

### 4. RandomizedSearchCV

BÃºsqueda aleatoria - mÃ¡s eficiente para espacios grandes:

```python
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint, uniform

# Distribuciones de hiperparÃ¡metros
param_distributions = {
    'n_estimators': randint(50, 500),           # Entero entre 50 y 500
    'max_depth': randint(5, 50),                # Entero entre 5 y 50
    'min_samples_split': randint(2, 20),        # Entero entre 2 y 20
    'min_samples_leaf': randint(1, 10),         # Entero entre 1 y 10
    'max_features': uniform(0.1, 0.9)           # Float entre 0.1 y 1.0
}

# RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_distributions=param_distributions,
    n_iter=50,               # NÃºmero de combinaciones a probar
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    random_state=42,
    verbose=1
)

random_search.fit(X_train, y_train)

print(f"Mejores hiperparÃ¡metros: {random_search.best_params_}")
print(f"Mejor score CV: {random_search.best_score_:.4f}")
print(f"Score en test: {random_search.score(X_test, y_test):.4f}")
```

---

### 5. GridSearch vs RandomizedSearch

| Aspecto                | GridSearchCV                  | RandomizedSearchCV                   |
| ---------------------- | ----------------------------- | ------------------------------------ |
| **BÃºsqueda**           | Exhaustiva                    | Aleatoria                            |
| **Complejidad**        | O(combinaciones Ã— K)          | O(n_iter Ã— K)                        |
| **CuÃ¡ndo usar**        | Pocos hiperparÃ¡metros         | Muchos hiperparÃ¡metros               |
| **Encuentra Ã³ptimo**   | Garantizado (si estÃ¡ en grid) | Probable con suficientes iteraciones |
| **Espacios continuos** | Discretiza                    | Natural                              |

```python
# Ejemplo de eficiencia
# Grid: 10 Ã— 10 Ã— 10 Ã— 10 = 10,000 combinaciones
# Random: 100 iteraciones pueden dar buen resultado
```

---

### 6. Bias-Variance Tradeoff

![Bias-Variance](../0-assets/05-bias-variance.svg)

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score

# Datos
np.random.seed(42)
X = np.sort(np.random.rand(100, 1) * 10, axis=0)
y = np.sin(X).ravel() + np.random.randn(100) * 0.3

# Evaluar diferentes complejidades (max_depth)
depths = range(1, 20)
train_scores = []
cv_scores = []

for depth in depths:
    model = DecisionTreeRegressor(max_depth=depth, random_state=42)
    model.fit(X, y)

    # Score en train
    train_scores.append(model.score(X, y))

    # Score CV
    cv = cross_val_score(model, X, y, cv=5, scoring='r2')
    cv_scores.append(cv.mean())

# Graficar
plt.figure(figsize=(10, 6))
plt.plot(depths, train_scores, 'b-', label='Train Score', linewidth=2)
plt.plot(depths, cv_scores, 'r-', label='CV Score', linewidth=2)
plt.xlabel('Complejidad del Modelo (max_depth)')
plt.ylabel('RÂ² Score')
plt.title('Bias-Variance Tradeoff')
plt.legend()
plt.grid(True, alpha=0.3)

# Marcar underfitting y overfitting
plt.axvline(x=4, color='g', linestyle='--', alpha=0.5, label='Ã“ptimo')
plt.annotate('Underfitting\n(Alto Bias)', xy=(2, 0.3), fontsize=10)
plt.annotate('Overfitting\n(Alta Variance)', xy=(15, 0.3), fontsize=10)
plt.tight_layout()
plt.show()
```

---

### 7. Nested Cross-Validation

**Problema:** Si usamos CV para seleccionar hiperparÃ¡metros Y evaluar el modelo, tenemos sesgo optimista.

**SoluciÃ³n:** Nested CV

```python
from sklearn.model_selection import cross_val_score, GridSearchCV

# CV interno: SelecciÃ³n de hiperparÃ¡metros
inner_cv = 5

# CV externo: EvaluaciÃ³n del proceso completo
outer_cv = 5

# GridSearch (loop interno)
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20]
}

grid_search = GridSearchCV(
    estimator=RandomForestClassifier(random_state=42),
    param_grid=param_grid,
    cv=inner_cv,
    scoring='accuracy',
    n_jobs=-1
)

# Nested CV (loop externo)
nested_scores = cross_val_score(
    grid_search,  # Objeto completo de GridSearch
    X, y,
    cv=outer_cv,
    scoring='accuracy'
)

print(f"Nested CV Accuracy: {nested_scores.mean():.4f} Â± {nested_scores.std():.4f}")
```

**Estructura:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CV Externo (5-fold)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Fold 1: Train(80%) â†’ GridSearchCV â†’ Test(20%) â”‚  â”‚
â”‚  â”‚  Fold 2: Train(80%) â†’ GridSearchCV â†’ Test(20%) â”‚  â”‚
â”‚  â”‚  ...                                           â”‚  â”‚
â”‚  â”‚  Fold 5: Train(80%) â†’ GridSearchCV â†’ Test(20%) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                       â”‚
â”‚  Dentro de cada GridSearchCV (CV Interno 5-fold):    â”‚
â”‚  - Encuentra mejores hiperparÃ¡metros                 â”‚
â”‚  - Entrena modelo final con esos hiperparÃ¡metros    â”‚
â”‚  - EvalÃºa en el fold de test externo                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 8. Pipelines con GridSearch

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC

# Pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('pca', PCA()),
    ('svm', SVC())
])

# Grid de hiperparÃ¡metros (usar nombre_paso__parametro)
param_grid = {
    'pca__n_components': [5, 10, 15],
    'svm__C': [0.1, 1, 10],
    'svm__kernel': ['rbf', 'linear'],
    'svm__gamma': ['scale', 'auto']
}

# GridSearch sobre pipeline completo
grid_search = GridSearchCV(
    pipeline,
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)

print(f"Mejores parÃ¡metros: {grid_search.best_params_}")
print(f"Score test: {grid_search.score(X_test, y_test):.4f}")
```

---

### 9. Estrategias de BÃºsqueda Avanzadas

#### 9.1 BÃºsqueda en Dos Etapas

```python
# Etapa 1: BÃºsqueda amplia con pocos valores
param_grid_coarse = {
    'n_estimators': [50, 200],
    'max_depth': [5, 20],
    'learning_rate': [0.01, 0.1]
}

grid_coarse = GridSearchCV(model, param_grid_coarse, cv=3)
grid_coarse.fit(X_train, y_train)

# Etapa 2: BÃºsqueda fina alrededor del mejor
best = grid_coarse.best_params_
param_grid_fine = {
    'n_estimators': [best['n_estimators'] - 50, best['n_estimators'], best['n_estimators'] + 50],
    'max_depth': [best['max_depth'] - 2, best['max_depth'], best['max_depth'] + 2],
    # ...
}

grid_fine = GridSearchCV(model, param_grid_fine, cv=5)
grid_fine.fit(X_train, y_train)
```

#### 9.2 Early Stopping

```python
from sklearn.ensemble import GradientBoostingClassifier

# Con early stopping manual via warm_start
model = GradientBoostingClassifier(warm_start=True, n_estimators=1)

for n_trees in range(1, 500, 10):
    model.n_estimators = n_trees
    model.fit(X_train, y_train)
    score = model.score(X_val, y_val)
    if n_trees > 50 and score < best_score - 0.01:
        print(f"Early stopping at {n_trees} trees")
        break
```

---

### 10. Ejemplo Completo: OptimizaciÃ³n de Modelo

```python
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report
import warnings
warnings.filterwarnings('ignore')

# Datos
data = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    data.data, data.target, test_size=0.2, random_state=42, stratify=data.target
)

# Grid de hiperparÃ¡metros
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'min_samples_split': [2, 5]
}

# GridSearchCV
model = GradientBoostingClassifier(random_state=42)
grid_search = GridSearchCV(
    model, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1
)
grid_search.fit(X_train, y_train)

# Resultados
print("\n" + "="*50)
print("RESULTADOS DE OPTIMIZACIÃ“N")
print("="*50)
print(f"\nMejores hiperparÃ¡metros:")
for param, value in grid_search.best_params_.items():
    print(f"  {param}: {value}")

print(f"\nMejor F1 Score (CV): {grid_search.best_score_:.4f}")

# Evaluar en test
y_pred = grid_search.predict(X_test)
print(f"\nRendimiento en Test:")
print(classification_report(y_test, y_pred, target_names=['Maligno', 'Benigno']))

# Nested CV para estimaciÃ³n honesta
print("\nEstimaciÃ³n con Nested CV:")
nested_scores = cross_val_score(grid_search, data.data, data.target, cv=5, scoring='f1')
print(f"F1 Score: {nested_scores.mean():.4f} Â± {nested_scores.std():.4f}")
```

---

### 11. Consejos PrÃ¡cticos

1. **Empieza simple**: Pocos hiperparÃ¡metros, rangos amplios
2. **Usa RandomizedSearch** para espacios grandes
3. **Paraleliza** con `n_jobs=-1`
4. **Nested CV** para reportar mÃ©tricas honestas
5. **No overfittees** los hiperparÃ¡metros al validation set
6. **Documenta** los hiperparÃ¡metros finales

---

## ðŸ“š Resumen

| MÃ©todo                 | Uso                           | Eficiencia            |
| ---------------------- | ----------------------------- | --------------------- |
| **GridSearchCV**       | Espacios pequeÃ±os, exhaustivo | O(combinaciones)      |
| **RandomizedSearchCV** | Espacios grandes              | O(n_iter)             |
| **Nested CV**          | EvaluaciÃ³n sin sesgo          | Costoso pero correcto |

---

## âœ… Checklist de VerificaciÃ³n

- [ ] Distingo parÃ¡metros de hiperparÃ¡metros
- [ ] SÃ© usar GridSearchCV y RandomizedSearchCV
- [ ] Entiendo el tradeoff Bias-Variance
- [ ] Comprendo por quÃ© es importante Nested CV
- [ ] Puedo optimizar pipelines completos

---

## ðŸ”— Recursos Adicionales

- [GridSearchCV Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)
- [Tuning Hyperparameters](https://scikit-learn.org/stable/modules/grid_search.html)
- [Nested CV](https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html)

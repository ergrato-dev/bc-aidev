# üìä Validaci√≥n Holdout (Train-Test Split)

## üéØ Objetivos de Aprendizaje

- Comprender la necesidad de separar datos de entrenamiento y prueba
- Implementar train-test split correctamente
- Conocer las limitaciones de la validaci√≥n holdout
- Entender el concepto de data leakage

---

## üìã Contenido

### 1. ¬øPor Qu√© Necesitamos Validaci√≥n?

El objetivo de Machine Learning es crear modelos que **generalicen** bien a datos nuevos, no solo que memoricen los datos de entrenamiento.

```python
# ‚ùå MAL: Evaluar en los mismos datos de entrenamiento
from sklearn.linear_model import LogisticRegression

model = LogisticRegression()
model.fit(X, y)
accuracy = model.score(X, y)  # Esto sobreestima el rendimiento real
print(f"Accuracy (train): {accuracy:.2f}")  # Puede ser 99% pero fallar en producci√≥n
```

**Problema**: Un modelo puede memorizar los datos de entrenamiento (overfitting) y dar m√©tricas excelentes, pero fallar completamente con datos nuevos.

---

### 2. Train-Test Split

La soluci√≥n m√°s simple es dividir los datos en dos conjuntos:

![Train-Test Split](../0-assets/01-train-test-split.svg)

```python
from sklearn.model_selection import train_test_split
import numpy as np

# Datos de ejemplo
np.random.seed(42)
X = np.random.randn(1000, 10)
y = np.random.randint(0, 2, 1000)

# Divisi√≥n 80-20
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,      # 20% para test
    random_state=42,    # Reproducibilidad
    stratify=y          # Mantener proporci√≥n de clases
)

print(f"Training set: {len(X_train)} muestras")
print(f"Test set: {len(X_test)} muestras")
```

**Output:**
```
Training set: 800 muestras
Test set: 200 muestras
```

---

### 3. Par√°metros Importantes

#### 3.1 `test_size` y `train_size`

```python
# Proporci√≥n (0-1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# N√∫mero absoluto
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200)

# Equivalentes
train_test_split(X, y, test_size=0.2)
train_test_split(X, y, train_size=0.8)
```

| Dataset Size | Recomendaci√≥n test_size |
|--------------|------------------------|
| < 1,000 | 0.30 - 0.40 |
| 1,000 - 10,000 | 0.20 - 0.30 |
| 10,000 - 100,000 | 0.15 - 0.20 |
| > 100,000 | 0.10 - 0.15 |

#### 3.2 `random_state`

**Crucial para reproducibilidad:**

```python
# ‚úÖ BIEN: Siempre fijar random_state
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Ejecutar m√∫ltiples veces da el mismo resultado
```

#### 3.3 `stratify` - Clasificaci√≥n Balanceada

```python
# Verificar distribuci√≥n original
import pandas as pd
print("Distribuci√≥n original:")
print(pd.Series(y).value_counts(normalize=True))

# Sin stratify - puede desbalancear
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
print("\nSin stratify:")
print(pd.Series(y_test).value_counts(normalize=True))

# ‚úÖ Con stratify - mantiene proporci√≥n
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y
)
print("\nCon stratify:")
print(pd.Series(y_test).value_counts(normalize=True))
```

---

### 4. Flujo Completo de Evaluaci√≥n

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# 1. Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 2. Entrenar modelo
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 3. Predecir en test (datos NUNCA vistos)
y_pred = model.predict(X_test)

# 4. Evaluar
print(f"Accuracy en Train: {model.score(X_train, y_train):.4f}")
print(f"Accuracy en Test: {model.score(X_test, y_test):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
```

---

### 5. Train-Validation-Test Split

Para ajustar hiperpar√°metros necesitamos **tres** conjuntos:

```python
# Primero: separar test (hold-out final)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Segundo: separar train y validation
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
)
# 0.25 de 0.8 = 0.2 del total

print(f"Train: {len(X_train)} ({len(X_train)/len(X):.0%})")
print(f"Validation: {len(X_val)} ({len(X_val)/len(X):.0%})")
print(f"Test: {len(X_test)} ({len(X_test)/len(X):.0%})")
```

**Prop√≥sito de cada conjunto:**

| Conjunto | Uso | Cu√°ndo se eval√∫a |
|----------|-----|------------------|
| **Train** | Entrenar modelo | Durante entrenamiento |
| **Validation** | Ajustar hiperpar√°metros | Durante desarrollo |
| **Test** | Evaluaci√≥n final | Solo al final, UNA vez |

---

### 6. ‚ö†Ô∏è Data Leakage - Error Com√∫n

**Data Leakage** ocurre cuando informaci√≥n del test "se filtra" al entrenamiento:

```python
# ‚ùå MAL: Escalar ANTES de dividir
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # Usa info de TODO el dataset
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)
# El scaler ya "vio" los datos de test!

# ‚úÖ BIEN: Escalar DESPU√âS de dividir
X_train, X_test, y_train, y_test = train_test_split(X, y)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Solo usa train
X_test_scaled = scaler.transform(X_test)        # Aplica sin refit
```

**Otros ejemplos de Data Leakage:**

```python
# ‚ùå MAL: Imputar valores faltantes con media de TODO el dataset
# ‚ùå MAL: Seleccionar features bas√°ndose en correlaci√≥n con TODO y
# ‚ùå MAL: Eliminar outliers mirando TODO el dataset

# ‚úÖ BIEN: Todo el preprocesamiento debe hacerse SOLO con datos de train
```

---

### 7. Limitaciones de Holdout

| Limitaci√≥n | Explicaci√≥n |
|------------|-------------|
| **Alta Varianza** | Un solo split puede no ser representativo |
| **Desperdicio de Datos** | 20-30% no se usa para entrenar |
| **Sensible al Split** | Diferentes splits dan diferentes resultados |

```python
# Demostraci√≥n de varianza entre splits
from sklearn.linear_model import LogisticRegression

accuracies = []
for seed in range(10):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=seed
    )
    model = LogisticRegression()
    model.fit(X_train, y_train)
    acc = model.score(X_test, y_test)
    accuracies.append(acc)

print(f"Accuracy promedio: {np.mean(accuracies):.4f}")
print(f"Desviaci√≥n est√°ndar: {np.std(accuracies):.4f}")
print(f"Rango: {np.min(accuracies):.4f} - {np.max(accuracies):.4f}")
```

**Soluci√≥n**: Usar **Cross-Validation** (siguiente tema).

---

### 8. Regresi√≥n: Sin Stratify

Para regresi√≥n no usamos `stratify`:

```python
# Datos de regresi√≥n
X = np.random.randn(1000, 10)
y_continuous = X[:, 0] * 2 + np.random.randn(1000) * 0.1

# Sin stratify (no aplica a valores continuos)
X_train, X_test, y_train, y_test = train_test_split(
    X, y_continuous, test_size=0.2, random_state=42
)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(f"MSE: {mean_squared_error(y_test, y_pred):.4f}")
print(f"R¬≤: {r2_score(y_test, y_pred):.4f}")
```

---

## üìö Resumen

| Concepto | Descripci√≥n |
|----------|-------------|
| **Holdout** | Divisi√≥n √∫nica en train/test |
| **test_size** | Proporci√≥n para test (t√≠pico: 0.2) |
| **stratify** | Mantiene proporci√≥n de clases |
| **random_state** | Fija seed para reproducibilidad |
| **Data Leakage** | Filtraci√≥n de info de test a train |

---

## ‚úÖ Checklist de Verificaci√≥n

- [ ] Entiendo por qu√© es necesario separar train y test
- [ ] S√© usar `train_test_split` con sus par√°metros principales
- [ ] Comprendo cu√°ndo usar `stratify`
- [ ] Identifico situaciones de Data Leakage
- [ ] Reconozco las limitaciones del holdout simple

---

## üîó Recursos Adicionales

- [Documentaci√≥n train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)
- [Data Leakage in ML](https://machinelearningmastery.com/data-leakage-machine-learning/)

---

**Siguiente**: [Cross-Validation](02-cross-validation.md)

#  Glosario - Semana 15

## Validaci贸n Cruzada y M茅tricas de Evaluaci贸n

T茅rminos clave ordenados alfab茅ticamente.

---

### A

**Accuracy (Exactitud)**
Proporci贸n de predicciones correctas sobre el total.
$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$
锔 Enga帽osa con clases desbalanceadas.

**AP (Average Precision)**
rea bajo la curva Precision-Recall. Mejor que AUC-ROC para clases desbalanceadas.

**AUC (Area Under Curve)**
rea bajo la curva ROC. Mide la capacidad discriminativa del modelo (0.5 = random, 1.0 = perfecto).

---

### B

**Bias**
Error sistem谩tico del modelo. Un modelo con alto bias es demasiado simple y no captura patrones (underfitting).

**Bias-Variance Tradeoff**
Compromiso entre la complejidad del modelo: muy simple = alto bias, muy complejo = alta varianza.

---

### C

**Classification Report**
Resumen de m茅tricas de clasificaci贸n: precision, recall, F1 por clase.

```python
from sklearn.metrics import classification_report
print(classification_report(y_true, y_pred))
```

**Confusion Matrix (Matriz de Confusi贸n)**
Tabla que muestra TP, TN, FP, FN. Base para calcular todas las m茅tricas de clasificaci贸n.

**Cross-Validation (Validaci贸n Cruzada)**
T茅cnica que divide los datos en K partes para entrenar y evaluar m煤ltiples veces, obteniendo una estimaci贸n m谩s robusta del rendimiento.

**cross_val_score**
Funci贸n de scikit-learn para realizar cross-validation en una l铆nea.

```python
scores = cross_val_score(model, X, y, cv=5)
```

---

### D

**Data Leakage**
Cuando informaci贸n del conjunto de test "se filtra" al entrenamiento, causando m茅tricas optimistas pero poco realistas.

---

### F

**F1-Score**
Media arm贸nica de Precision y Recall. Balancea ambas m茅tricas.
$$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$$

**False Negative (FN)**
Positivo real clasificado incorrectamente como negativo. Error Tipo II.

**False Positive (FP)**
Negativo real clasificado incorrectamente como positivo. Error Tipo I.

**FPR (False Positive Rate)**
Tasa de falsos positivos: FP / (FP + TN). Eje X de la curva ROC.

---

### G

**GridSearchCV**
B煤squeda exhaustiva de hiperpar谩metros probando todas las combinaciones posibles.

```python
grid = GridSearchCV(model, param_grid, cv=5)
```

**Group K-Fold**
Variante de K-Fold que garantiza que grupos (ej: pacientes) no se mezclen entre train y test.

---

### H

**Holdout**
M茅todo de validaci贸n simple: dividir datos en train y test una sola vez.

**Hyperparameter (Hiperpar谩metro)**
Par谩metro del modelo que se define antes del entrenamiento (ej: n_estimators, learning_rate).

---

### K

**K-Fold Cross-Validation**
Divide los datos en K partes. En cada iteraci贸n, K-1 partes para train, 1 para validaci贸n.

---

### L

**Leave-One-Out (LOO)**
Cross-validation donde K = n煤mero de muestras. Cada muestra es un fold de test.

---

### M

**MAE (Mean Absolute Error)**
Error absoluto promedio. Robusto a outliers.
$$MAE = \frac{1}{n} \sum |y_i - \hat{y}_i|$$

**MAPE (Mean Absolute Percentage Error)**
Error porcentual promedio. til cuando necesitas error relativo.

**MSE (Mean Squared Error)**
Error cuadr谩tico promedio. Penaliza errores grandes.
$$MSE = \frac{1}{n} \sum (y_i - \hat{y}_i)^2$$

---

### N

**Nested Cross-Validation**
CV anidado: CV externo para evaluaci贸n, CV interno para selecci贸n de hiperpar谩metros. Evita sesgo optimista.

---

### O

**Overfitting (Sobreajuste)**
Modelo demasiado complejo que memoriza el training pero no generaliza. Error bajo en train, alto en test.

---

### P

**Precision (Precisi贸n)**
De todos los predichos positivos, 驴cu谩ntos son realmente positivos?
$$\text{Precision} = \frac{TP}{TP + FP}$$
Importante cuando FP es costoso.

**Precision-Recall Curve**
Curva que muestra Precision vs Recall a diferentes umbrales. Mejor que ROC para clases desbalanceadas.

---

### R

**R虏 (Coeficiente de Determinaci贸n)**
Proporci贸n de varianza explicada por el modelo. 1.0 = perfecto, 0.0 = igual que predecir la media.
$$R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$$

**RandomizedSearchCV**
B煤squeda aleatoria de hiperpar谩metros. M谩s eficiente que GridSearch para espacios grandes.

**Recall (Sensibilidad / TPR)**
De todos los positivos reales, 驴cu谩ntos detect贸 el modelo?
$$\text{Recall} = \frac{TP}{TP + FN}$$
Importante cuando FN es costoso.

**RMSE (Root Mean Squared Error)**
Ra铆z del MSE. En las mismas unidades que la variable objetivo.
$$RMSE = \sqrt{MSE}$$

**ROC Curve**
Curva que grafica TPR vs FPR a diferentes umbrales de clasificaci贸n.

---

### S

**Scoring**
Par谩metro de cross_val_score que indica qu茅 m茅trica optimizar ('accuracy', 'f1', 'roc_auc', etc.).

**Stratified K-Fold**
K-Fold que mantiene la proporci贸n de clases en cada fold. Esencial para clases desbalanceadas.

---

### T

**Test Set (Conjunto de Prueba)**
Datos reservados para evaluaci贸n final. NUNCA se usan para entrenamiento ni selecci贸n de hiperpar谩metros.

**TPR (True Positive Rate)**
Igual que Recall. TP / (TP + FN). Eje Y de la curva ROC.

**Train Set (Conjunto de Entrenamiento)**
Datos usados para entrenar el modelo.

**True Negative (TN)**
Negativo real correctamente clasificado como negativo.

**True Positive (TP)**
Positivo real correctamente clasificado como positivo.

---

### U

**Umbral (Threshold)**
Valor que determina la clasificaci贸n. Por defecto 0.5 en clasificaci贸n binaria. Ajustable seg煤n necesidades.

**Underfitting (Subajuste)**
Modelo demasiado simple que no captura patrones. Error alto en train y test.

---

### V

**Validation Set (Conjunto de Validaci贸n)**
Datos usados para ajustar hiperpar谩metros durante el desarrollo. Diferente de test set.

**Variance (Varianza)**
Sensibilidad del modelo a cambios en los datos de entrenamiento. Alta varianza = overfitting.

---

##  Tabla de M茅tricas R谩pida

| Clasificaci贸n | Regresi贸n |
| ------------- | --------- |
| Accuracy      | R虏        |
| Precision     | MSE       |
| Recall        | RMSE      |
| F1-Score      | MAE       |
| AUC-ROC       | MAPE      |
| AP (PR-AUC)   |           |

---

##  Referencias

- [Scikit-learn Model Evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html)
- [Scikit-learn Cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html)

# üìà Ejercicio 03: M√©tricas de Regresi√≥n

## üéØ Objetivo

Comprender y aplicar las m√©tricas de regresi√≥n: MSE, RMSE, MAE, R¬≤ y analizar residuos.

---

## üìã Descripci√≥n

En este ejercicio aprender√°s a:

1. Calcular MSE, RMSE, MAE y R¬≤
2. Entender cu√°ndo usar cada m√©trica
3. Visualizar y analizar residuos
4. Comparar modelos de regresi√≥n

---

## üìÅ Archivos

- `starter/main.py` - C√≥digo inicial para descomentar
- `solution/main.py` - Soluci√≥n completa

---

## üî® Pasos

### Paso 1: Preparar Datos de Regresi√≥n

Usamos el dataset California Housing para predicci√≥n de precios.

```python
from sklearn.datasets import fetch_california_housing
X, y = fetch_california_housing(return_X_y=True)
```

**Abre `starter/main.py`** y descomenta la secci√≥n del Paso 1.

---

### Paso 2: MSE y RMSE

Calculamos el error cuadr√°tico medio y su ra√≠z.

```python
from sklearn.metrics import mean_squared_error
import numpy as np

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
```

**Abre `starter/main.py`** y descomenta la secci√≥n del Paso 2.

---

### Paso 3: MAE

Calculamos el error absoluto medio, m√°s robusto a outliers.

```python
from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_test, y_pred)
```

**Abre `starter/main.py`** y descomenta la secci√≥n del Paso 3.

---

### Paso 4: R¬≤ (Coeficiente de Determinaci√≥n)

Calculamos la proporci√≥n de varianza explicada.

```python
from sklearn.metrics import r2_score

r2 = r2_score(y_test, y_pred)
# 1.0 = perfecto, 0.0 = igual que predecir la media
```

**Abre `starter/main.py`** y descomenta la secci√≥n del Paso 4.

---

### Paso 5: An√°lisis de Residuos

Visualizamos los residuos para detectar patrones.

```python
residuals = y_test - y_pred
# Gr√°fico de residuos vs predicciones
# Histograma de residuos
```

**Abre `starter/main.py`** y descomenta la secci√≥n del Paso 5.

---

### Paso 6: Comparar Modelos

Evaluamos m√∫ltiples modelos de regresi√≥n.

```python
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor

models = {
    'LinearRegression': LinearRegression(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'RandomForest': RandomForestRegressor()
}
```

**Abre `starter/main.py`** y descomenta la secci√≥n del Paso 6.

---

### Paso 7: Sensibilidad a Outliers

Comparamos MSE vs MAE con datos con outliers.

```python
# Agregar outliers y ver c√≥mo cambian las m√©tricas
```

**Abre `starter/main.py`** y descomenta la secci√≥n del Paso 7.

---

## ‚úÖ Criterios de Evaluaci√≥n

| Criterio                            | Puntos |
| ----------------------------------- | ------ |
| MSE y RMSE calculados correctamente | 2      |
| MAE calculado correctamente         | 1      |
| R¬≤ calculado e interpretado         | 2      |
| An√°lisis de residuos completo       | 2      |
| Comparaci√≥n de modelos              | 2      |
| An√°lisis de sensibilidad a outliers | 1      |
| **Total**                           | **10** |

---

## üîó Recursos

- [Regression metrics scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)

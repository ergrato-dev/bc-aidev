# ğŸ“˜ GuÃ­a del Proyecto Final

## ğŸ¯ Objetivo

Desarrollar un proyecto completo de Inteligencia Artificial que integre los conocimientos adquiridos durante el bootcamp, desde la preparaciÃ³n de datos hasta el deployment en producciÃ³n.

---

## 1. VisiÃ³n General del Proyecto

### 1.1 Â¿QuÃ© es un Proyecto End-to-End?

Un proyecto end-to-end incluye todas las fases del ciclo de vida de ML:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 PROYECTO END-TO-END                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Data â”‚â”€â”€â–¶â”‚Model â”‚â”€â”€â–¶â”‚ API  â”‚â”€â”€â–¶â”‚Deployâ”‚â”€â”€â–¶â”‚ Demo â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â”‚  Semana 35:          Semana 36:                            â”‚
â”‚  â€¢ Datos             â€¢ Deployment                          â”‚
â”‚  â€¢ Modelo            â€¢ DocumentaciÃ³n                       â”‚
â”‚  â€¢ API               â€¢ PresentaciÃ³n                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Componentes Requeridos

| Componente | DescripciÃ³n | Entregable |
|------------|-------------|------------|
| **Datos** | Dataset preparado y procesado | Notebook o script |
| **Modelo** | Modelo entrenado y evaluado | Archivo .pkl/.pt/.h5 |
| **API** | Endpoints para predicciÃ³n | FastAPI app |
| **Docker** | ContainerizaciÃ³n | Dockerfile |
| **Deploy** | AplicaciÃ³n en la nube | URL pÃºblica |
| **Docs** | DocumentaciÃ³n completa | README.md |

---

## 2. Fases del Proyecto

### 2.1 Fase 1: DefiniciÃ³n (30 min)

```python
# Preguntas a responder
proyecto = {
    "problema": "Â¿QuÃ© problema resuelve?",
    "usuario": "Â¿QuiÃ©n lo usarÃ¡?",
    "valor": "Â¿QuÃ© valor aporta?",
    "alcance": "Â¿QuÃ© incluye el MVP?",
    "metricas": "Â¿CÃ³mo medimos el Ã©xito?"
}
```

**Checklist de DefiniciÃ³n:**
- [ ] Problema claramente definido
- [ ] Usuario objetivo identificado
- [ ] Alcance del MVP establecido
- [ ] MÃ©tricas de Ã©xito definidas
- [ ] Stack tecnolÃ³gico seleccionado

### 2.2 Fase 2: Datos (1 hora)

```python
# Pipeline tÃ­pico de datos
"""
1. ObtenciÃ³n
   - Descargar dataset (Kaggle, Hugging Face, API)
   - Verificar licencia y tÃ©rminos de uso
   
2. ExploraciÃ³n
   - AnÃ¡lisis exploratorio (EDA)
   - Identificar problemas de calidad
   
3. PreparaciÃ³n
   - Limpieza
   - Transformaciones
   - Split train/val/test
   
4. Versionado
   - Guardar datasets procesados
   - Documentar transformaciones
"""
```

**Fuentes de Datos Recomendadas:**

| Fuente | Tipo | URL |
|--------|------|-----|
| Kaggle | General | kaggle.com/datasets |
| Hugging Face | NLP/CV | huggingface.co/datasets |
| UCI ML | ClÃ¡sicos | archive.ics.uci.edu |
| Papers With Code | Benchmarks | paperswithcode.com |

### 2.3 Fase 3: Modelo (1.5 horas)

```python
# Estructura tÃ­pica de entrenamiento

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import joblib

def train_model(X: np.ndarray, y: np.ndarray) -> tuple:
    """
    Pipeline de entrenamiento.
    
    Returns:
        model: Modelo entrenado
        metrics: Diccionario de mÃ©tricas
    """
    # 1. Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # 2. Entrenar
    model = create_model()
    model.fit(X_train, y_train)
    
    # 3. Evaluar
    y_pred = model.predict(X_test)
    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "report": classification_report(y_test, y_pred)
    }
    
    # 4. Guardar
    joblib.dump(model, "models/model.pkl")
    
    return model, metrics
```

**Checklist del Modelo:**
- [ ] Baseline establecido
- [ ] Modelo principal entrenado
- [ ] HiperparÃ¡metros ajustados
- [ ] MÃ©tricas documentadas
- [ ] Modelo guardado correctamente

### 2.4 Fase 4: API (1 hora)

```python
# Estructura mÃ­nima de API

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib

app = FastAPI(title="Mi Proyecto ML")

# Cargar modelo al inicio
model = joblib.load("models/model.pkl")

class PredictionInput(BaseModel):
    features: list[float]

class PredictionOutput(BaseModel):
    prediction: str
    confidence: float

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/predict", response_model=PredictionOutput)
def predict(input_data: PredictionInput):
    try:
        prediction = model.predict([input_data.features])[0]
        confidence = model.predict_proba([input_data.features]).max()
        return PredictionOutput(
            prediction=str(prediction),
            confidence=float(confidence)
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## 3. Estructura de Proyecto Recomendada

```
mi-proyecto-final/
â”œâ”€â”€ README.md               # DocumentaciÃ³n principal
â”œâ”€â”€ requirements.txt        # Dependencias
â”œâ”€â”€ Dockerfile             # ContainerizaciÃ³n
â”œâ”€â”€ docker-compose.yml     # OrquestaciÃ³n
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Datos originales
â”‚   â”œâ”€â”€ processed/         # Datos procesados
â”‚   â””â”€â”€ README.md          # DocumentaciÃ³n de datos
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb       # AnÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ 02_training.ipynb  # Entrenamiento
â”‚   â””â”€â”€ 03_evaluation.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/              # MÃ³dulo de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ load.py
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”œâ”€â”€ models/            # MÃ³dulo de modelos
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train.py
â”‚   â”‚   â””â”€â”€ predict.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py            # FastAPI app
â”‚   â”œâ”€â”€ schemas.py         # Pydantic models
â”‚   â””â”€â”€ config.py          # ConfiguraciÃ³n
â”‚
â”œâ”€â”€ models/                # Modelos guardados
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_model.py
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ architecture.md
    â””â”€â”€ api.md
```

---

## 4. README Profesional

Tu README debe incluir:

```markdown
# ğŸš€ Nombre del Proyecto

DescripciÃ³n breve y clara del proyecto.

![Demo](docs/demo.gif)

## ğŸ¯ Problema

Â¿QuÃ© problema resuelve?

## âœ¨ Features

- Feature 1
- Feature 2
- Feature 3

## ğŸ› ï¸ Stack TecnolÃ³gico

- Python 3.11+
- FastAPI
- TensorFlow/PyTorch
- Docker

## ğŸš€ Quick Start

\`\`\`bash
# Clonar
git clone https://github.com/usuario/proyecto.git
cd proyecto

# Instalar
pip install -r requirements.txt

# Ejecutar
uvicorn app.main:app --reload
\`\`\`

## ğŸ“Š Resultados

| MÃ©trica | Valor |
|---------|-------|
| Accuracy | 95% |
| F1-Score | 0.94 |

## ğŸ“– API

### POST /predict

\`\`\`bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"features": [1.0, 2.0, 3.0]}'
\`\`\`

## ğŸ³ Docker

\`\`\`bash
docker compose up --build
\`\`\`

## ğŸ“ Licencia

MIT
```

---

## 5. Errores Comunes a Evitar

### âŒ No hagas esto:

```python
# 1. Hardcoded paths
model = load("C:/Users/mi_usuario/Desktop/model.pkl")  # âŒ

# 2. Sin manejo de errores
prediction = model.predict(data)  # âŒ Â¿Y si falla?

# 3. Secrets en cÃ³digo
API_KEY = "sk-abc123"  # âŒ

# 4. Sin validaciÃ³n de entrada
def predict(data):
    return model.predict(data)  # âŒ Â¿QuÃ© es data?
```

### âœ… Hazlo asÃ­:

```python
# 1. Paths relativos o configurables
from pathlib import Path
MODEL_PATH = Path(__file__).parent / "models" / "model.pkl"

# 2. Con manejo de errores
try:
    prediction = model.predict(data)
except Exception as e:
    logger.error(f"Prediction failed: {e}")
    raise HTTPException(status_code=500, detail="Prediction error")

# 3. Variables de entorno
import os
API_KEY = os.getenv("API_KEY")

# 4. Con validaciÃ³n (Pydantic)
class InputData(BaseModel):
    features: list[float] = Field(..., min_length=4, max_length=4)
```

---

## 6. Timeline Sugerido

### Semana 35 (6 horas)

| DÃ­a | Actividad | Tiempo |
|-----|-----------|--------|
| 1 | Leer guÃ­as, elegir proyecto | 1h |
| 2 | Obtener y explorar datos | 1.5h |
| 3 | Desarrollar modelo | 2h |
| 4 | Crear API bÃ¡sica | 1.5h |

### Semana 36 (6 horas)

| DÃ­a | Actividad | Tiempo |
|-----|-----------|--------|
| 1 | Dockerizar y desplegar | 2h |
| 2 | DocumentaciÃ³n y README | 2h |
| 3 | Preparar demo y presentaciÃ³n | 2h |

---

## âœ… Checklist Final

- [ ] Proyecto funciona localmente
- [ ] CÃ³digo estÃ¡ en GitHub
- [ ] README completo
- [ ] API documentada
- [ ] Docker funciona
- [ ] Deploy en cloud
- [ ] Demo lista

---

## ğŸ“š Recursos

- [FastAPI Best Practices](https://fastapi.tiangolo.com/tutorial/)
- [ML Project Template](https://github.com/drivendata/cookiecutter-data-science)
- [Hugging Face Spaces](https://huggingface.co/spaces)
- [Railway](https://railway.app/)

# ðŸŽ² Ejercicio 01: Implementar Dropout

## ðŸŽ¯ Objetivo

Implementar y comparar modelos con diferentes configuraciones de Dropout para combatir overfitting.

---

## ðŸ“‹ DescripciÃ³n

En este ejercicio aprenderÃ¡s:

1. CÃ³mo Dropout reduce overfitting
2. Elegir valores apropiados de p
3. Diferencia entre `model.train()` y `model.eval()`
4. Comparar rendimiento con/sin Dropout

---

## ðŸ”§ Requisitos

```bash
pip install torch torchvision matplotlib
```

---

## ðŸ“ Pasos del Ejercicio

### Paso 1: Cargar MNIST y Crear DataLoaders

Cargamos el dataset MNIST y creamos loaders para entrenamiento y test.

```python
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('data', train=False, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000)
```

**Abre `starter/main.py`** y descomenta la secciÃ³n del Paso 1.

---

### Paso 2: Modelo SIN Dropout (Baseline)

Creamos un modelo MLP simple sin regularizaciÃ³n.

```python
model_no_dropout = nn.Sequential(
    nn.Flatten(),
    nn.Linear(784, 512),
    nn.ReLU(),
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Linear(256, 10)
)
```

Este modelo tenderÃ¡ a hacer overfitting con suficientes Ã©pocas.

**Descomenta** la secciÃ³n del Paso 2 en `starter/main.py`.

---

### Paso 3: Modelo CON Dropout

Agregamos capas de Dropout despuÃ©s de cada activaciÃ³n ReLU.

```python
model_with_dropout = nn.Sequential(
    nn.Flatten(),
    nn.Linear(784, 512),
    nn.ReLU(),
    nn.Dropout(0.5),      # 50% dropout
    nn.Linear(512, 256),
    nn.ReLU(),
    nn.Dropout(0.3),      # 30% dropout
    nn.Linear(256, 10)
)
```

**Descomenta** la secciÃ³n del Paso 3 en `starter/main.py`.

---

### Paso 4: FunciÃ³n de Entrenamiento

Implementamos el loop de entrenamiento que registra mÃ©tricas.

```python
def train_epoch(model, train_loader, criterion, optimizer):
    model.train()  # Activa Dropout
    total_loss, correct, total = 0, 0, 0
    
    for x, y in train_loader:
        optimizer.zero_grad()
        output = model(x)
        loss = criterion(output, y)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        correct += (output.argmax(1) == y).sum().item()
        total += y.size(0)
    
    return total_loss / len(train_loader), correct / total
```

**Descomenta** la secciÃ³n del Paso 4 en `starter/main.py`.

---

### Paso 5: FunciÃ³n de EvaluaciÃ³n

Evaluamos en test set con Dropout desactivado.

```python
def evaluate(model, test_loader, criterion):
    model.eval()  # Desactiva Dropout
    total_loss, correct, total = 0, 0, 0
    
    with torch.no_grad():
        for x, y in test_loader:
            output = model(x)
            total_loss += criterion(output, y).item()
            correct += (output.argmax(1) == y).sum().item()
            total += y.size(0)
    
    return total_loss / len(test_loader), correct / total
```

âš ï¸ **Importante**: `model.eval()` desactiva Dropout durante inferencia.

**Descomenta** la secciÃ³n del Paso 5 en `starter/main.py`.

---

### Paso 6: Entrenar Ambos Modelos

Entrenamos y comparamos ambos modelos.

```python
epochs = 20
# Entrenar modelo sin dropout
for epoch in range(epochs):
    train_loss, train_acc = train_epoch(model_no_dropout, ...)
    test_loss, test_acc = evaluate(model_no_dropout, ...)
    # Guardar mÃ©tricas...

# Entrenar modelo con dropout
for epoch in range(epochs):
    train_loss, train_acc = train_epoch(model_with_dropout, ...)
    test_loss, test_acc = evaluate(model_with_dropout, ...)
    # Guardar mÃ©tricas...
```

**Descomenta** la secciÃ³n del Paso 6 en `starter/main.py`.

---

### Paso 7: Visualizar Resultados

Graficamos las curvas de aprendizaje para comparar.

```python
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Plot accuracy
axes[0].plot(no_dropout_train_accs, label='Sin Dropout - Train')
axes[0].plot(no_dropout_test_accs, label='Sin Dropout - Test')
axes[0].plot(with_dropout_train_accs, label='Con Dropout - Train')
axes[0].plot(with_dropout_test_accs, label='Con Dropout - Test')
axes[0].set_title('Accuracy: Dropout Comparison')
axes[0].legend()
```

**Descomenta** la secciÃ³n del Paso 7 en `starter/main.py`.

---

## âœ… Criterios de Ã‰xito

| MÃ©trica | Sin Dropout | Con Dropout |
|---------|-------------|-------------|
| Gap Train-Test | > 5% | < 3% |
| Test Accuracy | ~97% | ~98% |
| Overfitting | Visible | Reducido |

---

## ðŸ” Preguntas de ReflexiÃ³n

1. Â¿Por quÃ© el gap train-test es menor con Dropout?
2. Â¿QuÃ© pasarÃ­a si usamos `p=0.9`?
3. Â¿Por quÃ© es importante `model.eval()` en inferencia?

---

## ðŸ“š Recursos

- [PyTorch Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)
- [Dropout Paper (Srivastava 2014)](https://jmlr.org/papers/v15/srivastava14a.html)

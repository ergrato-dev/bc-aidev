# üìã R√∫brica de Evaluaci√≥n - Semana 27

## Optimizaci√≥n en Deep Learning

---

## üìä Distribuci√≥n de Puntos

| Componente | Puntos | Porcentaje |
|------------|--------|------------|
| Conocimiento (Teor√≠a) | 30 | 30% |
| Desempe√±o (Ejercicios) | 35 | 35% |
| Producto (Proyecto) | 35 | 35% |
| **Total** | **100** | **100%** |

---

## üß† Conocimiento (30 puntos)

### Conceptos Evaluados

| Tema | Puntos | Criterio |
|------|--------|----------|
| Optimizadores | 8 | Diferencia SGD/Adam/AdamW |
| Learning Rate | 8 | Schedules y su impacto |
| Inicializaci√≥n | 7 | Xavier vs He, cu√°ndo usar |
| Callbacks | 7 | Prop√≥sito y tipos |

### Niveles de Desempe√±o

| Nivel | Puntos | Descripci√≥n |
|-------|--------|-------------|
| Excelente | 27-30 | Explica trade-offs entre optimizadores |
| Bueno | 21-26 | Conoce los principales y cu√°ndo usarlos |
| Suficiente | 15-20 | Entiende conceptos b√°sicos |
| Insuficiente | <15 | Confunde optimizadores o schedules |

---

## üí™ Desempe√±o - Ejercicios (35 puntos)

### Ejercicio 01: Comparar Optimizadores (12 puntos)

| Criterio | Puntos | Descripci√≥n |
|----------|--------|-------------|
| Implementaci√≥n | 4 | SGD, Momentum, Adam, AdamW funcionan |
| Comparaci√≥n | 4 | Gr√°ficas de loss y accuracy |
| An√°lisis | 4 | Conclusiones sobre velocidad/estabilidad |

### Ejercicio 02: LR Schedules (12 puntos)

| Criterio | Puntos | Descripci√≥n |
|----------|--------|-------------|
| Schedules | 4 | StepLR, CosineAnnealing, OneCycle |
| Visualizaci√≥n | 4 | Curvas de LR por √©poca |
| Comparaci√≥n | 4 | Impacto en convergencia |

### Ejercicio 03: Callbacks (11 puntos)

| Criterio | Puntos | Descripci√≥n |
|----------|--------|-------------|
| EarlyStopping | 4 | Implementado correctamente |
| ModelCheckpoint | 4 | Guarda mejor modelo |
| Custom Callback | 3 | Logger o m√©trica custom |

---

## üì¶ Producto - Proyecto (35 puntos)

### Entrenador Optimizado

| Criterio | Puntos | Descripci√≥n |
|----------|--------|-------------|
| Arquitectura | 8 | Modelo con BatchNorm, Dropout |
| Optimizer | 7 | AdamW con weight decay |
| LR Schedule | 7 | OneCycleLR o Cosine configurado |
| Callbacks | 7 | Early stopping + checkpoint |
| Resultados | 6 | Test accuracy > 80% |

### Niveles de Calidad

| Nivel | Puntos | Descripci√≥n |
|-------|--------|-------------|
| Excelente | 32-35 | Pipeline robusto, m√©tricas logged |
| Bueno | 25-31 | Funcional con mejoras menores |
| Suficiente | 18-24 | B√°sico pero funciona |
| Insuficiente | <18 | No entrena o falla |

---

## ‚úÖ Checklist de Entrega

### Ejercicios
- [ ] Ejercicio 01: Gr√°ficas comparativas de optimizadores
- [ ] Ejercicio 02: Visualizaci√≥n de LR schedules
- [ ] Ejercicio 03: Callbacks implementados y funcionando

### Proyecto
- [ ] C√≥digo ejecutable sin errores
- [ ] Pipeline completo con todas las t√©cnicas
- [ ] Gr√°ficas de entrenamiento guardadas
- [ ] Test accuracy reportado

---

## üìÖ Fecha de Entrega

- **Ejercicios**: Final de semana 27
- **Proyecto**: Final de semana 27

---

## üí° Criterios de Aprobaci√≥n

- M√≠nimo **70%** en cada componente
- Todos los ejercicios deben ejecutar sin errores
- Proyecto debe completar entrenamiento exitosamente

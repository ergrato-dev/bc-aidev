# ðŸ–¼ï¸ IntroducciÃ³n a Redes Neuronales Convolucionales

## ðŸŽ¯ Objetivos

- Entender por quÃ© las CNNs revolucionaron la visiÃ³n por computadora
- Comprender las limitaciones de redes fully connected para imÃ¡genes
- Conocer la estructura general de una CNN
- Apreciar la inspiraciÃ³n biolÃ³gica de las CNNs

---

## ðŸ“‹ Contenido

### 1. El Problema de las ImÃ¡genes

Las redes fully connected tienen problemas graves con imÃ¡genes:

```python
# Una imagen pequeÃ±a de 28Ã—28 pÃ­xeles (MNIST)
imagen_mnist = 28 * 28  # = 784 neuronas de entrada

# Una imagen de 224Ã—224 RGB (ImageNet)
imagen_imagenet = 224 * 224 * 3  # = 150,528 neuronas de entrada

# Primera capa fully connected con 1000 neuronas
parametros_fc = 150_528 * 1000  # = 150,528,000 parÃ¡metros!
```

**Problemas de Fully Connected:**

| Problema | DescripciÃ³n |
|----------|-------------|
| **ExplosiÃ³n de parÃ¡metros** | Millones de parÃ¡metros para imÃ¡genes pequeÃ±as |
| **Sin estructura espacial** | Trata pÃ­xeles como independientes |
| **No invariante a traslaciÃ³n** | Un gato a la izquierda â‰  gato a la derecha |
| **Propenso a overfitting** | Demasiados parÃ¡metros, pocos datos |

---

### 2. La SoluciÃ³n: Convoluciones

Las CNNs resuelven estos problemas con tres ideas clave:

#### 2.1 Conexiones Locales

```
Fully Connected:              CNN:
Cada neurona conecta         Cada neurona conecta
con TODOS los pÃ­xeles        solo con una regiÃ³n local

[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ]           [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
       â†“                            â†“
    [â–ˆâ–ˆâ–ˆâ–ˆ]                       [â–ˆâ–ˆ]
```

#### 2.2 ParÃ¡metros Compartidos

El mismo filtro se aplica en todas las posiciones:

```python
# Fully Connected: cada conexiÃ³n tiene su propio peso
parametros_fc = entrada * salida

# CNN: el mismo kernel se usa en toda la imagen
parametros_conv = kernel_size * kernel_size * canales
# 3Ã—3Ã—3 = 27 parÃ¡metros vs millones
```

#### 2.3 Invarianza a TraslaciÃ³n

Un gato es un gato sin importar dÃ³nde estÃ© en la imagen:

```
Imagen 1:        Imagen 2:        Mismo filtro:
[ðŸ±â–‘â–‘â–‘â–‘]         [â–‘â–‘â–‘â–‘ðŸ±]         [âœ“ detecta gato]
[â–‘â–‘â–‘â–‘â–‘â–‘]         [â–‘â–‘â–‘â–‘â–‘â–‘]         [en ambas]
```

---

### 3. InspiraciÃ³n BiolÃ³gica

Las CNNs estÃ¡n inspiradas en el cÃ³rtex visual de los mamÃ­feros:

#### Experimento de Hubel & Wiesel (1959)

Descubrieron que el cÃ³rtex visual tiene:

- **CÃ©lulas simples**: Detectan bordes en orientaciones especÃ­ficas
- **CÃ©lulas complejas**: Responden a patrones mÃ¡s abstractos
- **JerarquÃ­a**: De caracterÃ­sticas simples a complejas

```
CÃ³rtex Visual             CNN
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€
V1: Bordes         â†’     Capa 1: Filtros de bordes
V2: Formas         â†’     Capa 2: Formas simples  
V4: Objetos        â†’     Capa 3: Partes de objetos
IT: CategorÃ­as     â†’     Capa final: ClasificaciÃ³n
```

---

### 4. Arquitectura General de una CNN

```
ENTRADA â†’ [CONV â†’ ReLU â†’ POOL]Ã—N â†’ FLATTEN â†’ FC â†’ SALIDA

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Imagen  â”‚ â†’ â”‚ Extractor de Featuresâ”‚ â†’ â”‚ Clasificadorâ”‚
â”‚ 224Ã—224 â”‚   â”‚ Conv + Pool layers   â”‚   â”‚ FC layers   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Componentes Principales

| Componente | FunciÃ³n | UbicaciÃ³n |
|------------|---------|-----------|
| **Conv** | Extrae caracterÃ­sticas locales | Capas iniciales |
| **ReLU** | Introduce no-linealidad | DespuÃ©s de cada conv |
| **Pool** | Reduce dimensionalidad | DespuÃ©s de bloques conv |
| **Flatten** | Convierte 3D â†’ 1D | TransiciÃ³n a FC |
| **FC** | ClasificaciÃ³n final | Capas finales |

---

### 5. EvoluciÃ³n de las CNNs

```
1998        2012         2014         2015         2016
 â”‚           â”‚            â”‚            â”‚            â”‚
 â–¼           â–¼            â–¼            â–¼            â–¼
LeNet    AlexNet        VGG        ResNet      DenseNet
 â”‚           â”‚            â”‚            â”‚            â”‚
 â””â”€â”€ DÃ­gitos â”‚            â”‚            â”‚            â”‚
             â””â”€â”€ ImageNet â”‚            â”‚            â”‚
                          â””â”€â”€ Profundidad           â”‚
                                       â””â”€â”€ Skip Connections
                                                    â””â”€â”€ Dense Connections
```

| AÃ±o | Modelo | InnovaciÃ³n | Capas |
|-----|--------|------------|-------|
| 1998 | LeNet-5 | Primera CNN prÃ¡ctica | 7 |
| 2012 | AlexNet | GPU, ReLU, Dropout | 8 |
| 2014 | VGG | Filtros 3Ã—3 uniformes | 16-19 |
| 2015 | ResNet | Skip connections | 152 |
| 2016 | DenseNet | Conexiones densas | 201 |

---

### 6. Por quÃ© Funcionan las CNNs

```python
# Las CNNs aprenden jerÃ¡rquicamente
# Capa 1: Detecta bordes y texturas simples
# Capa 2: Combina bordes en formas (cÃ­rculos, esquinas)
# Capa 3: Combina formas en partes (ojos, ruedas)
# Capa N: Combina partes en objetos (gatos, coches)

# Ejemplo conceptual
class ConceptualCNN:
    def forward(self, imagen):
        # Capa 1: Bordes
        bordes = self.conv1(imagen)  # "hay un borde vertical aquÃ­"
        
        # Capa 2: Formas
        formas = self.conv2(bordes)  # "hay un cÃ­rculo aquÃ­"
        
        # Capa 3: Partes
        partes = self.conv3(formas)  # "hay un ojo aquÃ­"
        
        # Clasificador
        clase = self.fc(partes)      # "esto es un gato"
        return clase
```

---

### 7. Ventajas de las CNNs

| Ventaja | DescripciÃ³n |
|---------|-------------|
| **Eficiencia** | Menos parÃ¡metros que fully connected |
| **Invarianza** | Detecta features sin importar posiciÃ³n |
| **JerarquÃ­a** | Aprende de simple a complejo |
| **Transfer Learning** | Features reutilizables entre tareas |

---

## ðŸ’» Ejemplo: CNN Simple en PyTorch

```python
import torch
import torch.nn as nn

class SimpleCNN(nn.Module):
    """CNN bÃ¡sica para clasificaciÃ³n de imÃ¡genes."""
    
    def __init__(self, num_classes: int = 10):
        super().__init__()
        
        # Extractor de caracterÃ­sticas
        self.features = nn.Sequential(
            # Bloque 1: 1 â†’ 32 canales
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # Reduce a la mitad
            
            # Bloque 2: 32 â†’ 64 canales
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),  # Reduce a la mitad
        )
        
        # Clasificador
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 7 * 7, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        x = self.features(x)
        x = self.classifier(x)
        return x

# Crear modelo
model = SimpleCNN(num_classes=10)

# Entrada de ejemplo: batch de 4 imÃ¡genes 28Ã—28 grayscale
x = torch.randn(4, 1, 28, 28)
output = model(x)
print(f"Input shape: {x.shape}")
print(f"Output shape: {output.shape}")  # [4, 10]
```

---

## ðŸ“š Recursos Adicionales

- ðŸ“– [CS231n: CNNs for Visual Recognition](https://cs231n.github.io/convolutional-networks/)
- ðŸ“„ Paper original LeNet: "Gradient-Based Learning Applied to Document Recognition" (LeCun, 1998)
- ðŸŽ¥ [3Blue1Brown: But what is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA)

---

## âœ… Checklist de VerificaciÃ³n

- [ ] Entiendo por quÃ© FC no escala para imÃ¡genes
- [ ] Conozco las tres ideas clave de las CNNs
- [ ] SÃ© quÃ© hace cada componente (Conv, ReLU, Pool, FC)
- [ ] Puedo describir la jerarquÃ­a de features
- [ ] Conozco la evoluciÃ³n histÃ³rica de las CNNs

---

_Siguiente: [OperaciÃ³n de ConvoluciÃ³n](02-operacion-convolucion.md)_

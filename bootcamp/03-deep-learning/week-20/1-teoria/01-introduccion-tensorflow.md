# ğŸ”· IntroducciÃ³n a TensorFlow

## ğŸ¯ Objetivos

- Comprender quÃ© es TensorFlow y su ecosistema
- Entender la arquitectura de tensores y grafos
- Conocer las diferencias entre TensorFlow 1.x y 2.x
- Configurar el entorno de trabajo correctamente

---

## ğŸ“š Contenido

### 1. Â¿QuÃ© es TensorFlow?

**TensorFlow** es una plataforma de cÃ³digo abierto para Machine Learning desarrollada por Google Brain. Es el framework de deep learning mÃ¡s utilizado en la industria.

```python
import tensorflow as tf

# Verificar versiÃ³n instalada
print(f"TensorFlow version: {tf.__version__}")

# Verificar si hay GPU disponible
gpus = tf.config.list_physical_devices('GPU')
print(f"GPUs disponibles: {len(gpus)}")
```

#### Â¿Por quÃ© TensorFlow?

| CaracterÃ­stica        | Beneficio                                      |
| --------------------- | ---------------------------------------------- |
| **Escalabilidad**     | Desde mÃ³viles hasta clusters de servidores     |
| **ProducciÃ³n**        | TensorFlow Serving para deployment             |
| **Ecosistema**        | TensorBoard, TF Lite, TF.js, TFX               |
| **Comunidad**         | DocumentaciÃ³n extensa, ejemplos, tutoriales    |
| **Keras Integrado**   | API de alto nivel incluida                     |

---

### 2. Arquitectura de TensorFlow

![Arquitectura TensorFlow](../0-assets/01-tensorflow-arquitectura.svg)

#### 2.1 Tensores: La Unidad BÃ¡sica

Un **tensor** es un array n-dimensional, la estructura de datos fundamental:

```python
import tensorflow as tf
import numpy as np

# Tensor escalar (0-D)
scalar = tf.constant(42)
print(f"Escalar: {scalar}, shape: {scalar.shape}, dtype: {scalar.dtype}")

# Tensor vector (1-D)
vector = tf.constant([1.0, 2.0, 3.0, 4.0])
print(f"Vector: {vector}, shape: {vector.shape}")

# Tensor matriz (2-D)
matrix = tf.constant([[1, 2, 3],
                      [4, 5, 6]])
print(f"Matriz shape: {matrix.shape}")

# Tensor 3-D (tÃ­pico para imÃ¡genes en batch)
tensor_3d = tf.constant([
    [[1, 2], [3, 4]],
    [[5, 6], [7, 8]]
])
print(f"3D tensor shape: {tensor_3d.shape}")  # (2, 2, 2)
```

#### 2.2 Tipos de Datos (dtypes)

```python
# Tipos mÃ¡s comunes
tf.float32   # MÃ¡s usado para pesos de redes neuronales
tf.float64   # Mayor precisiÃ³n, mÃ¡s lento
tf.int32     # Enteros, para Ã­ndices
tf.int64     # Enteros largos
tf.bool      # Booleanos
tf.string    # Texto

# Especificar dtype al crear tensor
weights = tf.constant([0.1, 0.2, 0.3], dtype=tf.float32)
labels = tf.constant([0, 1, 2], dtype=tf.int32)
```

---

### 3. TensorFlow 2.x: EjecuciÃ³n Eager

En TensorFlow 2.x, la **ejecuciÃ³n eager** estÃ¡ habilitada por defecto:

```python
# TensorFlow 1.x (antiguo) - RequerÃ­a sesiones
# with tf.Session() as sess:
#     result = sess.run(operation)

# TensorFlow 2.x (actual) - EjecuciÃ³n inmediata
a = tf.constant([1, 2, 3])
b = tf.constant([4, 5, 6])
c = a + b  # Se ejecuta inmediatamente
print(c)  # tf.Tensor([5 7 9], shape=(3,), dtype=int32)

# Convertir a NumPy fÃ¡cilmente
numpy_array = c.numpy()
print(type(numpy_array))  # <class 'numpy.ndarray'>
```

#### Ventajas de Eager Execution

1. **Debugging intuitivo**: Puedes usar print() y pdb
2. **Flujo natural de Python**: Sin necesidad de sesiones
3. **Interoperabilidad con NumPy**: ConversiÃ³n directa

---

### 4. Operaciones con Tensores

#### 4.1 Operaciones MatemÃ¡ticas

```python
import tensorflow as tf

a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
b = tf.constant([[5.0, 6.0], [7.0, 8.0]])

# Operaciones elemento a elemento
print("Suma:", tf.add(a, b))          # o simplemente: a + b
print("Resta:", tf.subtract(a, b))    # o: a - b
print("MultiplicaciÃ³n:", tf.multiply(a, b))  # o: a * b
print("DivisiÃ³n:", tf.divide(a, b))   # o: a / b

# Operaciones matriciales
print("Matmul:", tf.matmul(a, b))     # o: a @ b

# Funciones matemÃ¡ticas
print("RaÃ­z cuadrada:", tf.sqrt(a))
print("Exponencial:", tf.exp(a))
print("Logaritmo:", tf.math.log(a))
```

#### 4.2 ReducciÃ³n y AgregaciÃ³n

```python
tensor = tf.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.float32)

# ReducciÃ³n sobre todo el tensor
print("Suma total:", tf.reduce_sum(tensor))
print("Media:", tf.reduce_mean(tensor))
print("MÃ¡ximo:", tf.reduce_max(tensor))
print("MÃ­nimo:", tf.reduce_min(tensor))

# ReducciÃ³n sobre un eje especÃ­fico
print("Suma por filas:", tf.reduce_sum(tensor, axis=1))  # [6, 15]
print("Suma por columnas:", tf.reduce_sum(tensor, axis=0))  # [5, 7, 9]
```

#### 4.3 Reshape y ManipulaciÃ³n

```python
# Reshape
original = tf.constant([[1, 2, 3], [4, 5, 6]])
reshaped = tf.reshape(original, [3, 2])
print(f"Original: {original.shape} -> Reshaped: {reshaped.shape}")

# Transpose
transposed = tf.transpose(original)
print(f"Transpuesta: {transposed.shape}")

# Expand dims (aÃ±adir dimensiÃ³n)
expanded = tf.expand_dims(original, axis=0)  # Para batch
print(f"Expandido: {expanded.shape}")  # (1, 2, 3)

# Squeeze (eliminar dimensiones de tamaÃ±o 1)
squeezed = tf.squeeze(expanded)
print(f"Squeezed: {squeezed.shape}")  # (2, 3)
```

---

### 5. Variables: Pesos Entrenables

Los **tensores constantes** son inmutables. Para pesos de redes neuronales, usamos **Variables**:

```python
# Crear una variable (peso entrenable)
weights = tf.Variable(
    initial_value=tf.random.normal([3, 2]),
    trainable=True,
    name="layer_weights"
)
print(f"Weights: {weights.shape}")

# Las variables se pueden modificar
weights.assign(weights * 2)  # Multiplicar por 2
weights.assign_add(tf.ones_like(weights))  # Sumar 1

# Inicializadores comunes para pesos
glorot_init = tf.keras.initializers.GlorotUniform()
he_init = tf.keras.initializers.HeNormal()

# Crear variable con inicializador
layer_weights = tf.Variable(
    initial_value=glorot_init(shape=[784, 256]),
    trainable=True
)
```

---

### 6. GradientTape: DiferenciaciÃ³n AutomÃ¡tica

TensorFlow calcula gradientes automÃ¡ticamente con `tf.GradientTape`:

```python
# Ejemplo simple de gradiente
x = tf.Variable(3.0)

with tf.GradientTape() as tape:
    y = x ** 2  # y = xÂ²

# dy/dx = 2x, cuando x=3, gradiente = 6
grad = tape.gradient(y, x)
print(f"Gradiente de xÂ² en x=3: {grad}")  # 6.0

# Ejemplo con mÃºltiples variables (como en una red neuronal)
w = tf.Variable(tf.random.normal([2, 1]))
b = tf.Variable(tf.zeros([1]))
x = tf.constant([[1.0, 2.0], [3.0, 4.0]])
y_true = tf.constant([[1.0], [0.0]])

with tf.GradientTape() as tape:
    # Forward pass
    y_pred = tf.sigmoid(tf.matmul(x, w) + b)
    # Loss
    loss = tf.reduce_mean((y_true - y_pred) ** 2)

# Calcular gradientes respecto a w y b
gradients = tape.gradient(loss, [w, b])
print(f"Gradiente de w: {gradients[0].shape}")
print(f"Gradiente de b: {gradients[1].shape}")
```

---

### 7. El Ecosistema TensorFlow

```
                    TensorFlow Ecosystem
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                             â”‚
    â”‚   ğŸ”§ TensorFlow Core (Bajo nivel)           â”‚
    â”‚                                             â”‚
    â”‚   ğŸ¯ Keras (Alto nivel) - ESTA SEMANA       â”‚
    â”‚                                             â”‚
    â”‚   ğŸ“Š TensorBoard (VisualizaciÃ³n)            â”‚
    â”‚                                             â”‚
    â”‚   ğŸ“± TF Lite (Mobile/Edge)                  â”‚
    â”‚                                             â”‚
    â”‚   ğŸŒ TF.js (JavaScript)                     â”‚
    â”‚                                             â”‚
    â”‚   ğŸ­ TFX (ProducciÃ³n/MLOps)                 â”‚
    â”‚                                             â”‚
    â”‚   ğŸ”„ TF Data (Pipelines de datos)           â”‚
    â”‚                                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 8. ConfiguraciÃ³n del Entorno

```python
import tensorflow as tf

# Verificar instalaciÃ³n
print(f"TensorFlow: {tf.__version__}")

# Configurar memoria GPU (si hay)
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        # Permitir crecimiento dinÃ¡mico de memoria
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"GPU configurada: {gpus}")
    except RuntimeError as e:
        print(e)
else:
    print("No se detectÃ³ GPU, usando CPU")

# Establecer seed para reproducibilidad
tf.random.set_seed(42)
```

---

## ğŸ’¡ Resumen

| Concepto           | DescripciÃ³n                                           |
| ------------------ | ----------------------------------------------------- |
| **Tensor**         | Array n-dimensional, unidad bÃ¡sica de datos           |
| **Variable**       | Tensor mutable para pesos entrenables                 |
| **GradientTape**   | Contexto para calcular gradientes automÃ¡ticamente     |
| **Eager Execution**| EvaluaciÃ³n inmediata (por defecto en TF 2.x)          |
| **dtype**          | Tipo de datos del tensor (float32, int32, etc.)       |

---

## âœ… VerificaciÃ³n de Aprendizaje

- [ ] Puedo crear tensores de diferentes dimensiones
- [ ] Entiendo la diferencia entre Constant y Variable
- [ ] SÃ© usar GradientTape para calcular gradientes
- [ ] Puedo realizar operaciones matemÃ¡ticas con tensores
- [ ] Comprendo el ecosistema de TensorFlow

---

_Siguiente: [02-keras-api-sequential.md](02-keras-api-sequential.md)_

# ðŸ”¢ Proyecto: Clasificador MNIST con Keras

## ðŸŽ¯ Objetivo

Construir un clasificador de dÃ­gitos escritos a mano utilizando TensorFlow/Keras, aplicando todos los conceptos aprendidos durante la semana: API Sequential, capas, compilaciÃ³n, callbacks y guardado de modelos.

## â±ï¸ DuraciÃ³n

2 horas

## ðŸ“‹ DescripciÃ³n del Proyecto

El dataset MNIST contiene 70,000 imÃ¡genes de dÃ­gitos escritos a mano (0-9), cada una de 28x28 pÃ­xeles en escala de grises. Tu tarea es construir una red neuronal que clasifique estos dÃ­gitos con al menos **97% de accuracy** en el conjunto de test.

---

## ðŸ“Š El Dataset

```
MNIST Dataset:
â”œâ”€â”€ Entrenamiento: 60,000 imÃ¡genes
â”œâ”€â”€ Test: 10,000 imÃ¡genes
â”œâ”€â”€ TamaÃ±o: 28x28 pÃ­xeles
â”œâ”€â”€ Canales: 1 (grayscale)
â”œâ”€â”€ Clases: 10 (dÃ­gitos 0-9)
â””â”€â”€ Formato: numpy arrays
```

---

## ðŸŽ¯ Requisitos del Proyecto

### Requisitos MÃ­nimos (70%)

1. **Preprocesamiento correcto**
   - NormalizaciÃ³n de pÃ­xeles (0-255 â†’ 0-1)
   - Reshape apropiado para el modelo
   - Split de validaciÃ³n

2. **Arquitectura del modelo**
   - MÃ­nimo 2 capas ocultas
   - Activaciones apropiadas
   - Capa de salida con softmax

3. **Entrenamiento**
   - CompilaciÃ³n con optimizer, loss y metrics
   - Al menos 1 callback implementado
   - Accuracy â‰¥ 95% en test

### Requisitos Intermedios (85%)

4. **RegularizaciÃ³n**
   - Dropout en capas ocultas
   - BatchNormalization opcional

5. **Callbacks completos**
   - EarlyStopping
   - ModelCheckpoint

6. **MÃ©tricas**
   - Accuracy â‰¥ 97% en test
   - VisualizaciÃ³n de curvas de entrenamiento

### Requisitos Avanzados (100%)

7. **OptimizaciÃ³n**
   - ReduceLROnPlateau
   - ExperimentaciÃ³n con hiperparÃ¡metros

8. **EvaluaciÃ³n completa**
   - Matriz de confusiÃ³n
   - VisualizaciÃ³n de predicciones incorrectas
   - Accuracy â‰¥ 98% en test

9. **DocumentaciÃ³n**
   - CÃ³digo comentado
   - Decisiones justificadas
   - Modelo exportado

---

## ðŸ—‚ï¸ Estructura del Proyecto

```
clasificador-mnist/
â”œâ”€â”€ README.md              # Este archivo
â”œâ”€â”€ starter/
â”‚   â””â”€â”€ main.py           # Plantilla con TODOs
â”œâ”€â”€ solution/
â”‚   â””â”€â”€ main.py           # SoluciÃ³n de referencia
â””â”€â”€ outputs/              # Generado durante ejecuciÃ³n
    â”œâ”€â”€ best_model.keras
    â”œâ”€â”€ training_history.png
    â””â”€â”€ confusion_matrix.png
```

---

## ðŸ“ Instrucciones

### Paso 1: Cargar y Explorar Datos

```python
from tensorflow.keras.datasets import mnist

(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Explorar shapes y valores
print(f"Train: {X_train.shape}")  # (60000, 28, 28)
print(f"Valores: min={X_train.min()}, max={X_train.max()}")
```

### Paso 2: Preprocesar

```python
# Aplanar: (60000, 28, 28) â†’ (60000, 784)
X_train = X_train.reshape(-1, 784).astype('float32') / 255.0
X_test = X_test.reshape(-1, 784).astype('float32') / 255.0

# Separar validaciÃ³n
X_val, y_val = X_train[:6000], y_train[:6000]
X_train, y_train = X_train[6000:], y_train[6000:]
```

### Paso 3: DiseÃ±ar Arquitectura

Experimenta con diferentes configuraciones:

```python
model = Sequential([
    # TODO: DiseÃ±ar arquitectura
    # - Input: 784 features
    # - Hidden layers con ReLU
    # - RegularizaciÃ³n (Dropout/BatchNorm)
    # - Output: 10 clases con softmax
])
```

### Paso 4: Compilar

```python
model.compile(
    optimizer='adam',  # Experimentar con learning rate
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

### Paso 5: Configurar Callbacks

```python
callbacks = [
    # TODO: EarlyStopping
    # TODO: ModelCheckpoint
    # TODO: ReduceLROnPlateau (opcional)
]
```

### Paso 6: Entrenar

```python
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=128,
    validation_data=(X_val, y_val),
    callbacks=callbacks
)
```

### Paso 7: Evaluar

```python
# EvaluaciÃ³n en test
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc:.4f}")

# Matriz de confusiÃ³n
from sklearn.metrics import confusion_matrix
y_pred = model.predict(X_test).argmax(axis=1)
cm = confusion_matrix(y_test, y_pred)
```

### Paso 8: Visualizar

```python
# Curvas de entrenamiento
# Matriz de confusiÃ³n
# Predicciones incorrectas
```

---

## ðŸŽ¨ Arquitectura Sugerida

Punto de partida recomendado:

```
Input (784)
    â†“
Dense(256) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.3)
    â†“
Dense(128) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.3)
    â†“
Dense(64) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2)
    â†“
Dense(10) â†’ Softmax
    â†“
Output (10 probabilidades)
```

---

## ðŸ“ˆ MÃ©tricas Objetivo

| MÃ©trica      | MÃ­nimo | Esperado | Excelente |
| ------------ | ------ | -------- | --------- |
| Test Accuracy | 95%   | 97%      | >98%      |
| Val Loss     | <0.15  | <0.10    | <0.08     |

---

## ðŸ’¡ Tips

1. **Empieza simple**: Un modelo bÃ¡sico primero, luego aÃ±ade complejidad
2. **Monitorea overfitting**: Si train_acc >> val_acc, aÃ±ade regularizaciÃ³n
3. **Learning rate**: Si el loss oscila mucho, reduce el learning rate
4. **Batch size**: 32-128 suelen funcionar bien
5. **Paciencia**: Usa EarlyStopping con patience suficiente (5-10)

---

## âœ… Checklist de Entrega

- [ ] CÃ³digo ejecutable sin errores
- [ ] Preprocesamiento correcto
- [ ] Modelo con arquitectura justificada
- [ ] Callbacks implementados
- [ ] Test accuracy â‰¥ 97%
- [ ] Visualizaciones generadas
- [ ] Modelo guardado en .keras
- [ ] CÃ³digo comentado

---

## ðŸ“š Recursos

- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)
- [Keras Sequential API](https://keras.io/guides/sequential_model/)
- [Keras Callbacks](https://keras.io/api/callbacks/)

---

_Proyecto Semana 20 | TensorFlow y Keras | Bootcamp IA: Zero to Hero_

# ðŸ§  Semana 19: Fundamentos de Redes Neuronales

## ðŸŽ¯ Objetivos de Aprendizaje

Al finalizar esta semana, serÃ¡s capaz de:

- âœ… Comprender la inspiraciÃ³n biolÃ³gica de las redes neuronales
- âœ… Implementar un perceptrÃ³n desde cero
- âœ… Entender el algoritmo de backpropagation matemÃ¡ticamente
- âœ… Conocer las funciones de activaciÃ³n y sus propiedades
- âœ… Construir una red neuronal multicapa con NumPy

---

## ðŸ“š Requisitos Previos

- MÃ³dulo 2: Machine Learning completado
- Ãlgebra lineal (matrices, vectores, multiplicaciÃ³n)
- CÃ¡lculo bÃ¡sico (derivadas, regla de la cadena)
- NumPy dominado

---

## ðŸ—‚ï¸ Estructura de la Semana

```
week-19/
â”œâ”€â”€ README.md
â”œâ”€â”€ rubrica-evaluacion.md
â”œâ”€â”€ 0-assets/
â”‚   â”œâ”€â”€ 01-neurona-biologica-vs-artificial.svg
â”‚   â”œâ”€â”€ 02-perceptron-arquitectura.svg
â”‚   â”œâ”€â”€ 03-funciones-activacion.svg
â”‚   â””â”€â”€ 04-backpropagation-flow.svg
â”œâ”€â”€ 1-teoria/
â”‚   â”œâ”€â”€ 01-introduccion-redes-neuronales.md
â”‚   â”œâ”€â”€ 02-perceptron.md
â”‚   â”œâ”€â”€ 03-funciones-activacion.md
â”‚   â””â”€â”€ 04-backpropagation.md
â”œâ”€â”€ 2-practicas/
â”‚   â”œâ”€â”€ ejercicio-01-perceptron/
â”‚   â”œâ”€â”€ ejercicio-02-funciones-activacion/
â”‚   â””â”€â”€ ejercicio-03-mlp-numpy/
â”œâ”€â”€ 3-proyecto/
â”‚   â””â”€â”€ red-neuronal-desde-cero/
â”œâ”€â”€ 4-recursos/
â””â”€â”€ 5-glosario/
```

---

## ðŸ“ Contenidos

### ðŸ“– TeorÃ­a (1.5 horas)

| #   | Tema                            | Archivo                                                                             | DuraciÃ³n |
| --- | ------------------------------- | ----------------------------------------------------------------------------------- | -------- |
| 1   | IntroducciÃ³n a Redes Neuronales | [01-introduccion-redes-neuronales.md](1-teoria/01-introduccion-redes-neuronales.md) | 20 min   |
| 2   | El PerceptrÃ³n                   | [02-perceptron.md](1-teoria/02-perceptron.md)                                       | 25 min   |
| 3   | Funciones de ActivaciÃ³n         | [03-funciones-activacion.md](1-teoria/03-funciones-activacion.md)                   | 20 min   |
| 4   | Backpropagation                 | [04-backpropagation.md](1-teoria/04-backpropagation.md)                             | 25 min   |

### ðŸ’» PrÃ¡cticas (2.5 horas)

| #   | Ejercicio               | Carpeta                                                                              | DuraciÃ³n |
| --- | ----------------------- | ------------------------------------------------------------------------------------ | -------- |
| 1   | PerceptrÃ³n Simple       | [ejercicio-01-perceptron/](2-practicas/ejercicio-01-perceptron/)                     | 45 min   |
| 2   | Funciones de ActivaciÃ³n | [ejercicio-02-funciones-activacion/](2-practicas/ejercicio-02-funciones-activacion/) | 45 min   |
| 3   | MLP con NumPy           | [ejercicio-03-mlp-numpy/](2-practicas/ejercicio-03-mlp-numpy/)                       | 60 min   |

### ðŸ“¦ Proyecto (2 horas)

| Proyecto                | DescripciÃ³n                                 | Carpeta                                                         |
| ----------------------- | ------------------------------------------- | --------------------------------------------------------------- |
| Red Neuronal desde Cero | Clasificador binario implementado con NumPy | [red-neuronal-desde-cero/](3-proyecto/red-neuronal-desde-cero/) |

---

## â±ï¸ DistribuciÃ³n del Tiempo

```
Total: 6 horas

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ðŸ“– TeorÃ­a      â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  1.5h (25%)  â”‚
â”‚  ðŸ’» PrÃ¡cticas   â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  2.5h (42%)  â”‚
â”‚  ðŸ“¦ Proyecto    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚  2.0h (33%)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Œ Entregables

1. **Ejercicios completados** (2-practicas/)

   - [ ] PerceptrÃ³n clasificando AND y OR
   - [ ] VisualizaciÃ³n de funciones de activaciÃ³n
   - [ ] MLP forward pass implementado

2. **Proyecto semanal** (3-proyecto/)
   - [ ] Red neuronal multicapa funcional
   - [ ] Backpropagation implementado correctamente
   - [ ] Entrenamiento en dataset sintÃ©tico
   - [ ] DocumentaciÃ³n del proceso

---

## ðŸ”‘ Conceptos Clave

- **Neurona artificial**: Unidad bÃ¡sica que recibe inputs, aplica pesos y una funciÃ³n de activaciÃ³n
- **PerceptrÃ³n**: Red neuronal de una sola capa para clasificaciÃ³n lineal
- **FunciÃ³n de activaciÃ³n**: Introduce no-linealidad (sigmoid, tanh, ReLU)
- **Forward propagation**: Flujo de datos desde input hasta output
- **Backpropagation**: Algoritmo para calcular gradientes usando regla de la cadena
- **Gradient descent**: OptimizaciÃ³n de pesos usando los gradientes calculados

---

## ðŸ”— NavegaciÃ³n

| â¬…ï¸ Anterior                                              | ðŸ  MÃ³dulo                     | Siguiente âž¡ï¸                      |
| -------------------------------------------------------- | ----------------------------- | --------------------------------- |
| [Semana 18](../../02-machine-learning/week-18/README.md) | [Deep Learning](../README.md) | [Semana 20](../week-20/README.md) |

---

## ðŸ’¡ Tips para esta Semana

> ðŸŽ¯ **Consejo**: Entender backpropagation es FUNDAMENTAL. No te saltes las matemÃ¡ticas - dibuja los grafos de computaciÃ³n y calcula las derivadas a mano al menos una vez.

- **Dibuja**: Visualiza las redes y el flujo de gradientes
- **Deriva**: Calcula las derivadas de las funciones de activaciÃ³n a mano
- **Implementa**: No uses frameworks esta semana, todo con NumPy
- **Verifica**: Usa gradient checking para validar tu implementaciÃ³n

---

## ðŸ“š Recursos RÃ¡pidos

- ðŸ“– [3Blue1Brown - Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- ðŸ“– [Neural Networks and Deep Learning (Michael Nielsen)](http://neuralnetworksanddeeplearning.com/)
- ðŸ”¬ [Backpropagation Calculus - 3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8)

---

_Semana 19 de 36 | MÃ³dulo: Deep Learning | Bootcamp IA: Zero to Hero_

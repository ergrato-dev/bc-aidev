# И Ejercicio 02: Funciones de Activaci贸n

##  Objetivo

Implementar y visualizar las principales funciones de activaci贸n y sus derivadas.

---

##  Instrucciones

Abre `starter/main.py` y sigue los pasos descomentando el c贸digo.

---

##  Conceptos Clave

- Sigmoid, Tanh, ReLU
- Derivadas para backpropagation
- Vanishing gradient problem
- Cu谩ndo usar cada funci贸n

---

## 憋 Duraci贸n

45 minutos

# üìã R√∫brica de Evaluaci√≥n - Semana 19

## üß† Fundamentos de Redes Neuronales

---

## üìä Distribuci√≥n de Puntos

| Componente               | Porcentaje | Puntos  |
| ------------------------ | ---------- | ------- |
| üß† Conocimiento          | 30%        | 30      |
| üí™ Desempe√±o (Pr√°cticas) | 35%        | 35      |
| üì¶ Producto (Proyecto)   | 35%        | 35      |
| **Total**                | **100%**   | **100** |

---

## üß† Conocimiento (30 puntos)

### Conceptos Te√≥ricos

| Criterio                                            | Puntos |
| --------------------------------------------------- | ------ |
| Explica la analog√≠a neurona biol√≥gica vs artificial | 5      |
| Describe el algoritmo del perceptr√≥n                | 5      |
| Conoce propiedades de funciones de activaci√≥n       | 8      |
| Entiende backpropagation y regla de la cadena       | 12     |

### Niveles de Desempe√±o - Conocimiento

| Nivel        | Rango | Descripci√≥n                              |
| ------------ | ----- | ---------------------------------------- |
| Insuficiente | 0-17  | No comprende los conceptos fundamentales |
| Suficiente   | 18-21 | Comprensi√≥n b√°sica de redes neuronales   |
| Bueno        | 22-26 | Entiende matem√°ticas de backpropagation  |
| Excelente    | 27-30 | Domina teor√≠a y puede derivar ecuaciones |

---

## üí™ Desempe√±o - Pr√°cticas (35 puntos)

### Ejercicio 1: Perceptr√≥n (10 puntos)

| Criterio                              | Puntos |
| ------------------------------------- | ------ |
| Implementa forward pass correctamente | 3      |
| Implementa regla de aprendizaje       | 4      |
| Clasifica correctamente AND y OR      | 3      |

### Ejercicio 2: Funciones de Activaci√≥n (10 puntos)

| Criterio                              | Puntos |
| ------------------------------------- | ------ |
| Implementa sigmoid y su derivada      | 3      |
| Implementa tanh y su derivada         | 3      |
| Implementa ReLU y variantes           | 2      |
| Visualiza correctamente las funciones | 2      |

### Ejercicio 3: MLP con NumPy (15 puntos)

| Criterio                                    | Puntos |
| ------------------------------------------- | ------ |
| Forward propagation correcto                | 5      |
| Arquitectura configurable (capas/neuronas)  | 4      |
| C√≥digo vectorizado (sin loops innecesarios) | 4      |
| Documentaci√≥n clara                         | 2      |

---

## üì¶ Producto - Proyecto (35 puntos)

### Red Neuronal desde Cero

| Criterio                           | Puntos |
| ---------------------------------- | ------ |
| **Arquitectura** (10 pts)          |        |
| - Inicializaci√≥n de pesos correcta | 3      |
| - Forward pass multicapa           | 4      |
| - Estructura modular y extensible  | 3      |
| **Backpropagation** (15 pts)       |        |
| - C√°lculo de gradientes correcto   | 8      |
| - Actualizaci√≥n de pesos y biases  | 4      |
| - Gradient checking implementado   | 3      |
| **Entrenamiento** (10 pts)         |        |
| - Loop de entrenamiento funcional  | 3      |
| - Tracking de loss por √©poca       | 2      |
| - Convergencia demostrada          | 3      |
| - Visualizaci√≥n del proceso        | 2      |

---

## üéØ Criterios de Aprobaci√≥n

- ‚úÖ M√≠nimo **70%** en cada componente
- ‚úÖ Proyecto funcional con backpropagation correcto
- ‚úÖ Implementaci√≥n sin usar frameworks de DL
- ‚úÖ Gradient checking con error < 1e-5

---

## ‚≠ê Puntos Extra (hasta +10)

| Criterio                                    | Puntos |
| ------------------------------------------- | ------ |
| Implementa momentum o Adam optimizer        | +3     |
| A√±ade regularizaci√≥n L2                     | +2     |
| Implementa mini-batch gradient descent      | +3     |
| Visualizaci√≥n interactiva del entrenamiento | +2     |

---

## ‚ö†Ô∏è Penalizaciones

| Criterio                                   | Puntos |
| ------------------------------------------ | ------ |
| Usar TensorFlow/PyTorch/Keras              | -20    |
| C√≥digo copiado sin entender                | -15    |
| No implementar backpropagation manualmente | -20    |
| Gradientes incorrectos (error > 1e-3)      | -10    |

---

## üìù Notas

- Esta semana es FUNDAMENTAL para entender deep learning
- La implementaci√≥n manual construye intuici√≥n profunda
- Frameworks vendr√°n en semanas siguientes
- Los gradientes deben verificarse num√©ricamente

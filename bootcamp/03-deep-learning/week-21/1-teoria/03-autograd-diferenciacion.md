# ‚ö° Autograd: Diferenciaci√≥n Autom√°tica

## üéØ Objetivos

- Comprender el sistema de diferenciaci√≥n autom√°tica de PyTorch
- Dominar `requires_grad` y el grafo computacional
- Usar `backward()` para calcular gradientes
- Aplicar `torch.no_grad()` y `detach()` correctamente

---

## 1. ¬øQu√© es Autograd?

**Autograd** es el motor de diferenciaci√≥n autom√°tica de PyTorch. Permite calcular gradientes autom√°ticamente sin derivar f√≥rmulas manualmente.

```python
import torch

# Crear tensor con seguimiento de gradientes
x = torch.tensor([2.0], requires_grad=True)

# Operaci√≥n: y = x¬≤
y = x ** 2

# Calcular gradiente: dy/dx = 2x
y.backward()

print(f"x = {x.item()}")
print(f"y = x¬≤ = {y.item()}")
print(f"dy/dx = 2x = {x.grad.item()}")  # 4.0
```

---

## 2. Grafo Computacional

![Grafo Computacional](../0-assets/03-autograd-computational-graph.svg)

PyTorch construye un **grafo computacional din√°mico** durante el forward pass:

```python
import torch

# Variables de entrada
a = torch.tensor([2.0], requires_grad=True)
b = torch.tensor([3.0], requires_grad=True)

# Forward pass (construye el grafo)
c = a * b       # MulBackward
d = c + a       # AddBackward
e = d ** 2      # PowBackward

# El grafo se construye autom√°ticamente
print(f"e.grad_fn: {e.grad_fn}")  # PowBackward

# Backward pass (calcula gradientes siguiendo el grafo)
e.backward()

print(f"de/da = {a.grad.item()}")  # 56.0
print(f"de/db = {b.grad.item()}")  # 32.0
```

### ¬øC√≥mo funciona?

```
Forward:
a=2 ‚îÄ‚î¨‚îÄ‚Üí [√ó] ‚Üí c=6 ‚îÄ‚îÄ‚Üí [+] ‚Üí d=8 ‚îÄ‚îÄ‚Üí [¬≤] ‚Üí e=64
     ‚îÇ              ‚Üó
b=3 ‚îÄ‚îò          a=2

Backward (cadena de derivadas):
de/da = de/dd √ó dd/dc √ó dc/da + de/dd √ó dd/da
      = 2d    √ó 1     √ó b     + 2d    √ó 1
      = 16    √ó 1     √ó 3     + 16    √ó 1
      = 48 + 8 = 56
```

---

## 3. requires_grad

El flag `requires_grad` indica si PyTorch debe rastrear operaciones para calcular gradientes:

```python
import torch

# Con requires_grad=True
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
y = x.sum() ** 2
y.backward()
print(f"Gradiente: {x.grad}")

# Sin requires_grad (default)
z = torch.tensor([1.0, 2.0, 3.0])  # requires_grad=False
print(f"requires_grad: {z.requires_grad}")  # False

# Activar requires_grad despu√©s
z.requires_grad_(True)  # In-place
print(f"requires_grad: {z.requires_grad}")  # True

# Los resultados heredan requires_grad
a = torch.rand(3, requires_grad=True)
b = torch.rand(3)  # No requiere grad
c = a + b
print(f"c.requires_grad: {c.requires_grad}")  # True (hereda de a)
```

---

## 4. backward() en Detalle

### Caso Escalar

```python
# Si el output es escalar, no necesita argumentos
x = torch.tensor([2.0], requires_grad=True)
y = x ** 3  # y = x¬≥
y.backward()  # dy/dx = 3x¬≤ = 12
print(f"Gradiente: {x.grad}")  # tensor([12.])
```

### Caso Vector/Matriz

```python
# Si el output NO es escalar, necesita un "vector gradiente"
x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
y = x ** 2  # y = [1, 4, 9]

# Necesitamos un vector del mismo tama√±o
# T√≠picamente usamos loss.sum() o loss.mean() para obtener escalar
loss = y.sum()  # Ahora es escalar
loss.backward()
print(f"Gradiente: {x.grad}")  # [2., 4., 6.] = 2x

# Alternativa: pasar gradient directamente
x.grad.zero_()  # Limpiar gradientes previos
y = x ** 2
y.backward(torch.ones_like(y))  # Vector de unos
print(f"Gradiente: {x.grad}")  # [2., 4., 6.]
```

---

## 5. Acumulaci√≥n de Gradientes

PyTorch **acumula** gradientes por defecto. Hay que limpiarlos manualmente:

```python
import torch

x = torch.tensor([2.0], requires_grad=True)

# Primera backward
y1 = x ** 2
y1.backward()
print(f"Grad despu√©s de y1: {x.grad}")  # 4.0

# Segunda backward (se acumula!)
y2 = x ** 3
y2.backward()
print(f"Grad despu√©s de y2: {x.grad}")  # 4.0 + 12.0 = 16.0

# Limpiar gradientes
x.grad.zero_()  # o x.grad = None
y3 = x ** 2
y3.backward()
print(f"Grad despu√©s de limpiar: {x.grad}")  # 4.0
```

### En Training Loop

```python
# Patr√≥n est√°ndar
optimizer = torch.optim.SGD([x], lr=0.01)

for epoch in range(100):
    # 1. Limpiar gradientes
    optimizer.zero_grad()
    
    # 2. Forward
    y = model(x)
    loss = criterion(y, target)
    
    # 3. Backward
    loss.backward()
    
    # 4. Actualizar par√°metros
    optimizer.step()
```

---

## 6. torch.no_grad()

Desactiva el c√°lculo de gradientes para mejorar rendimiento:

```python
import torch

x = torch.tensor([1.0], requires_grad=True)

# Con gradientes (entrenamiento)
y = x ** 2
print(f"y.requires_grad: {y.requires_grad}")  # True

# Sin gradientes (inferencia)
with torch.no_grad():
    z = x ** 2
    print(f"z.requires_grad: {z.requires_grad}")  # False

# Uso t√≠pico: evaluaci√≥n de modelo
model.eval()  # Modo evaluaci√≥n
with torch.no_grad():
    predictions = model(test_data)
    # No se calculan gradientes = m√°s r√°pido y menos memoria
```

### Alternativa: @torch.no_grad()

```python
@torch.no_grad()
def evaluate(model, test_loader):
    model.eval()
    correct = 0
    total = 0
    for data, target in test_loader:
        output = model(data)
        _, predicted = output.max(1)
        correct += (predicted == target).sum().item()
        total += target.size(0)
    return correct / total
```

---

## 7. detach()

Crea una copia del tensor sin conexi√≥n al grafo:

```python
import torch

x = torch.tensor([2.0], requires_grad=True)
y = x ** 2

# y est√° conectado al grafo
print(f"y.requires_grad: {y.requires_grad}")  # True

# detach() crea copia sin gradientes
z = y.detach()
print(f"z.requires_grad: {z.requires_grad}")  # False

# √ötil para:
# 1. Pasar tensor a NumPy
numpy_array = y.detach().numpy()

# 2. Usar valor sin afectar gradientes
target = y.detach()  # No propaga gradientes hacia atr√°s

# 3. Congelar parte de la red
frozen_features = pretrained_model(x).detach()
output = my_classifier(frozen_features)  # Solo entrena my_classifier
```

---

## 8. Gradientes de Funciones Comunes

```python
import torch

x = torch.tensor([2.0], requires_grad=True)

# Funci√≥n lineal: y = 3x + 2 ‚Üí dy/dx = 3
y = 3 * x + 2
y.backward()
print(f"Lineal: {x.grad.item()}")  # 3.0
x.grad.zero_()

# Cuadr√°tica: y = x¬≤ ‚Üí dy/dx = 2x
y = x ** 2
y.backward()
print(f"Cuadr√°tica: {x.grad.item()}")  # 4.0
x.grad.zero_()

# Exponencial: y = e^x ‚Üí dy/dx = e^x
y = torch.exp(x)
y.backward()
print(f"Exponencial: {x.grad.item()}")  # ~7.39
x.grad.zero_()

# Sigmoid: œÉ(x) ‚Üí œÉ(x)(1-œÉ(x))
y = torch.sigmoid(x)
y.backward()
print(f"Sigmoid: {x.grad.item()}")  # ~0.105
x.grad.zero_()

# ReLU: max(0, x) ‚Üí 1 si x > 0, 0 si x ‚â§ 0
y = torch.relu(x)
y.backward()
print(f"ReLU: {x.grad.item()}")  # 1.0 (x > 0)
```

---

## 9. Ejemplo: Regresi√≥n Lineal Manual

```python
import torch

# Datos
X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])
y = torch.tensor([[2.0], [4.0], [6.0], [8.0]])

# Par√°metros con gradientes
w = torch.randn(1, 1, requires_grad=True)
b = torch.zeros(1, requires_grad=True)

learning_rate = 0.01

for epoch in range(1000):
    # Forward: y_pred = Xw + b
    y_pred = X @ w + b
    
    # Loss: MSE
    loss = ((y_pred - y) ** 2).mean()
    
    # Backward
    loss.backward()
    
    # Update (sin acumular gradientes, sin crear grafo)
    with torch.no_grad():
        w -= learning_rate * w.grad
        b -= learning_rate * b.grad
    
    # Limpiar gradientes
    w.grad.zero_()
    b.grad.zero_()
    
    if (epoch + 1) % 200 == 0:
        print(f"Epoch {epoch+1}, Loss: {loss.item():.6f}, w: {w.item():.3f}")

print(f"\nResultado: y = {w.item():.3f}x + {b.item():.3f}")
```

---

## üìù Resumen

| Concepto         | Descripci√≥n                                    |
| ---------------- | ---------------------------------------------- |
| `requires_grad`  | Flag para rastrear operaciones                 |
| `backward()`     | Calcula gradientes usando backpropagation      |
| `grad`           | Atributo donde se almacenan los gradientes     |
| `zero_grad()`    | Limpia gradientes acumulados                   |
| `no_grad()`      | Contexto sin c√°lculo de gradientes             |
| `detach()`       | Desconecta tensor del grafo computacional      |

---

## üîó Recursos

- [Autograd Tutorial](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)
- [Autograd Mechanics](https://pytorch.org/docs/stable/notes/autograd.html)

---

_Siguiente: [04 - nn.Module y Training Loop](04-nn-module-training.md)_

# ðŸ“‹ RÃºbrica de EvaluaciÃ³n - Semana 28

## Proyecto Final de Deep Learning

### ðŸ“Š DistribuciÃ³n de PuntuaciÃ³n

| Componente | Porcentaje | Puntos |
|------------|------------|--------|
| Funcionalidad del Modelo | 35% | 35 |
| Calidad del CÃ³digo | 20% | 20 |
| DocumentaciÃ³n | 20% | 20 |
| MÃ©tricas Alcanzadas | 15% | 15 |
| PresentaciÃ³n/README | 10% | 10 |
| **Total** | **100%** | **100** |

---

## 1. Funcionalidad del Modelo (35 puntos)

### Excelente (32-35 puntos)
- Modelo funciona correctamente end-to-end
- Pipeline completo: carga datos â†’ preprocesamiento â†’ entrenamiento â†’ evaluaciÃ³n â†’ inferencia
- Manejo robusto de errores
- CÃ³digo de inferencia para nuevas muestras
- Modelo guardado y cargable sin problemas

### Bueno (25-31 puntos)
- Modelo funciona correctamente
- Pipeline completo pero con algunos pasos manuales
- Manejo bÃ¡sico de errores
- Modelo guardado correctamente

### Suficiente (18-24 puntos)
- Modelo funciona con supervisiÃ³n
- Pipeline incompleto o con bugs menores
- Errores no manejados pueden causar fallos

### Insuficiente (0-17 puntos)
- Modelo no funciona o tiene errores crÃ­ticos
- Pipeline incompleto
- No se puede reproducir el entrenamiento

---

## 2. Calidad del CÃ³digo (20 puntos)

### Excelente (18-20 puntos)
- CÃ³digo limpio y bien organizado
- Funciones modulares y reutilizables
- Type hints en funciones principales
- Docstrings completos
- Nombres descriptivos de variables/funciones
- Sin cÃ³digo duplicado
- ConfiguraciÃ³n separada (no hardcoded)

### Bueno (14-17 puntos)
- CÃ³digo organizado y legible
- Algunas funciones modulares
- DocumentaciÃ³n parcial
- Nombres razonables

### Suficiente (10-13 puntos)
- CÃ³digo funcional pero desordenado
- Poca modularizaciÃ³n
- DocumentaciÃ³n mÃ­nima

### Insuficiente (0-9 puntos)
- CÃ³digo difÃ­cil de leer
- Sin organizaciÃ³n
- Sin documentaciÃ³n

---

## 3. DocumentaciÃ³n (20 puntos)

### Excelente (18-20 puntos)
- README completo con:
  - DescripciÃ³n clara del problema
  - Instrucciones de instalaciÃ³n y ejecuciÃ³n
  - DescripciÃ³n del dataset
  - Arquitectura del modelo (con diagrama)
  - Resultados y mÃ©tricas
  - Ejemplos de uso
  - Conclusiones y trabajo futuro
- Notebook bien comentado
- CÃ³digo autodocumentado

### Bueno (14-17 puntos)
- README con secciones principales
- Notebook con comentarios
- Instrucciones bÃ¡sicas de uso

### Suficiente (10-13 puntos)
- README bÃ¡sico
- Comentarios escasos
- Falta informaciÃ³n importante

### Insuficiente (0-9 puntos)
- Sin README o muy incompleto
- Sin comentarios en cÃ³digo
- No se puede entender el proyecto

---

## 4. MÃ©tricas Alcanzadas (15 puntos)

### Computer Vision (OpciÃ³n A)

| Accuracy Test | Puntos |
|---------------|--------|
| > 90% | 15 |
| 85-90% | 12 |
| 80-85% | 9 |
| 75-80% | 6 |
| < 75% | 3 |

### NLP (OpciÃ³n B)

| F1-Score / Accuracy | Puntos |
|---------------------|--------|
| > 85% | 15 |
| 80-85% | 12 |
| 75-80% | 9 |
| 70-75% | 6 |
| < 70% | 3 |

**Nota**: Se evaluarÃ¡ la mÃ©trica principal segÃºn el problema elegido.

---

## 5. PresentaciÃ³n / README (10 puntos)

### Excelente (9-10 puntos)
- README profesional y atractivo
- Uso correcto de Markdown
- ImÃ¡genes/diagramas de arquitectura
- GrÃ¡ficas de resultados (loss, accuracy)
- Badges si aplica
- Ejemplos visuales de predicciones

### Bueno (7-8 puntos)
- README bien estructurado
- Algunas visualizaciones
- Formato correcto

### Suficiente (5-6 puntos)
- README bÃ¡sico pero funcional
- Pocas o ninguna visualizaciÃ³n

### Insuficiente (0-4 puntos)
- README pobre o inexistente
- Sin estructura clara

---

## ðŸ“ Checklist de Entrega

### Archivos Requeridos

- [ ] `README.md` - DocumentaciÃ³n del proyecto
- [ ] `requirements.txt` - Dependencias
- [ ] Notebook o script principal
- [ ] Modelo guardado (`.pth`, `.h5`, o similar)
- [ ] Carpeta `data/` o instrucciones de descarga

### Contenido del README

- [ ] TÃ­tulo y descripciÃ³n
- [ ] Problema a resolver
- [ ] Dataset utilizado
- [ ] Arquitectura del modelo
- [ ] Instrucciones de instalaciÃ³n
- [ ] Instrucciones de entrenamiento
- [ ] Instrucciones de inferencia
- [ ] Resultados y mÃ©tricas
- [ ] Visualizaciones
- [ ] Conclusiones

### CÃ³digo

- [ ] Se ejecuta sin errores
- [ ] Reproducible (seeds fijos)
- [ ] Documentado
- [ ] Modular

---

## ðŸŽ¯ Criterios de AprobaciÃ³n

| Requisito | MÃ­nimo |
|-----------|--------|
| PuntuaciÃ³n total | â‰¥ 70/100 |
| Funcionalidad del modelo | â‰¥ 20/35 |
| MÃ©tricas alcanzadas | â‰¥ 6/15 |
| Entregables completos | 100% |

---

## ðŸ“Œ Notas Adicionales

### Bonificaciones (+5 puntos mÃ¡ximo)

- **+2**: Deployment bÃ¡sico (Gradio, Streamlit)
- **+2**: AnÃ¡lisis de errores detallado
- **+1**: ComparaciÃ³n de mÃºltiples modelos

### Penalizaciones

- **-10**: Entrega tardÃ­a (por dÃ­a)
- **-5**: CÃ³digo no reproducible
- **-5**: Plagio o copia

---

_RÃºbrica Semana 28 - Proyecto Final Deep Learning_

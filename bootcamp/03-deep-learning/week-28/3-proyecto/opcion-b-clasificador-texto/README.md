# ğŸ“ Proyecto: Clasificador de Texto con Transformers

## ğŸ¯ Objetivo

Construir un clasificador de sentimiento usando fine-tuning de modelos preentrenados de Hugging Face (DistilBERT/BERT).

---

## ğŸ“‹ DescripciÃ³n

DesarrollarÃ¡s un pipeline completo de NLP que incluye:
- Carga y exploraciÃ³n del dataset
- TokenizaciÃ³n con AutoTokenizer
- Fine-tuning de DistilBERT
- Entrenamiento con Hugging Face Trainer
- EvaluaciÃ³n e inferencia

---

## â±ï¸ DuraciÃ³n

4 horas

---

## ğŸ“Š Dataset

**IMDB Movie Reviews** - 50,000 reviews de pelÃ­culas:
- 25,000 para entrenamiento
- 25,000 para test
- ClasificaciÃ³n binaria: Positivo / Negativo

El dataset se descarga automÃ¡ticamente desde Hugging Face.

---

## ğŸ—‚ï¸ Estructura

```
opcion-b-clasificador-texto/
â”œâ”€â”€ README.md          # Este archivo
â”œâ”€â”€ starter/
â”‚   â””â”€â”€ main.py        # CÃ³digo con TODOs
â””â”€â”€ solution/
    â””â”€â”€ main.py        # SoluciÃ³n completa
```

---

## ğŸ“ Tareas a Implementar

### 1. Carga de Datos (15 min)
- [ ] Cargar dataset IMDB desde Hugging Face
- [ ] Explorar estructura y ejemplos
- [ ] Crear subset para desarrollo rÃ¡pido (opcional)

### 2. TokenizaciÃ³n (30 min)
- [ ] Cargar tokenizer de DistilBERT
- [ ] Implementar funciÃ³n de tokenizaciÃ³n
- [ ] Aplicar a todo el dataset

### 3. Modelo (20 min)
- [ ] Cargar modelo preentrenado
- [ ] Configurar para clasificaciÃ³n binaria

### 4. Entrenamiento (60 min)
- [ ] Configurar TrainingArguments
- [ ] Definir funciÃ³n de mÃ©tricas
- [ ] Entrenar con Trainer API
- [ ] Implementar early stopping

### 5. EvaluaciÃ³n (30 min)
- [ ] Evaluar en test set
- [ ] Analizar errores
- [ ] Probar inferencia con textos nuevos

### 6. DocumentaciÃ³n (25 min)
- [ ] Documentar cÃ³digo
- [ ] Guardar modelo
- [ ] Escribir conclusiones

---

## ğŸ¯ Criterios de Ã‰xito

| MÃ©trica | MÃ­nimo | Objetivo | Excelente |
|---------|--------|----------|-----------|
| Test Accuracy | 80% | 85% | 90%+ |
| Test F1-Score | 80% | 85% | 90%+ |
| CÃ³digo documentado | âœ“ | âœ“ | âœ“ |
| Inferencia funcionando | âœ“ | âœ“ | âœ“ |

---

## ğŸš€ Instrucciones

### 1. Preparar Entorno

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac

# Instalar dependencias
pip install transformers datasets evaluate accelerate scikit-learn
pip install torch  # Si no estÃ¡ instalado
```

### 2. Implementar el Proyecto

```bash
cd starter
python main.py
```

### 3. Verificar Resultados

- Accuracy en test > 85%
- Modelo guardado en `./model`
- Inferencia funcionando

---

## ğŸ’¡ Tips

### Para Mejor Accuracy

1. **HiperparÃ¡metros Ã³ptimos**
   ```python
   learning_rate = 2e-5  # Rango: 1e-5 a 5e-5
   batch_size = 16       # 8-32 segÃºn GPU
   epochs = 3            # 2-5 para fine-tuning
   warmup_ratio = 0.1    # Warmup importante
   ```

2. **No entrenar demasiado**
   - 3-5 Ã©pocas suelen ser suficientes
   - MÃ¡s Ã©pocas pueden causar overfitting

3. **Usar subset para desarrollo**
   ```python
   # Para pruebas rÃ¡pidas
   train_dataset = train_dataset.select(range(1000))
   ```

### Errores Comunes

- âŒ Learning rate muy alto (> 1e-4)
- âŒ Demasiadas Ã©pocas (> 5)
- âŒ No usar warmup
- âŒ Olvidar establecer `fp16=True` con GPU

---

## ğŸ“š Recursos

- [Hugging Face Course - NLP](https://huggingface.co/course/chapter3)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [IMDB Dataset](https://huggingface.co/datasets/imdb)
- [DistilBERT Paper](https://arxiv.org/abs/1910.01108)

---

_Proyecto OpciÃ³n B - NLP | Semana 28_
